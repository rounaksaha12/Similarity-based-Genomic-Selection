After clean(removal of rows with high missing values + redundancy removal) X.shape:  (397, 24108)
Fold 1, k_feat 8
X_train.shape:  (264, 8)
y_pred:  [ 0.59021926  0.57034725  0.59021926  0.59021926  0.59021926  0.59021926
  0.59021926  0.59021926  0.59021926  0.59021926  0.45599914  0.59021926
  0.01022447 -0.691081   -0.8054291   0.45599914  0.59021926  0.2617044
  0.2235626   0.05357045 -0.26878035  0.59021926  0.1092145   0.05196823
 -0.8054291   0.01022447  0.59021926  0.12748426 -0.8054291   0.59021926
  0.59021926  0.01022447  0.59021926  0.59021926  0.59021926  0.01022447
 -0.26878035 -0.28705013 -0.8054291   0.4003551  -0.7100411  -0.59729517
 -0.38312846 -0.8054291  -0.8054291   0.4964335   0.59021926 -0.7299131
 -0.691081   -0.8054291  -0.07281851 -0.691081    0.1092145  -0.66695833
  0.01022447  0.01022447  0.01022447 -0.8054291  -0.691081    0.59021926
  0.05357045 -0.8054291  -0.7299131   0.57034725 -0.26878035  0.36513644
 -0.26878035 -0.24890833 -0.26878035 -0.7855571   0.16791858  0.03369845
  0.59021926  0.59021926  0.59021926 -0.61556494 -0.8054291   0.1290865
 -0.40029395  0.01022447  0.01022447  0.01022447  0.01022447  0.01022447
  0.01022447  0.43772936  0.01022447  0.01022447  0.14735626  0.01022447
  0.03369845  0.01022447  0.01022447  0.05357045  0.59021926  0.59021926
 -0.8054291  -0.8054291   0.59021926  0.59021926  0.59021926 -0.8054291
  0.59021926  0.1290865  -0.61556494  0.3622133   0.16791858 -0.26717812
  0.2235626   0.57034725  0.1092145  -0.24890833 -0.38312846 -0.26316214
 -0.24890833  0.16791858 -0.3442964   0.14804658 -0.83535624 -0.48857158
 -0.36256617 -0.6917713  -0.8054291  -0.7936468  -0.5774232  -0.7299131
 -0.7299131   0.52763605  0.5719495  -0.3244244   0.16791858 -0.7737748
  0.5147032 ]
Pearson r: 0.595
MSE: 0.730
Fold 2, k_feat 8
X_train.shape:  (265, 8)
y_pred:  [ 0.438056    0.438056    0.438056    0.438056    0.39978182  0.438056
  0.14176345  0.3720808   0.438056    0.438056    0.438056    0.438056
 -0.7264779   0.438056   -0.7264779   0.39978182 -0.6605027   0.3720808
 -0.64240044  0.34231412 -0.47981453  0.438056    0.438056    0.438056
  0.438056   -0.4684595   0.14176345  0.42670095  0.3720808  -0.53443474
 -0.5259273  -0.7264779   0.438056    0.18003762  0.18003762  0.15027094
  0.15027094 -0.7264779   0.438056    0.438056    0.438056    0.438056
  0.33380663  0.3720808   0.34231412  0.14176345 -0.7264779  -0.7264779
 -0.4684595  -0.7264779  -0.7264779  -0.7264779  -0.7264779  -0.4684595
  0.438056    0.40701604  0.438056    0.39978182  0.438056    0.39978182
  0.42670095  0.438056    0.438056    0.438056    0.14176345  0.438056
  0.23092997  0.34231412  0.438056    0.438056    0.438056    0.18003762
  0.42670095  0.438056    0.3720808   0.39978182  0.438056    0.438056
  0.438056    0.49460292 -0.6605027   0.40701604 -0.4684595   0.3720808
  0.20773864 -0.7264779  -0.7264779   0.3720808  -0.53728235  0.14176345
  0.14176345  0.14176345  0.14176345  0.3720808   0.33380663  0.14176345
  0.438056    0.438056    0.438056    0.33380663  0.438056    0.438056
 -0.7264779  -0.4684595  -0.7264779  -0.7264779  -0.6882039  -0.53443474
  0.438056   -0.7179705   0.438056   -0.7264779   0.4178841   0.56651235
 -0.53443474  0.14176345 -0.6631427   0.39978182  0.39978182 -0.6605027
  0.26830673  0.14176345 -0.7264779  -0.53443474 -0.43018544 -0.6222286
 -0.7264779   0.2460128   0.438056   -0.03432262 -0.4961607   0.3720808 ]
Pearson r: 0.520
MSE: 0.828
Fold 3, k_feat 8
X_train.shape:  (265, 8)
y_pred:  [ 0.5610484   0.5610484   0.5610484   0.5610484  -0.08632624  0.5610484
  0.5610484   0.4792019  -0.23385978  0.56813705  0.5610484   0.5610484
 -0.5176672   0.45606458  0.09183645  0.45606458  0.09183645 -1.0395553
  0.5610484   0.50641096 -0.30096984 -1.193622   -0.23877168 -0.81730616
 -0.2463324  -1.193622   -0.5905272  -0.23385978 -0.23385978  0.5610484
  0.5610484   0.5610484   0.5610484  -0.23385978 -0.07274437 -0.49878573
  0.5610484  -0.928696   -0.5051918   0.5610484  -0.7626687   0.3021251
  0.3021251  -0.32560122  0.5610484  -1.193622    0.5610484   0.50641096
  0.3021251   0.5610484   0.3217734   0.50641096  0.5610484   0.5610484
  0.5610484   0.438609   -0.70047057  0.5610484   0.5610484  -0.84684944
  0.50641096 -0.32560122  0.5610484  -0.06667781  0.35676253  0.44850385
 -0.07274437  0.510702   -0.13494253  0.3217734   0.5610484   0.5610484
  0.47571313 -0.18413424 -1.193622    0.09183645 -0.2702719  -0.1534363
  0.09183645  0.09183645  0.09183645  0.09183645  0.09183645 -0.21912324
 -0.08230996 -0.30096984  0.4792019  -0.30096984  0.03719902  0.26542437
  0.46930707  0.09183645 -0.18413424  0.50641096 -1.193622   -1.193622
 -1.193622   -1.193622    0.1835779   0.15403461  0.5610484   0.5610484
  0.5610484  -0.06667781  0.5610484  -0.928696    0.5610484  -0.23385978
  0.39386642  0.21078694 -0.15957391 -1.1082866   0.12253439  0.06789696
 -0.45450592 -0.51125836  0.42456448 -0.06667781 -0.21563447 -1.1117754
 -0.08948922 -0.24375463  0.5267345  -0.93469864 -0.30096984 -0.02378726
 -0.4680878   0.01698875  0.4792019  -0.2463324  -0.3623017  -0.72441006]
Pearson r: 0.493
MSE: 0.610
Average pearson_r accross all folds = 0.5360757506410775
Average mse accross all folds = 0.7223989367485046
Fold 1, k_feat 16
X_train.shape:  (264, 16)
y_pred:  [ 0.80430466  0.7933796   0.80430466  0.80430466  0.80430466  0.80430466
  0.80430466  0.80430466  0.80430466  0.80430466  0.71135205  0.80430466
 -0.4391227  -0.9479338  -1.4909316   0.5189468   0.41470116  0.30311912
 -0.06886423  0.22163594  0.25481433  0.80430466 -0.20472121 -0.2871271
 -0.98268414 -0.4391227   0.80430466  0.2018717  -0.98268414  0.37900394
  0.37900394 -0.4391227   0.80430466  0.37900394  0.80430466  0.02184761
  0.42905968 -0.3929154  -1.4909316   0.25143814 -0.8905513  -0.873826
 -0.6206187  -0.9470145  -0.9470145   0.32305616  0.80430466 -0.9662633
 -0.6852016  -0.5217139  -0.04053813 -0.86498696 -0.23383865 -0.8762262
  0.20155865  0.20155865 -0.4391227  -1.0299615  -0.9479338   0.80430466
  0.39588135 -1.4909316  -0.47617573  0.7933796   0.42905968  0.50990313
  0.42905968  0.43998474  0.42905968 -0.51078886  0.34006506 -0.27937683
  0.80430466  0.6300593   0.37900394 -0.4589351  -0.98268414 -0.22291362
 -0.09292674  0.20155865  0.20155865  0.20155865  0.20155865  0.21971852
  0.20155865  0.42559034  0.20155865  0.20155865 -0.12955707  0.20155865
  0.22887081  0.20155865  0.20155865 -0.26845178  0.80430466  0.80430466
 -0.98268414 -0.98268414  0.80430466  0.80430466  0.80430466 -0.5217139
  0.80430466  0.26717412 -0.21990281 -0.08091819  0.04691195 -0.5919053
 -0.45669588  0.7933796  -0.07775325 -0.89733785 -0.87164646 -0.6157158
  0.05371994 -0.491309   -0.17698854  0.2927385  -0.44040614 -0.2532876
 -0.16923827 -1.0909475  -0.8375562  -0.77652836 -0.19856822 -0.47617573
 -0.5748418  -0.13005662 -0.20886219 -0.36326173 -0.6655543  -0.4970383
 -0.4028566 ]
Pearson r: 0.663
MSE: 0.625
Fold 2, k_feat 16
X_train.shape:  (265, 16)
y_pred:  [ 0.5545453   0.5545453   0.32143676  0.6747881   0.5607656   0.5545453
  0.2862996   0.44138062  0.5545453   0.32143676  0.4017781   0.4017781
 -0.91112584  0.5545453  -0.91112584 -0.17979836 -0.67638135  0.23888338
 -0.9299412   0.0734539  -0.49503553  0.02725041  0.5545453   0.5545453
  0.26035893 -0.32685578 -0.03900993  0.02032936  0.51151    -0.01253736
 -0.5044755  -0.91112584  0.5545453   0.01527166 -0.1063081  -0.35265505
 -0.21123588 -0.91112584  0.5545453   0.5545453   0.4017781   0.5545453
  0.5392901   0.23888338  0.07950807  0.10240936 -0.91112584 -0.91112584
 -0.75772774 -0.6169393  -0.91112584 -0.91112584 -0.91112584 -0.75772774
  0.5545453   0.29021823  0.5545453   0.26657903  0.6747881   0.26657903
  0.29467642  0.32143676  0.5545453   0.46285617  0.19409859  0.4017781
  0.52936137  0.07950807  0.4017781   0.6747881   0.5545453   0.28828156
  0.29467642  0.5545453   0.53306973  0.05331016  0.5545453   0.5545453
  0.5545453   0.8958107  -0.88965034  0.52332675 -0.15858305  0.01182914
  0.3371538  -0.6169393  -0.91112584  0.24493754 -0.22022355  0.19409859
  0.19409859  0.11318123  0.10240936  0.23888338  0.54534423  0.19409859
  0.5545453   0.5545453   0.5545453   0.5392901   0.5545453   0.5545453
 -0.91112584 -0.7516736  -0.91112584 -0.91112584 -0.92340016 -0.4681908
  0.5545453  -0.6363981   0.5545453  -0.4036703   0.52652895  0.42394984
 -0.47896254  0.33551776 -0.9290085   0.5668198   0.05936432 -0.15514052
  0.20193112 -0.3331964  -0.17056179 -0.5460948  -0.23059893 -0.4555472
 -0.19708884 -0.32399535  0.5545453  -0.30308068 -0.76952434  0.08669233]
Pearson r: 0.548
MSE: 0.790
Fold 3, k_feat 16
X_train.shape:  (265, 16)
y_pred:  [ 0.66162956  0.66162956  0.66162956  0.66162956 -0.15727925  0.66162956
  0.66162956  0.6088706  -0.4173218   0.48737395  0.66162956  0.66162956
 -0.71881133  0.31969154 -0.05222833  0.31969154 -0.05222833 -0.98059535
  0.66162956  0.5752338  -0.27473438 -1.2793959  -0.18848193 -0.79919386
 -0.07394922 -1.2391291  -0.6834099  -0.42594326 -0.42594326  0.39099848
  0.66162956  0.66162956  0.40300405 -0.42594326  0.08309376 -0.65894115
  0.66162956 -1.078146   -0.1179831   0.40300405 -0.56758463  0.24933946
  0.24933946 -0.21865082  0.66162956 -1.2391291   0.40300405  0.6400238
  0.24933946  0.59683955  0.25621545  0.42057788  0.66162956  0.59683955
  0.66162956  0.21050489 -0.4410652   0.40300405  0.40300405 -0.7777795
  0.42919934 -0.17978084  0.66162956 -0.12115502  0.27203226  0.29650104
  0.08309376  0.55130064 -0.03480422  0.2648369   0.66162956  0.66162956
  0.5926837  -0.02806604 -1.2391291   0.10242772 -0.29218423  0.06594443
  0.10242772  0.3610989   0.10242772 -0.05222833  0.10242772 -0.24499905
 -0.02783203 -0.3063798   0.3416232  -0.3063798   0.12000179  0.40663636
  0.5651461   0.10242772  0.05174887  0.6400238  -1.2391291  -1.2391291
 -1.2391291  -1.2391291   0.19891131  0.40693676  0.66162956  0.66162956
  0.66162956 -0.12977648  0.66162956 -1.0695245   0.66162956 -0.42594326
  0.38608992  0.19722974 -0.00324404 -1.0163482   0.07215142 -0.10468614
 -0.6750039  -0.42273307  0.0893873   0.06545603 -0.05195355 -1.1057336
  0.09183586 -0.18179345  0.68563163 -0.8902319  -0.47335088 -0.04465437
 -0.67721224 -0.0201484   0.4731778   0.03833234 -0.1455524  -0.9291103 ]
Pearson r: 0.500
MSE: 0.609
Average pearson_r accross all folds = 0.5704100060152038
Average mse accross all folds = 0.6747949123382568
Fold 1, k_feat 32
X_train.shape:  (264, 32)
y_pred:  [ 0.91907275  0.86487055  0.8692312   0.8560158   0.8692312   0.7421483
  0.7421483   0.628132    0.7421483   0.8692312   0.98182034  0.67302823
 -0.44698074 -0.993789   -1.4509323   0.5339354   0.58067834  0.44595754
  0.03956026  0.15614021  0.19598544  0.7421483   0.01321071 -0.4041446
 -0.9414316  -0.44698074  0.8692312   0.3886311  -0.9414316   0.4409082
  0.37785125 -0.44698074  1.0437995   0.39106667  0.7552149  -0.05690914
  0.4522729  -0.3231988  -1.4509323   0.14876449 -0.9756818  -0.8570405
 -0.57310045 -1.0955595  -1.0200713   0.34932637  0.8692312  -0.92753035
 -0.76631117 -0.55512214  0.26079667 -0.97566813 -0.20823419 -0.98063534
  0.0813275   0.0813275  -0.44698074 -1.0646229  -0.993789    0.67302823
  0.33102453 -1.4509323  -0.49811578  0.86487055  0.4522729   0.83751154
  0.4522729   0.5196904   0.4522729  -0.53583956  0.43371332 -0.33692965
  0.8692312   0.809147    0.4409082  -0.38229418 -0.9414316  -0.28024727
 -0.1255275   0.09454292  0.12410027  0.0813275   0.09454292  0.11157209
  0.1593064   0.41285145  0.0813275   0.0813275  -0.069574    0.0813275
  0.18202412  0.0813275   0.0813275  -0.18996984  0.8560158   0.91907275
 -0.9414316  -0.9414316   1.1681054   0.72286975  0.93228817 -0.55512214
  0.8692312   0.13595182 -0.39142886  0.02213365  0.09165496 -0.4895549
 -0.334265    0.8516551  -0.17927992 -0.7100108  -0.5511061  -0.7640467
  0.22658539 -0.61991125 -0.1513691   0.3250997  -0.5030296   0.21564984
 -0.34717667 -1.0547371  -1.101377   -0.6788267  -0.379678   -0.5223471
 -0.62006176 -0.32657027 -0.4542032  -0.42853704 -0.74305254 -0.5876908
 -0.26338267]
Pearson r: 0.661
MSE: 0.626
Fold 2, k_feat 32
X_train.shape:  (265, 32)
y_pred:  [ 0.7050196   0.716746    0.5657824   0.7292713   0.72867     0.7050196
 -0.09812582  0.6394144   0.69862044  0.57094777  0.70239747  0.70239747
 -1.2039859   0.7050196  -1.1367342   0.2470771  -0.94572526  0.15573943
 -1.2175345   0.12308192 -0.7199955   0.370772    0.6570848   0.7050196
  0.5164083  -0.10769033  0.4536878   0.46077406  0.47628653 -0.09362483
 -0.38670707 -1.1367342   0.7050196  -0.15115404 -0.64609826 -0.81367373
 -0.7244333  -1.2452095   0.7050196   0.7050196   0.70239747  0.7050196
  0.42703044  0.25826776  0.21875334  0.11248219 -1.2039859  -1.2039859
 -0.30736816 -0.66903055 -0.319875   -1.2039859  -1.1367342  -0.30736816
  0.7050196   0.43851697  0.7025825   0.4444505   0.7292713   0.4444505
  0.5158335   0.5657824   0.7050196   0.75177157  0.3448223   0.70239747
  0.6923789   0.23047972  0.70239747  0.83824956  0.7050196   0.21394837
  0.56376827  0.7050196   0.70106876  0.14123535  0.7050196   0.7050196
  0.69862044  0.8320297  -0.8696727   0.6867324  -0.06676507  0.13029933
 -0.09932673 -0.66903055 -0.47998774  0.5172759  -0.5202272   0.3448223
  0.20697618  0.13164818  0.27796185  0.4762491   0.3927945   0.2261945
  0.7050196   0.7025825   0.7025825   0.3361777   0.7050196   0.7050196
 -1.1367342  -0.46498132 -1.2452095  -1.1367342  -0.7441572  -0.57404375
  0.5960411  -0.68281925  0.7050196  -0.9073698   0.17877829 -0.35021496
 -0.42367613 -0.38205397 -1.3672932   0.7217623   0.03081322 -0.45996737
 -0.41175246 -0.84150684 -0.77198476 -0.43994856 -0.02400768 -0.65872705
 -0.45643783 -0.6818477   0.7050196  -0.7634258  -0.5634788   0.09685922]
Pearson r: 0.639
MSE: 0.666
Fold 3, k_feat 32
X_train.shape:  (265, 32)
y_pred:  [ 0.70313966  0.5671958   0.70313966  0.5671958  -0.17595828  0.70313966
  0.6762787   0.46313584 -0.5738939   0.27183938  0.6148964   0.70313966
 -0.79719496  0.16434228  0.07267892  0.16434228  0.07267892 -1.10082
  0.70313966  0.56895316 -0.14871716 -1.3463892  -0.20812285 -0.9170854
 -0.07047319 -1.2017274  -0.56519043 -0.4767785  -0.5496502   0.27117288
  0.70313966  0.70313966  0.42831075 -0.42311358  0.02695906 -0.6908772
  0.6148964  -1.0858338  -0.14762294  0.42831075 -0.5787467   0.14706242
  0.14706242 -0.17696452  0.6148964  -1.2745991   0.42831075  0.6378025
  0.14706242  0.63429034  0.35974562  0.4456147   0.70313966  0.65437925
  0.70313966  0.2689749  -0.4281838   0.42831075  0.42831075 -0.8302505
  0.4567064  -0.29249966  0.70313966 -0.06354046  0.1006844   0.11000884
  0.03838515  0.42300403 -0.075804    0.169976    0.70313966  0.6148964
  0.6122247  -0.2569487  -1.2745991   0.1960175  -0.14853644  0.15703154
  0.1960175   0.24773502  0.1960175  -0.08189487  0.1960175  -0.3031205
  0.17126346 -0.30011332  0.3487507  -0.31690657  0.0868504   0.33392394
  0.37044942  0.1960175   0.01638377  0.63748944 -1.2745991  -1.2745991
 -1.2745991  -1.2745991  -0.02195001  0.22038078  0.6148964   0.70313966
  0.70313966 -0.07463217  0.70313966 -0.9288521   0.73833835 -0.42311358
  0.21456432  0.21321929 -0.02604914 -0.93216926  0.29842007 -0.28902447
 -0.6073704  -0.3145957  -0.01200175  0.17905831 -0.01259255 -0.9695151
 -0.00995433 -0.07504547  0.60979664 -0.63028955 -0.6657647   0.21264672
 -0.6069052   0.10677135  0.55153954 -0.1318115  -0.22077644 -0.8688924 ]
Pearson r: 0.512
MSE: 0.597
Average pearson_r accross all folds = 0.6039823624038011
Average mse accross all folds = 0.6295809745788574
Fold 1, k_feat 64
X_train.shape:  (264, 64)
y_pred:  [ 0.9877403   0.855587    0.8165202   0.90468156  0.91447365  0.883368
  0.883368    0.78831875  0.883368    0.91447365  0.6997421   0.69667447
 -0.6736144  -1.1455967  -1.5635698   0.705104    0.7207116   0.63432264
  0.03389418  0.05313921  0.30865884  0.883368   -0.08745795 -0.6351713
 -1.0072634  -0.6736144   0.91447365  0.3292358  -1.1052169   0.57506335
  0.49200463 -0.66983056  1.1462315   0.44772696  0.8194244   0.23670435
  0.52823925 -0.32639056 -1.4883854   0.05780542 -0.98009914 -0.6539068
 -0.7811872  -1.263891   -1.2353518   0.40083492  0.91447365 -0.66369796
 -1.0471236  -0.70518476  0.5714978  -0.74770176 -0.49862263 -0.9178181
  0.18672895  0.17927527 -0.66983056 -1.5287607  -1.0815868   0.69530797
  0.2700293  -1.4883854  -0.5519885   0.9049301   0.52823925  0.6416824
  0.5315993   0.61748135  0.52823925 -0.44705963  0.39493668 -0.48512572
  0.91447365  0.8435173   0.57506335 -0.44366437 -1.101433   -0.32414448
  0.10113251 -0.16736293  0.02499449  0.11628127  0.21292627 -0.01899886
  0.23476875  0.07336223  0.20490384  0.25998938 -0.21029884  0.25998938
 -0.12393206  0.15043092  0.25998938 -0.40934145  0.90468156  0.9877403
 -1.1052169  -1.1052169   1.2356771   0.82264435  0.99753237 -0.67423713
  0.91447365  0.29563463 -0.35755843  0.34631813  0.25657153 -0.424282
 -0.32136744  0.8314332  -0.36702627 -0.41584522 -0.28719455 -0.3573622
  0.29590666 -0.39307392 -0.10852969  0.16368973 -0.5636698   0.04472625
 -0.38716298 -0.8258569  -1.3637927  -0.347157   -0.33877617 -0.4686538
 -0.6220027  -0.49376866 -0.66442907 -0.26952028 -0.8820105  -0.19414765
 -0.26481003]
Pearson r: 0.680
MSE: 0.596
Fold 2, k_feat 64
X_train.shape:  (265, 64)
y_pred:  [ 0.8937098   0.8426064   0.8132402   0.58937275  0.8631822   0.5599822
 -0.05042219  0.95389473  0.83257043  0.7926303   0.48013318  0.51635826
 -1.394688    0.8937098  -1.2064643   0.0913738  -0.7798665  -0.1327256
 -1.2347126   0.17952251 -0.66499877  0.63977444  0.8401207   0.8690175
  0.5514213  -0.33395493  0.65209734  0.61703646  0.7066926   0.24776244
 -0.42533493 -1.172711    0.8937098   0.02425599 -0.94598496 -0.47727394
 -0.96571827 -1.2758231   0.8937098   0.8937098   0.60421693  0.8007997
  0.47731674 -0.05956686  0.23688626  0.56376326 -1.394688   -1.394688
 -0.17845964 -0.54740727 -0.58193076 -1.1959882  -1.2604977  -0.17845964
  1.0040642   0.728618    0.8924266  -0.08905208  0.58937275 -0.00280452
  0.43028176  0.5899404   0.7318152   0.9917046   0.42151916  0.7298862
  0.6088921   0.44460285  0.60421693  0.8580383   0.80790865  0.21878874
  0.80008066  0.508515    0.13853729  0.2244364   0.6704098   0.8937098
  0.88925517  0.84089386 -0.7424116   0.66288507  0.18107605  0.08868372
 -0.41700017 -0.4918623  -0.6702147   0.0219928  -0.94964033  0.25962412
  0.15632737  0.09541321  0.30242395  0.10729229  0.13818967  0.24530566
  0.6704098   0.7995168   0.8924266   0.22440994  0.8937098   0.8937098
 -1.2604977  -0.886745   -1.2056413  -1.172711   -0.37549984 -0.38140345
  0.43265092 -0.6518218   0.8007997  -0.88705647 -0.15514767 -0.23836792
 -0.49767327 -1.0374825  -0.80379516  0.28157067 -0.62971747 -0.15997458
 -0.43135858 -0.9434506  -0.84603125 -0.317361   -0.5536134  -0.48894298
 -0.48736787 -0.4265343   0.5048245  -0.34426987 -0.23141527  0.16487491]
Pearson r: 0.665
MSE: 0.627
Fold 3, k_feat 64
X_train.shape:  (265, 64)
y_pred:  [ 0.8516639   0.7594809   0.8516639   0.7594809   0.1551804   0.7542034
  0.75972754  0.27357388 -0.6210934  -0.514702    0.59467655  0.7409325
 -0.9403802  -0.18013585  0.16072595 -0.18013585  0.16072595 -1.4989333
  0.76000446  0.6632373  -0.38656104 -0.98588777 -0.09329665 -0.26508707
 -0.72671086 -1.2934391  -0.9187015  -0.62859917 -0.36254835  0.35297424
  0.8516639   0.8516639   0.6532292  -0.5749732   0.05165285 -0.8812096
  0.78380245 -1.1050855   0.04537606  0.57556003 -0.58417577  0.3496067
  0.3496067   0.14549482  0.78380245 -0.5009387   0.6532292   0.7906175
  0.30903107  0.6943249   0.31873482  0.6397055   0.7788177   0.34574002
  0.8516639   0.28980458 -0.00647283  0.65333074  0.6532292  -0.58278733
  0.6339918  -0.4111286   0.8516639  -0.04394335 -0.06843489  0.13423383
  0.1952141   0.20387846 -0.28773865  0.04646248  0.8516639   0.78380245
  0.64340276 -0.36825836 -1.0300827   0.26421076 -0.18210238  0.25609088
  0.2446956   0.20792413  0.24760383 -0.04856187  0.30105585 -0.10258156
  0.47076076 -0.20291197  0.2826134  -0.05732989  0.02620655  0.15530264
  0.17101991  0.24760383 -0.07778132  0.63396126 -1.2182201  -1.2910663
 -0.9737365  -1.2910663   0.0069074   0.10906732  0.787854    0.85001904
  0.8356957   0.2787001   0.7392877  -0.88200843  0.852019   -0.5749732
 -0.02195036  0.13115    -0.04176199 -0.8448346   0.5954636  -0.90489775
 -0.77561426 -0.49732655 -0.4861338   0.16272229 -0.26809165 -0.50150406
 -0.34021416  0.22299159  0.75651914 -0.2136634  -1.066851   -0.24772078
 -0.83754945  0.25428247  0.31474024 -0.27823812 -0.20122814 -0.79882103]
Pearson r: 0.597
MSE: 0.516
Average pearson_r accross all folds = 0.6475443772324038
Average mse accross all folds = 0.579536497592926
Fold 1, k_feat 128
X_train.shape:  (264, 128)
y_pred:  [ 1.0942518e+00  1.0063947e+00  9.4119036e-01  1.0007079e+00
  1.0107477e+00  1.0239562e+00  1.0239562e+00  9.7996247e-01
  1.0239562e+00  9.9892330e-01  6.9856119e-01  8.7619162e-01
 -8.0389756e-01 -1.4338784e+00 -1.6150401e+00  6.6830885e-01
  6.2119043e-01  5.6384492e-01 -3.9002120e-02  3.0877513e-01
  3.3610165e-02  1.0239562e+00 -3.9562958e-01 -8.4526277e-01
 -1.1210098e+00 -7.8508729e-01  1.0065572e+00  6.7582607e-02
 -1.1910765e+00  6.9224215e-01  6.0117030e-01 -6.2748283e-01
  1.2348280e+00 -1.5044808e-03  9.5492959e-01  3.0659592e-01
  1.1802912e-01 -9.1637790e-02 -1.6439561e+00 -7.7370048e-02
 -1.0133082e+00 -5.8224493e-01 -8.4013402e-01 -1.1834688e+00
 -1.1316746e+00  5.2091289e-01  9.9892330e-01 -6.6931647e-01
 -1.1767776e+00 -9.1805851e-01  4.4453895e-01 -6.9456953e-01
 -5.9175825e-01 -1.1713202e+00 -1.5590072e-02  2.8058094e-01
 -6.2748283e-01 -1.6551766e+00 -1.3957030e+00  8.4303319e-01
  2.5067419e-01 -1.5655267e+00 -4.6521845e-01  9.9070776e-01
  4.8951316e-01  7.5335264e-01  1.2971890e-01  3.8323396e-01
  4.3461919e-02 -1.7188153e-01  3.8758129e-01 -6.6591549e-01
  1.0068177e+00  7.9086959e-01  6.9224215e-01  1.7628163e-01
 -1.1828122e+00 -3.4090400e-01  1.8147159e-01  2.3259163e-02
  1.7130512e-01  5.0703287e-02  1.9112188e-01  2.2585338e-01
  2.7337480e-01  1.8267614e-01  9.2491627e-02  2.4395269e-01
 -9.8649293e-02  2.1682113e-01 -2.3335823e-01  1.7732626e-01
  1.5940577e-01 -6.3844550e-01  9.8888350e-01  8.9493608e-01
 -1.1910765e+00 -1.0382584e+00  1.2765006e+00  9.8907292e-01
  1.0087726e+00 -4.2171973e-01  8.8436472e-01  2.9162472e-01
 -1.3997135e-01  3.9387643e-01  2.3546410e-01 -6.8556565e-01
  6.4561963e-02  1.0092670e+00  7.5544417e-02 -2.7621508e-01
 -3.7622583e-01 -6.1745143e-01 -1.3695836e-02 -5.5768245e-01
  7.1012676e-02  3.6459422e-01 -7.4474549e-01  2.8161412e-01
 -2.3078176e-01 -1.0344449e+00 -1.3408065e+00 -2.5040451e-01
 -2.8642806e-01 -6.2586850e-01 -7.8180337e-01 -5.2560306e-01
 -8.4103131e-01 -4.5322216e-01 -9.1011405e-01 -3.1539869e-01
 -1.4490297e-01]
Pearson r: 0.692
MSE: 0.579
Fold 2, k_feat 128
X_train.shape:  (265, 128)
y_pred:  [ 0.98560154  1.0759252   0.90824497  0.75497234  1.0714687   0.7664081
  0.28985107  1.0357295   0.56262994  0.7528416   0.6639247   0.7159772
 -1.6570547   0.95806944 -1.1216346  -0.20216429 -1.1856292  -0.01406515
 -1.1019814   0.41151798 -0.97471774  0.48315334  0.96702754  1.0000147
  0.67603207 -0.21870327  0.6939696   0.35420096  0.59224176  0.44174755
 -0.17526984 -1.0580986   1.0000955  -0.30440146 -0.9220672  -0.52832496
 -0.40421343 -1.2378371   0.9961029   0.9961029   0.6831727   0.6115353
  0.36283636  0.08047366  0.5615418   0.72640204 -1.6570547  -1.6513314
 -0.20908308 -0.229586   -0.5259898  -1.5378332  -1.1069688  -0.20908308
  1.0951566   0.8291193   0.91682255 -0.2016753   0.75497234  0.18758225
 -0.23520494  0.63269365  0.8424977   1.0531098   0.38667822  0.8101989
  0.67553794  0.56503487  0.6874639   0.6923263   0.7663702   0.1042788
  0.30175006  0.62598443  0.19582915  0.28029716  0.7731205   0.8680979
  0.9937259   0.680645   -0.6437157   0.7384485  -0.18217266 -0.05357671
 -0.31194013 -0.35491127 -0.47821623  0.22979808 -1.0199748   0.3735721
  0.2541107   0.29684043  0.6527779   0.06180334  0.1379205   0.19584048
  0.76856506  0.7445538   0.9142188   0.58164597  0.9961029   0.70212364
 -1.1069688  -0.4651708  -1.1297055  -1.095466   -0.9558722  -0.30871147
  0.56010926 -0.15696502  0.79933774 -0.975923    0.16776693 -0.07237923
 -0.6348154  -1.4663918  -0.8743565   0.23327994 -0.6864109  -0.58083874
 -0.55085146 -0.9075141  -1.2251059  -0.36580127 -0.61273384 -0.37256157
 -0.22531152 -0.7239348   0.59708464 -0.21102726  0.04050112  0.46344244]
Pearson r: 0.694
MSE: 0.584
Fold 3, k_feat 128
X_train.shape:  (265, 128)
y_pred:  [ 1.1285386   0.7664551   0.9772348   0.97180086  0.32876986  0.93046945
  0.8456246   0.6418827  -0.9823415  -0.48506168  0.7212314   1.0349433
 -0.9185841  -0.10454428  0.07608503 -0.12389678  0.07608503 -0.9163945
  0.6633107   0.9236129  -0.8489898  -0.9250695  -0.31356785 -0.31508613
 -0.79019284 -0.94933355 -0.5507374  -0.3602729  -0.45456252 -0.48245502
  0.8972301   0.8972301   0.7855428  -0.64238244 -0.00214267 -0.7025525
  0.8094173  -0.80857754 -0.0223496   0.53128093 -0.48167115  0.6632051
  0.6632051   0.3765748   0.889422   -0.5651591   0.78139716  0.9074531
  0.7720651   1.1775146   0.41434485  0.78917104  0.8181576   0.41449147
  0.9772348   0.20654988 -0.51285064  0.54958636  0.5629888  -0.77932227
  0.6412634  -0.21872184  0.9969941   0.07275385  0.13980502  0.25966275
 -0.20939398  0.6195579  -0.13540673 -0.0214414   0.9772348   0.96431774
  0.37079066  0.03030574 -0.98640573  0.3767665  -0.22383782 -0.38458163
  0.37503058  0.26516128  0.37202722  0.21921456  0.30320245 -0.44897115
  0.50224334 -0.40739396  0.7500574  -0.3016902   0.05061442  0.45962697
 -0.2330381   0.22938073 -0.41795743  0.42644817 -0.9924159  -1.0884315
 -0.92072606 -1.0884315  -0.19016236 -0.4956671   0.8968641   0.8660429
  0.8250974   0.28417593  0.8324041  -0.689036    0.8322553  -0.64238244
  0.1465959  -0.15356088  0.11940467 -1.1707988   0.12988758 -1.0517412
 -0.8023431  -0.6935706  -0.3881178   0.26020914 -0.41477868 -0.7151647
 -0.39661968  0.19857705  0.9660689  -0.47573647 -1.07757    -0.5086495
 -1.0824475  -0.30993083  0.09991848 -0.47213298 -0.2412729  -0.5807455 ]
Pearson r: 0.667
MSE: 0.444
Average pearson_r accross all folds = 0.6842498575398791
Average mse accross all folds = 0.5356584787368774
Fold 1, k_feat 256
X_train.shape:  (264, 256)
y_pred:  [ 1.0140412   1.0080496   0.9274055   0.9879966   0.9985235   1.0507478
  1.0352403   0.9332942   0.9939108   0.9799142   0.56097484  0.77586555
 -0.8215437  -1.5834534  -1.8170308   0.6084186   0.7504294   0.7621695
 -0.31801784  0.11961061  0.2493071   1.0644113  -0.8521179  -0.64842725
 -1.1826915  -0.60810304  0.9806173   0.07047337 -1.1988738   0.6803608
  0.58668005 -0.28208128  1.2818079   0.16165757  0.9380635   0.6976603
 -0.15024805 -0.19550395 -1.741637    0.07784212 -0.49472696 -0.32766858
 -1.0155447  -0.97414774 -1.1357802   0.5240221   0.9426378  -0.8784239
 -1.3052303  -0.9825957   0.71985507 -0.30829617 -0.7097184  -0.9487071
 -0.01251006  0.5184041  -0.6516845  -1.6745485  -1.6526408   0.91432464
  0.01011229 -1.6754067  -0.9233205   0.96587396  0.25795048  0.86471105
 -0.00718492  0.24178028 -0.31124547 -0.29835996  0.32530665 -0.23474148
  0.9912498   0.6775062   0.6803608   0.3908081  -1.1779246   0.09043181
  0.08634019 -0.20583495  0.19928235  0.11680722  0.0946157   0.24253017
  0.29424196  0.1852758  -0.2299268  -0.01311684 -0.08212572  0.24411696
 -0.23281416 -0.01063824  0.23790497 -0.3274273   0.9331881   0.8190495
 -1.1866025  -1.03376     1.1809365   0.8667941   0.9412769  -0.6395552
  0.8918376   0.09744751 -0.7208413   0.28272218  0.52889574 -0.29350176
 -0.06401026  0.96624255  0.2318781  -0.25983205 -0.34072492 -0.8212108
 -0.0363127  -0.5082733  -0.05671376  0.19565111 -0.65992916  0.2493788
 -0.2715566  -0.86988413 -1.0874689  -0.11159825 -0.48418224 -0.93706936
 -0.8152779  -0.6189147  -0.7726372   0.04628849 -1.2499385   0.11879683
 -0.7025124 ]
Pearson r: 0.691
MSE: 0.579
Fold 2, k_feat 256
X_train.shape:  (265, 256)
y_pred:  [ 1.1006093   1.3094329   1.1051431   0.85180855  1.4210075   0.86953115
  0.02192163  1.4002558   0.80601823  1.134364    0.5683216   0.6435257
 -1.8136737   1.2731754  -1.1000524  -0.2276184  -0.98099667  0.04032868
 -0.96072316  0.67440736 -1.0532753   0.4051733   1.2189637   0.72474277
  0.802189   -0.21045715  0.23215008  0.17800438  0.45018244  0.7636845
 -0.04295021 -0.975003    0.95120263 -0.4796235  -0.9313908  -0.4659726
 -0.34659296 -1.2459586   1.221088    1.2130295   0.46137035  0.80288863
  0.16912651 -0.08081228  0.754918    0.6287643  -1.893985   -1.8120244
 -0.27198446 -0.04973781 -0.7096346  -1.758048   -1.1082063  -0.26449364
  1.1759938   0.7708185   1.2137512  -0.5269962   0.9457195  -0.05814892
 -0.07702237  0.7806014   1.1605884   1.254311    0.22295475  0.6537403
  0.6048504   0.5873122   0.47491515  0.53231287  0.8524221   0.25577033
  0.11128259  0.8964052   0.09923363  0.42519438  0.9676492   0.9702532
  0.90955734  0.5533941  -0.659324    0.50195944  0.4136064  -0.28827256
 -0.24419212 -0.08625203 -0.29678684  0.08593881 -1.3509767   0.1780442
  0.3495624  -0.1346345   0.40396655 -0.441709    0.2502172   0.06202662
  0.87246966  0.80031335  0.93237376  0.5003849   1.4207126   1.1557509
 -1.0588751  -0.190444   -1.0618649  -1.0462006  -1.0414432  -0.63559985
  0.79098725 -0.40464315  0.7469524  -0.7683795  -0.11242664 -0.8978923
 -0.659181   -1.4714484  -1.0705228   0.11258322 -0.64885116 -0.3635432
 -0.4313742  -1.1315134  -1.3382969  -0.11544132 -0.66046894 -0.11851209
  0.18058884 -0.8123629   0.6345496  -0.67652416  0.12093389  0.5727534 ]
Pearson r: 0.684
MSE: 0.609
Fold 3, k_feat 256
X_train.shape:  (265, 256)
y_pred:  [ 1.1717522   0.79262185  1.0176547   0.7865145   0.31583926  0.9866214
  1.0200602   0.5364014  -1.1638967  -0.8532698   0.6800153   1.067174
 -1.0145772   0.21570405  0.03247112  0.1683527   0.03247112 -1.0038117
  0.8026482   0.9268203  -1.3898202  -0.8182646  -0.49556205 -0.0106923
 -0.5887735  -0.7656126  -0.8135505  -0.3344021  -0.502828   -0.08455771
  0.93675745  0.8698628   0.8681214  -0.5636023  -0.10936745 -0.41709584
  0.6076877  -0.40883166 -0.2852825   0.6964325  -0.51802015  0.67285347
  0.6702421   0.39992288  0.8312918  -0.58577263  0.80200124  1.0404886
  0.8948047   1.0495577   0.38952175  0.78891754  0.96276426  0.27372184
  1.0907701   0.60839844 -0.53244126  0.55605984  0.55448973 -0.53891677
  0.8571986  -0.2012814   1.1206852   0.15663272  0.37386873  0.57527757
 -0.3947171   0.3823214  -0.36503032 -0.0250423   1.0902872   0.8232856
  0.8349885   0.2513719  -0.6062368   0.50871515  0.06657755 -0.37381473
  0.36747918  0.2535338   0.3332977   0.3511447   0.43814674 -0.9743732
  0.06744379 -0.41506174  1.0333925  -0.24779452  0.11584848  0.15335205
 -0.20339411  0.27365795 -0.39759484  0.44098088 -0.973263   -0.9609413
 -0.79385287 -0.9455044   0.07835591 -0.6225027   0.7229886   1.0007198
  0.8467858   0.43064377  0.65025806 -1.0851259   0.76485896 -0.55601144
  0.14776096  0.14512369 -0.0142428  -1.5710938   0.05897084 -0.99522734
 -1.2491323  -0.6073177  -0.5843278   0.05672473 -1.1007454  -0.50630045
 -0.1733667   0.4373215   0.86778903 -0.14542545 -0.7173438  -0.8038058
 -1.0263087  -0.54472405  0.3138781  -0.23188266 -0.49784195 -0.911396  ]
Pearson r: 0.650
MSE: 0.471
Average pearson_r accross all folds = 0.6750302749086168
Average mse accross all folds = 0.5530590415000916
Fold 1, k_feat 512
X_train.shape:  (264, 512)
y_pred:  [ 1.113775    1.3068596   0.9711188   0.9693632   0.86546147  1.0973148
  1.139243    0.98313546  1.1249826   1.0375221   0.20674936  0.68072397
 -0.6383124  -1.557659   -1.6098801  -0.0159826   0.82711625  0.7748642
 -0.41287374  0.10794218  0.29253882  1.2889391  -1.1731243  -0.5159844
 -1.0644102  -0.7790832   0.9092866  -0.5235408  -0.9605768   0.8006891
  0.83096933 -0.21246943  1.1894375  -0.09991448  0.9677831   0.5448687
 -0.4300837  -0.20955375 -1.8136977   0.24636929 -0.10181086 -0.48977977
 -0.84416926 -1.0645101  -1.4663923   0.29819763  0.82897186 -0.5107789
 -1.448426   -1.616347    0.67740625 -0.30608088 -0.5138859  -0.8584879
  0.0382238   0.5291209  -0.704453   -1.640183   -1.7413138   0.96924746
  0.24368869 -1.8552493  -1.117442    1.1546419  -0.03928426  0.25933498
 -0.02030149  0.27989852 -0.70616245 -0.31947172  0.23988132 -0.35182792
  1.2249068   0.859784    0.8006891  -0.0805719  -0.8765978  -0.12585607
  0.02502    -0.30585766  0.01577848  0.0203439   0.19234528  0.6770373
  0.7994927  -0.00519353 -0.18950379 -0.39048177 -0.09777191  0.35305566
 -0.43723106 -0.16055797  0.24594231 -0.52998275  0.84076726  0.9431236
 -1.0653548  -0.6277498   1.3611833   0.9095409   0.73621607 -0.71476716
  0.7438526  -0.14700666 -0.56997466  0.46419036 -0.03694016 -0.17812954
  0.07949904  1.0393339   0.35432225  0.01889932  0.11507981 -0.60015535
 -0.48804516 -1.1199732  -0.03895295 -0.08709043 -1.6571805   0.6291106
 -0.17580807 -0.6458124  -1.2168409  -0.10858613 -0.18618159 -0.9242476
 -1.2975584  -0.40137166 -0.64920837 -0.09038183 -1.567565   -0.81445
 -0.6924653 ]
Pearson r: 0.686
MSE: 0.592
Fold 2, k_feat 512
X_train.shape:  (265, 512)
y_pred:  [ 1.2272438   1.3556136   1.3632828   1.0000821   1.3613919   0.3783964
 -0.7508072   1.5431551   0.68231356  0.5790285   0.3155316   0.61630344
 -1.9904617   1.3794092  -1.0476272  -0.31078386 -1.0638961  -0.3121577
 -0.9874341   0.5123142  -1.1799073  -0.3475536   1.0907489   1.0200084
  0.4901998  -0.5194607   0.14347112 -0.00683892 -0.03773761  0.35376096
  0.11874163 -0.9778551   0.6983391  -0.57602084 -1.6204274  -0.84489536
 -0.47226483 -0.7592829   1.3499678   1.2895514   0.63150334  0.86364615
 -0.04110992 -0.1025787   0.7105007   0.5082053  -2.1826687  -2.0129573
 -0.9926459   0.07468009 -0.77644897 -1.9200604  -0.7132375  -0.8618762
  1.0570413   0.92057455  1.0704061  -0.40448183  1.2774886  -0.16071397
 -0.10555518  0.28272963  1.3427726   1.0845674   0.12560594  0.70619905
  1.0920757   0.7551565   0.684875    0.7602279   1.3693386  -0.17301357
  0.0585146   1.0578233   0.2226156   0.51518846  1.1324419   1.149537
  1.1422559   0.5284771  -0.42589003  0.48203337 -0.07929718 -0.35443044
 -0.35493147  0.0043242  -0.44122976 -0.2866066  -1.3822162   0.280316
  0.29330993 -0.68479204 -0.21539474 -0.37618482  0.45300186 -0.00338697
  0.70934033  0.47730315  0.60200226  0.10715497  1.6640784   1.30679
 -0.95127773 -0.8514488  -0.8689304  -0.7990339  -0.9178083  -1.2304978
  1.1910795  -0.7359596   1.2145368  -0.7450204   0.18732047 -0.45461333
 -0.77627033 -1.3635583  -1.4206616   0.22789276 -1.1934878  -0.8838991
 -0.57080287 -1.0851434  -1.2577999   0.27556586 -0.5400014  -0.9420949
  0.02849436 -0.9380236   0.70773566 -1.0399989   0.06439376  1.008382  ]
Pearson r: 0.645
MSE: 0.701
Fold 3, k_feat 512
X_train.shape:  (265, 512)
y_pred:  [ 1.420543    1.1920156   1.3434219   0.9683878   0.73564523  1.1539953
  0.93560416  0.414581   -1.0877337  -0.9736955   0.95478207  1.1578306
 -0.75395286 -0.2755502  -0.0030638  -0.2886114  -0.0030638  -1.1123147
  0.6358832   0.6544686  -1.8546681  -0.8903013  -0.7410198   0.8389073
 -0.7543727  -0.8954481  -0.72016466 -0.42129636 -0.7287362  -0.14108929
  0.8714163   0.98931664  0.9553029  -0.6380665  -0.44832712 -0.18540496
  0.33075833 -0.8250163  -0.63050354  0.71301246 -1.0285314   0.47339112
  0.5586461   0.75659126  0.8588149  -0.51528245  0.73694336  0.94809407
  0.35384643  0.88280016  0.01153022  0.7506165   1.1032453   0.0367174
  0.56172985  0.9540958  -0.44489163  0.5930462   0.58830047 -0.67975825
  1.162475   -0.8913944   1.4549303   0.28129143  0.67321455  0.8993605
 -0.6611775   0.14124413 -0.22385688 -0.38393283  0.90824014  0.70821077
  1.0520033   0.40928483 -0.61983544  0.8023136  -0.4298072  -0.6603978
  0.19706134 -0.12669387  0.16436689  0.4278984   0.4580586  -1.1773542
  0.37674522 -0.56987435  1.3006632  -0.22798719 -0.0767239  -0.53335756
 -0.02254343  0.19740163 -0.73761386  0.394256   -0.97927254 -0.98166823
 -0.8408702  -1.0881363  -0.14925797 -0.29797873  0.8629733   0.7432169
  1.1700985   1.1307458   0.79071    -0.88870317  0.54613656 -0.66453415
  0.52545977  0.2213882  -0.16259453 -1.4687959   0.05167118 -0.80415976
 -1.5891973  -0.51025325 -0.45103794 -0.0036722  -1.3282315  -0.78297096
  0.89571303  0.70415944  0.94038206  0.06424622 -0.80180424 -0.46043658
 -0.6054081  -0.06296916  0.5915931  -0.4999659   0.16411667 -0.3059268 ]
Pearson r: 0.649
MSE: 0.495
Average pearson_r accross all folds = 0.6601985915859215
Average mse accross all folds = 0.5961598753929138
Fold 1, k_feat 1024
X_train.shape:  (264, 1024)
y_pred:  [ 0.8455267   1.2370523   0.9604361   0.9183922   1.1102321   0.9908285
  0.88872814  0.7781124   0.8405771   0.6434574   0.48864508  0.6008316
 -0.9277464  -1.1215397  -1.4874972   0.20114386  0.9603739   1.4103836
 -1.5401654  -0.41354924  0.2618671   0.96923494 -1.9676452  -0.47154516
 -0.92263544 -0.6025437   1.2766354  -0.84797645 -0.9534685   0.7770134
  0.4716326   0.03324205  0.9490876  -0.2708671   0.6475698   0.8229461
 -0.66148144 -0.44743615 -1.9203548   0.0626933   0.49418533 -0.35970914
 -0.7874147  -1.1129782  -1.7555424   0.22253448  0.75110996  0.14687091
 -1.5178034  -1.530515    0.5806165   0.04242992 -0.784367   -1.0415647
  0.5180706   0.3349796  -0.49124673 -1.7909912  -1.3159034   0.6713388
  0.25425965 -1.8114243  -0.23754081  1.5677768  -0.6338972   0.02870059
 -0.08788115 -0.09536451 -0.7597552  -0.25702122  0.37044418 -0.6327786
  1.2231568   0.5245632   0.78467834  0.81347895 -0.7285954  -0.25149605
  0.192267   -0.48037356  0.00364131  0.28733385  0.15258467  0.29196084
  0.6720356  -0.7196183   0.09480548 -0.27709472 -0.26194432  0.151865
 -0.5752614   0.25406414 -0.1107215  -0.9626241   0.88829947  0.7814399
 -1.107512   -0.5069244   1.3032966   1.0191153   0.6004665  -0.70915735
  0.712965   -0.04107106 -0.85683334  0.03616226  0.33579808 -0.26785883
  0.13947904  1.0963191  -0.32220015 -0.2708197  -0.26140755 -0.6945807
 -1.0344156  -1.1843102  -0.49462497 -0.6677298  -1.4475216   0.34373295
 -0.3209867  -0.6403803  -1.1655064  -0.08310485 -0.41612116 -0.8904776
 -1.443006    0.5735868  -0.31651565 -0.14038566 -1.5665721  -1.4714992
 -0.05022222]
Pearson r: 0.663
MSE: 0.639
Fold 2, k_feat 1024
X_train.shape:  (265, 1024)
y_pred:  [ 1.1212292   1.4991517   1.6008115   1.0732274   1.5136149   0.91093403
 -0.82678473  1.8685002   1.2446425   1.2790387   0.62973446  0.57785875
 -1.8176076   1.2757354  -1.4064043  -0.46496522 -1.9290452   0.02348611
 -1.0192747   0.9246016  -1.2929447   0.36559927  1.168133    1.2123997
  0.6263149  -0.6522591  -0.04529291  0.03783083  0.24915344  1.2355838
  0.03969118 -0.9088778   0.4722216   0.01461816 -1.6572912  -0.31407565
 -0.7491612  -0.9882585   1.7770791   1.4403389   0.36346787  0.48902166
  0.47696942 -0.01181769  1.4286172   0.6175935  -1.885392   -1.8944538
 -0.38703403 -0.22382084 -0.59756047 -1.8530109  -0.78539985 -0.2796296
  0.8182406   0.90228707  0.7214679  -0.6266235   1.3256638  -0.7435495
 -0.01664543  0.46712714  1.2274756   0.8403587   0.03155181  1.155684
  0.41750252  0.6009599   0.39005345  1.1988978   1.7774417   0.07886896
 -0.02818438  1.2066348   0.04841614  0.36648786  1.301322    1.1419158
  1.2654552   0.0375894  -0.38846073  0.33405876 -0.26025745 -0.1719993
 -0.5152835  -0.24281907 -0.3208067  -0.6119747  -1.2638671   0.25222456
  0.28295875 -0.25796887  0.23902941 -0.5030247  -0.00667891  0.06879604
  0.74913746  0.33851993  0.65845793  0.53627795  1.8302131   1.1095238
 -0.9457579  -1.5368042  -0.8743064  -0.9141001   0.19641775 -1.5073555
  1.2748287  -0.56740016  1.2872565  -1.2425084  -0.23778018 -0.18491028
 -0.81708086 -2.0379012  -1.343879    0.7819187  -1.36232    -0.29126844
 -0.70378643 -1.4393332  -0.5489734  -0.01241967 -0.7442548  -1.010099
 -0.29500648 -0.660948    1.3157794  -0.14108904  0.01147816  1.0358901 ]
Pearson r: 0.676
MSE: 0.670
Fold 3, k_feat 1024
X_train.shape:  (265, 1024)
y_pred:  [ 1.4090183   1.2913823   1.3266778   1.2849452   1.2193677   1.5002062
  1.118254    0.9133412  -0.9200435  -0.95922923  1.1474032   1.5662556
 -1.075357    0.6990926   0.14777032  0.7088141   0.0890494  -1.004806
  0.8645981   0.41304386 -2.3430274  -0.5547067  -1.0644392   1.0638199
 -0.893461   -0.9505982  -1.1211898  -0.34703666 -0.63671887  0.44029176
  0.73707455  1.0944285   0.6908488  -0.5150918  -0.5056498  -0.6004152
  0.25522798 -0.26612034 -0.82892853  0.5106067  -0.5277905   0.42746973
  0.5230989   0.8311992   1.2089591  -0.59426683  0.67012566  1.0787153
  0.48795182  0.9771007   0.05123812  0.2363854   1.6920252   0.37724996
  0.6241306   0.6745969  -0.5012856   0.5344445   0.537484   -0.6345556
  1.7328887  -0.9406116   1.8702493   0.8245397   0.41741073  1.1451893
 -0.340453    0.5282333   0.08461678 -0.41531402  0.9426361   0.50253314
  0.9261915   0.7350653  -0.6846973   0.4321661  -0.32032397 -0.36835656
  0.2208727  -0.07138208  0.20950776  0.5505517   0.44459617 -1.296687
  0.5161623  -0.51430833  1.3789449  -0.05917448 -0.23712753 -0.38097677
 -0.28606495  0.19329637 -0.94594747  0.13622373 -0.8234123  -0.97590977
 -0.70844674 -0.83698237  0.10162932 -0.50209725  0.4628244   1.0059686
  1.4014652   0.9100352   0.8559634  -0.76839006  0.53269696 -0.5395997
  0.36331087 -0.02046931  0.2552209  -2.383747    0.08092996 -0.14898098
 -1.7801633  -0.93772477 -0.5895009   0.46322173 -0.41547155 -0.7059189
  0.6020613   0.6082984   1.2754214  -0.15199296 -0.5943336  -0.3260766
 -0.69726145 -0.6832226   0.53537464 -0.46506268  0.01070178 -0.10085821]
Pearson r: 0.656
MSE: 0.524
Average pearson_r accross all folds = 0.6651302062356576
Average mse accross all folds = 0.6112667918205261
Fold 1, k_feat 2048
X_train.shape:  (264, 2048)
y_pred:  [ 0.8544229   1.632923    1.3686858   1.5272967   1.1558255   0.6723999
  0.8091346   0.61810195  0.7810031   0.6113092   0.11371469  0.6734632
 -0.84990096 -1.1546435  -1.4239305   0.5228399   1.121663    1.2281722
 -1.3808606   0.3327645   0.10729086  0.82332647 -0.876594   -0.88822675
 -0.9545977  -0.8183122   1.0063609  -0.6135913  -0.7924316   0.47109854
  0.08867455 -0.28065646  0.5374359   0.09154701  0.8039273   0.24718797
 -0.553157   -0.94112045 -1.5959513  -0.15878904  0.19278479 -0.61055124
 -0.3607837  -0.82298446 -2.404996    0.702644    0.66008794  0.13205111
 -1.4218256  -1.6664075   0.7933632   0.31523812 -0.9952724  -1.0173477
  0.9375056   0.48147237 -0.6995244  -1.7982571  -1.1004552   0.5724567
  0.48129666 -1.5361265   0.24640739  1.4817196  -0.4600798   0.39934027
  0.2477175  -0.01880848 -0.40020084 -0.16671348  0.10720348 -0.58704793
  0.99970233  0.11180341  0.428424    0.59946764 -0.9011835  -0.6611309
  0.06731832 -0.07697535 -0.07837892  0.26866496  0.2545296   0.43817127
 -0.24814963 -1.0726991   0.11904097 -0.2424972  -0.62375855  0.12010109
  0.1886872   0.34571683 -0.0567497  -0.8626739   0.98278177  0.37884223
 -1.0229692  -0.631644    1.5558788   0.5822102   0.7081176  -0.6797862
 -0.30862725 -0.5908642  -0.73933065 -0.6968645   0.6693717  -0.36644137
  0.02550709  0.6869575  -0.5926032  -0.58253014  0.36392105 -1.1528158
 -1.2578311  -0.5798383  -1.4928715  -0.3833959  -1.2622154   1.1312374
 -0.96143913 -0.2522421  -1.2943993  -0.09920871 -0.9937952  -1.0938145
 -0.8678967  -0.18974483  0.39138567 -0.9997874  -1.7382543  -0.889103
 -0.16241086]
Pearson r: 0.653
MSE: 0.659
Fold 2, k_feat 2048
X_train.shape:  (265, 2048)
y_pred:  [ 1.1172391   1.6828297   1.6547343   1.2686957   1.5470704   1.4548739
 -0.86181355  1.8885168   1.5209221   0.90728843  0.62067974  0.6911535
 -1.749527    1.0038254  -1.2514961  -0.08738697 -1.6538519  -0.49133623
 -1.1997995   0.64121306 -1.310134    0.77269816  1.0907518   1.3239056
  0.6825925  -1.0287405  -0.2740302  -0.22254908 -0.13768399  1.4693323
  0.41332138 -1.0447358   0.8547578   0.04661787 -1.988576   -0.760957
 -0.8949865  -1.0430375   2.201212    1.6049799   0.55963683  0.653239
  1.1831638   0.0482794   1.4915715   0.57492995 -1.6665138  -1.7031318
  0.31211329 -0.336452   -0.67275286 -1.5029447  -0.9493313   0.2620349
  0.6143787   1.2860922   1.0175457  -0.38705575  1.1296716  -0.80895615
  0.2358135   0.68672216  1.2533485   1.6756984  -0.27416182  1.3408266
  0.9418136   0.63693726  0.51910186  1.6864041   1.907298   -0.1686796
  0.4681803   1.33315     0.01861274  0.04979777  1.2217866   1.1755679
  1.2237661   0.33843887  0.16254902  0.27371883 -0.33498776 -0.07349205
 -0.08048499 -0.23877692  0.02310371 -0.76320195 -0.7418798   0.14714861
 -0.15436399 -0.01835883  0.13966441 -0.510005    0.08101296  0.26485276
  0.27490103  0.5149071   1.3595144   0.9078326   2.1910806   1.0662011
 -0.96331465 -1.7867388  -0.4971348  -1.1470287  -0.12592971 -1.6310629
  1.1288111  -0.7307575   1.325056   -0.9871521  -0.59093225 -0.48343575
 -1.2754039  -2.0899048  -1.3101767   0.8741344  -1.4513751  -0.8252021
 -1.2582057  -1.9524558  -1.7022315  -0.36228418 -0.73447835 -1.1414146
 -1.23847     0.11406398  1.0260645  -0.36885428  0.66107786  0.8788444 ]
Pearson r: 0.712
MSE: 0.645
Fold 3, k_feat 2048
X_train.shape:  (265, 2048)
y_pred:  [ 1.3944955   1.615752    1.2075187   1.528429    1.8379638   1.5996987
  1.6907055   0.7735586  -0.8765036  -0.88303137  1.4065027   1.5422477
 -1.230738    0.55270576 -0.02006963  0.43702206 -0.06522623 -1.0193666
  0.6771369   0.4300728  -2.4425254  -1.024314   -1.1291734   0.505576
 -0.5116799  -0.94021106 -0.866893   -0.3314655  -0.41156635  0.09884086
  0.39038047  1.3271712   0.4666418   0.05208778 -0.5993435  -0.3329955
 -0.04224756 -0.9488238  -0.7347386   0.5275445  -0.2850105   0.45792213
  0.48945954  0.96679175  0.90678537 -0.3841887   0.7225177   0.7512338
  0.32220164  1.103091   -0.24408495  0.05143532  1.808455    0.07520226
  0.11314812  0.82091916 -0.5388485   0.65009046  0.65163577 -0.7772622
  1.7153146  -0.11690065  2.4690213   0.79498005  0.65832293  0.6793381
 -0.2770888   0.27486172 -0.39583746 -0.4985953   1.003817   -0.1708375
  1.2890413   0.46640202 -0.75511956  0.33106974 -0.6088325  -0.55476594
 -0.02094576 -0.29854816 -0.01472324  0.32328215  0.31534502 -0.70526123
  0.6585245  -0.21627468  1.4599867   0.21999803 -0.44779274 -0.6706171
 -0.5665672  -0.00764048 -0.66492915  0.24425521 -1.1200415  -0.89428926
 -0.83373237 -0.85696423  0.23165771  0.16221657  0.2787563   0.8900571
  1.290044    0.6257976   1.1682527  -0.75988245  0.41428664 -0.01143631
  0.16975614  0.09065697  0.18118289 -1.9588876   0.40591815 -0.13072792
 -0.96101177 -0.9736135   0.05850989  0.5511918  -0.5518365  -1.2576016
  1.0931565   0.6767435   1.3693671   0.4177843  -0.4859581   0.1427727
 -0.496218   -0.39976457  0.4813302  -0.40065965 -0.19171616 -0.3098317 ]
Pearson r: 0.662
MSE: 0.520
Average pearson_r accross all folds = 0.6755967796352281
Average mse accross all folds = 0.6081694960594177
Fold 1, k_feat 4096
X_train.shape:  (264, 4096)
y_pred:  [ 0.93204594  1.3340557   1.4720771   1.7439368   1.4144695   0.777982
  0.87303114  1.0158844   0.8705511   0.2577597  -0.11923695  0.86466265
 -0.7073134  -1.026684   -1.5506338   1.140065    0.6010537   0.9602754
 -0.57777154 -0.26780868 -0.37720072  0.9284699  -0.34068465 -1.1319292
 -0.79120976 -0.80580616  1.2613928  -0.76770127 -0.8543289   0.2533679
 -0.12801313 -0.23102641  0.76010036 -0.11350179  0.7334175  -0.21331978
 -0.6129771  -1.1446533  -1.4646791  -0.31072843 -0.52727914 -0.12814534
 -0.66902316 -0.86804587 -1.5289814   0.4308436   0.30978298  0.08292425
 -1.3964789  -1.3725077   0.10232711  0.46457422 -0.7502844  -0.6677048
  0.85596347  0.56135154 -0.82460076 -1.8588321  -1.1643751   0.02799189
  0.5850897  -1.5594983   0.2807269   1.6691811  -0.5355956   0.52510214
 -0.19898212  0.13395262 -0.52875555 -0.35002327  0.08857918 -0.59099644
  0.7636738   0.2448541   0.28900647  0.12694502 -0.9723158  -0.46203232
 -0.01577938  0.5804367  -0.00250721  0.2919743   0.50887346  0.5032518
  0.19994915 -0.8230525  -0.16046667  0.06795585 -0.24641073  0.00941622
  0.05578244  0.3051089   0.37990916 -0.48680067  0.8245828   0.74825764
 -0.94354796 -0.80321586  1.5916927   0.8785634   0.7623255  -0.5773705
 -0.40864563 -0.57591003 -0.9606805  -0.17619526  0.31134796 -0.69328177
 -0.09886062  0.20646107 -0.05784059 -0.18426633  0.32791424 -1.2060125
 -0.7783797  -0.9882548  -1.2599254   0.01233959 -0.77508503  0.23313093
 -0.43082666 -0.81958514 -0.9990608  -0.05431664 -0.8232476  -0.98889744
 -1.089741    0.00354671  0.55389404 -1.322348   -0.8063557  -1.2796866
 -0.21721208]
Pearson r: 0.712
MSE: 0.550
Fold 2, k_feat 4096
X_train.shape:  (265, 4096)
y_pred:  [ 1.4386797e+00  1.8405111e+00  1.6356151e+00  1.2753999e+00
  1.3244700e+00  1.5650134e+00 -1.4017098e+00  1.5276551e+00
  8.6744785e-01  1.0791671e+00  8.5215855e-01  8.3514798e-01
 -1.6378154e+00  8.5194468e-01 -1.0457537e+00 -4.7040635e-01
 -1.9082968e+00 -4.0932029e-01 -1.0715369e+00  1.1962166e+00
 -9.6397221e-01  1.3827372e-01  8.3368635e-01  1.0191110e+00
  6.9896293e-01 -1.2340102e+00 -3.0467880e-01 -2.2961271e-01
 -5.3816390e-01  7.7836215e-02  6.7820847e-02 -8.7314844e-01
 -6.0493469e-02  4.6961188e-02 -2.2762659e+00 -3.8979673e-01
 -3.3981642e-01 -1.0463761e+00  2.8208926e+00  1.8393791e+00
  5.7818866e-01  6.0751748e-01  2.2583222e-01  4.3901205e-03
  7.6663351e-01  5.5822349e-01 -1.5178208e+00 -1.5376294e+00
  5.7537103e-01 -5.9274793e-02 -6.5952778e-01 -1.6917695e+00
 -9.9751842e-01  5.0598800e-01  6.9993794e-01  1.0838614e+00
  1.1247890e+00 -4.9273908e-01  1.0454683e+00 -9.6932244e-01
  8.9153886e-02  1.0914648e+00  1.2588553e+00  1.0917354e+00
 -1.2116444e-01  1.8105869e+00  5.1649070e-01  6.8959606e-01
  5.1506460e-01  1.2821283e+00  2.2956731e+00  2.0769131e-01
  6.3248754e-01  1.3771608e+00 -6.6919208e-02 -4.1231012e-01
  1.1067814e+00  1.1329536e+00  1.0209668e+00 -1.5852916e-01
  4.1579163e-01  2.2418475e-01 -6.4891529e-01 -2.8842002e-01
  2.0159668e-01 -2.4928159e-01 -2.1241939e-01 -7.9729491e-01
 -6.8499327e-01  6.4359593e-01 -6.5514326e-02 -3.3170527e-01
  3.8751984e-01 -6.8376184e-01 -3.2786024e-01  8.1338418e-01
 -1.7005515e-01  7.7271461e-01  9.9910116e-01  2.5294185e-01
  1.7750392e+00  7.7196097e-01 -7.9931676e-01 -1.2076802e+00
 -6.8978840e-01 -1.0752250e+00  4.4073665e-01 -1.2792313e+00
  1.1142187e+00 -7.2990346e-01  1.3779676e+00 -1.4512914e+00
 -7.4067199e-01 -4.1610360e-02 -1.0042362e+00 -1.9502932e+00
 -1.1680115e+00  2.0779324e-01 -1.1164615e+00 -1.3188124e-03
 -7.1880084e-01 -1.8574579e+00 -1.7456594e+00 -8.1960976e-01
 -5.2580655e-01 -4.6336722e-01 -1.0011084e+00  9.6243978e-02
  1.0873665e+00 -7.1033716e-02  5.2529097e-01  8.0546808e-01]
Pearson r: 0.754
MSE: 0.528
Fold 3, k_feat 4096
X_train.shape:  (265, 4096)
y_pred:  [ 1.324662    1.7965264   1.5794148   1.892144    2.476486    1.3658972
  1.9922371   0.8848075  -0.8909064  -0.12490743  1.3226116   1.3242872
 -0.9957009   0.1298626   0.15742844  0.04619247  0.12306994 -1.0907981
  0.74519724  0.46562248 -1.4984636  -0.77504116 -1.2315996   0.34682125
 -0.4029513  -1.0092137  -1.1177394  -0.3648222  -1.0256248   0.06013626
  0.4203573   1.1092093   0.3544324  -0.01695424 -0.81978565 -0.13668436
 -0.07555383 -0.78991383 -1.100483    0.7938903  -0.34571642  0.603136
  0.6175149   0.99948555  0.37104207 -0.19418484  0.8326692   1.0432916
  0.63066024  1.5516982  -0.06436425  0.13171977  0.9949388  -0.39120132
  0.4596805   0.45458692 -0.5444302   0.5843614   0.5882445  -0.6201628
  1.4586203  -0.04093415  3.0885005   1.0920808   0.7013959   0.71248645
 -0.6293332  -0.15370804 -1.1443448  -0.5077463   1.0051184   0.11995035
  1.3312707  -0.01910943 -0.8320008   0.48302883 -0.29985768 -0.67523485
  0.02443606 -0.12617189  0.0323469   0.19182712  0.32051235 -0.37403697
  0.4497277  -0.2405439   1.108043    0.15059525 -0.01412362 -0.6552753
 -0.47180766  0.12565583 -0.8814866  -0.05096465 -0.84733194 -0.81641525
 -0.6891925  -1.0834632   0.03140563 -0.18483967  0.0225547   0.8718385
  0.8830468   0.25097126  1.5515561  -0.6336486   0.8752423  -0.01350695
 -0.04291683 -0.14944261 -0.5487549  -1.8080742  -0.7893105  -0.29070932
 -1.4211628  -0.59718436 -0.03737706  0.535899   -0.06940991 -0.9760591
  0.6935827   0.8190021   1.2244124   0.08952689 -0.6989413  -0.7254955
 -0.5711357  -0.22238594  0.42234367 -0.6880589  -0.21476954  0.2819708 ]
Pearson r: 0.730
MSE: 0.420
Average pearson_r accross all folds = 0.7320028166884249
Average mse accross all folds = 0.499239444732666
Fold 1, k_feat 8192
X_train.shape:  (264, 8192)
y_pred:  [ 9.64030504e-01  1.72381234e+00  1.79259729e+00  1.66873574e+00
  1.24356675e+00  4.84976530e-01  4.63583708e-01  6.77362680e-01
  6.00484133e-01  1.90622091e-01  2.84615278e-01  1.07857084e+00
 -9.96891201e-01 -1.14375424e+00 -1.56644380e+00  7.98028708e-01
  1.44898534e-01  1.02751565e+00 -8.07380974e-01 -6.01522207e-01
 -4.87172365e-01  4.21128273e-01 -6.32009864e-01 -6.84840024e-01
 -9.30521011e-01 -9.09409165e-01  1.43432188e+00 -1.10021424e+00
 -1.02339053e+00  1.68277860e-01 -1.12080455e-01 -4.06337738e-01
  9.19081450e-01  1.60836697e-01  6.30119562e-01 -2.15912461e-01
 -3.62142801e-01 -1.09246373e+00 -1.46506965e+00 -2.38507152e-01
 -8.06625307e-01  1.56841278e-02 -7.07253456e-01 -9.16152000e-01
 -1.48470485e+00  1.70885801e-01  1.18052363e-01 -2.96407223e-01
 -1.20240259e+00 -1.29465950e+00  3.56439233e-01  7.36638308e-02
 -7.11328268e-01 -5.44226825e-01  8.76201868e-01  6.15699053e-01
 -8.05293083e-01 -1.94487715e+00 -1.11590743e+00  4.70191002e-01
  6.24428988e-01 -1.59321320e+00 -1.62861347e-02  1.37389803e+00
 -4.67259169e-01  3.80521774e-01  1.68008089e-01 -4.13942337e-02
 -4.77034569e-01 -4.14521933e-01 -3.04350257e-01 -6.72760606e-01
  6.03847980e-01  5.74757576e-01  1.98824406e-01  6.15024567e-03
 -9.32158470e-01 -4.88119602e-01  2.61168838e-01  4.05722976e-01
 -2.39867926e-01  1.18484259e-01  2.71908283e-01  4.56129313e-02
  2.84075737e-04 -7.89578676e-01 -1.64008856e-01  5.91248274e-02
 -2.10432172e-01 -6.82828426e-02 -1.32577777e-01  3.11398983e-01
  1.03089452e-01 -3.95158529e-01  7.49803066e-01  9.37339544e-01
 -9.99725342e-01 -7.57545769e-01  1.26132464e+00  9.20755863e-01
  9.17334318e-01 -5.82192659e-01 -3.73585463e-01 -4.11511779e-01
 -8.04447412e-01 -5.13035774e-01  3.62211108e-01 -3.13596487e-01
 -4.29296374e-01 -1.27673745e-01 -4.60053682e-02 -1.66458130e-01
 -4.60495949e-02 -5.57765126e-01 -4.11715627e-01 -6.88508570e-01
 -1.00586426e+00 -3.61402154e-01 -8.36601436e-01  4.79090929e-01
 -5.29925108e-01 -7.96302140e-01 -1.05000103e+00 -3.05870652e-01
 -1.30071425e+00 -8.70333016e-01 -1.42087257e+00 -4.80788827e-01
  7.68638372e-01 -7.04094827e-01 -5.11339784e-01 -6.57244325e-01
 -4.29352164e-01]
Pearson r: 0.727
MSE: 0.528
Fold 2, k_feat 8192
X_train.shape:  (265, 8192)
y_pred:  [ 0.82995945  1.5551851   1.5254843   1.1897953   1.4095886   1.622576
 -1.363128    0.9927736   0.59841114  0.69865614  0.92337877  0.7639528
 -1.5836878   0.30865914 -1.034339   -0.37661415 -1.7569213  -0.4262346
 -0.9576924   1.1093907  -0.50429213  0.29439908  1.196955    1.347328
  0.6136907  -1.0651901  -0.27929157 -0.15366489 -0.46665293  0.42652684
 -0.3849734  -1.0276917  -0.02744806  0.11476964 -2.3029113  -0.2880013
 -0.6731564  -1.0748591   3.048807    1.7202826   0.69771355  0.8209023
  0.61054724  0.03723437  0.7058242   0.5996569  -1.4020528  -1.526127
  0.20520884  0.165618   -0.37467378 -1.9608047  -0.73488486  0.19285017
  0.88863677  0.981571    1.27234    -0.07975459  1.0722106  -0.7028792
 -0.10577351  1.0454895   1.3574903   1.0273721  -0.20907992  2.005914
  0.68382007  0.77790457  0.6468783   1.320492    2.0023952   0.20184857
  0.63305527  1.1845462  -0.0362758  -0.3302294   1.0069797   1.1879818
  0.85410434  0.05592138  0.4129929   0.21105427 -0.4076575  -0.79656786
  0.35043043 -0.19861853 -0.18011612 -0.6298092  -0.73817754  0.47156852
 -0.06082898 -0.48901016  0.31892306 -0.51242256 -0.503799    0.7379356
  0.07658225  0.82331425  1.1046972   0.33613378  1.9948881   0.9203978
 -0.69776344 -1.387363   -0.6849206  -0.924146   -0.09240144 -0.9491335
  1.0775123  -0.7273907   1.258769   -1.5373815  -0.39417005 -0.23352969
 -0.8384871  -2.2433894  -1.119543   -0.07249612 -1.4958179  -0.14936769
  0.17928714 -1.8262792  -1.1862352  -0.7929918  -0.6295896  -0.38253665
 -1.5425553   0.04721183  0.7448817  -0.08545607  0.3214336   1.0120502 ]
Pearson r: 0.748
MSE: 0.533
Fold 3, k_feat 8192
X_train.shape:  (265, 8192)
y_pred:  [ 1.1408055e+00  1.9147632e+00  1.7315364e+00  1.8839567e+00
  2.1863925e+00  1.3978527e+00  2.2843592e+00  1.3968859e+00
 -9.0422499e-01  3.4103942e-01  1.1292400e+00  1.2494680e+00
 -9.0035295e-01  1.1303300e-01 -4.9495697e-04  7.9455972e-02
 -5.9272766e-02 -9.2260957e-01  3.9679551e-01  2.5441301e-01
 -1.8048391e+00 -7.0927823e-01 -1.1491699e+00  2.8834593e-01
  2.0131326e-01 -9.6656859e-01 -1.1755190e+00 -1.8039030e-01
 -7.7789289e-01  1.6207159e-02  4.2237854e-01  9.7383249e-01
  2.3495221e-01 -1.1568296e-01 -4.7242761e-01 -3.4843040e-01
 -1.5163529e-01 -8.5510814e-01 -1.1017406e+00  6.8063867e-01
 -4.8632079e-01  7.5943661e-01  7.9752481e-01  7.8838694e-01
  3.0527949e-01 -4.5195866e-01  7.2243249e-01  7.6583266e-01
  8.4473825e-01  1.5759294e+00 -2.0653665e-02  7.1734488e-02
  8.1718850e-01 -1.0396522e-01  4.6293306e-01  2.8202486e-01
 -6.5139300e-01  7.2363091e-01  7.6171017e-01 -6.3449657e-01
  1.6136510e+00 -2.3399907e-01  3.3698575e+00  1.1016908e+00
  3.6216378e-01  3.9313817e-01 -4.9140555e-01 -6.6532731e-02
 -1.0871649e+00 -5.1018625e-01  1.0375068e+00  5.7648540e-02
  1.2671306e+00 -4.3120652e-01 -8.5664970e-01  3.0563092e-01
  1.7371517e-01 -6.2402046e-01 -2.8543776e-01 -7.1471334e-02
 -2.1600765e-01  3.4464240e-01  1.4245737e-01 -2.8914237e-01
  4.5804167e-01 -1.7446673e-01  9.0747094e-01  2.4352002e-01
  2.9826331e-01 -6.6280502e-01 -5.7546419e-01  2.2943354e-01
 -7.2523463e-01 -2.5734818e-01 -8.5691065e-01 -8.2252324e-01
 -7.3959589e-01 -1.1159647e+00 -3.3493853e-01 -2.2481620e-01
  1.4907885e-01  1.1793947e+00  5.9614205e-01  3.7656510e-01
  1.3682148e+00 -6.5164208e-01  1.2278460e+00 -1.4439344e-01
 -2.1851182e-02 -1.9286609e-01 -6.0353518e-01 -1.8562063e+00
 -8.9317220e-01 -2.6856375e-01 -1.4339888e+00 -8.6056888e-01
 -3.1718260e-01  7.2585535e-01 -2.1473885e-01 -8.8305593e-01
  3.9618397e-01  7.7305484e-01  1.4363701e+00  3.0826783e-01
 -8.2206905e-01 -3.9696699e-01 -6.4007312e-01 -6.8531036e-02
 -1.7353481e-01 -6.6772848e-01  6.3790560e-02  1.2566745e-01]
Pearson r: 0.728
MSE: 0.426
Average pearson_r accross all folds = 0.7346008396072145
Average mse accross all folds = 0.4957162141799927
Fold 1, k_feat 16384
X_train.shape:  (264, 16384)
y_pred:  [ 9.99673128e-01  1.76773000e+00  1.82686639e+00  1.92155623e+00
  1.13333678e+00  4.77569342e-01  3.73742104e-01  4.21438098e-01
  6.62229061e-01  8.55197191e-01  7.31364965e-01  8.70238066e-01
 -1.00173783e+00 -1.14148951e+00 -1.65829706e+00  4.93275881e-01
  5.58117628e-02  8.62619162e-01 -1.24896789e+00 -6.71309054e-01
 -5.14346838e-01  3.70187521e-01 -7.88326800e-01 -2.12725043e-01
 -1.08694744e+00 -8.67035747e-01  1.19489837e+00 -1.06609547e+00
 -1.00837207e+00  1.87620640e-01 -7.95618296e-02 -4.90289390e-01
  1.08200717e+00  4.89340782e-01  7.07181692e-01 -1.53486490e-01
 -4.17479873e-01 -1.10920036e+00 -1.46762466e+00 -2.46792555e-01
 -9.75837350e-01  8.77219439e-02 -8.53027403e-01 -7.93120444e-01
 -1.21637988e+00  3.19220781e-01  1.77212119e-01 -4.10594225e-01
 -1.17921090e+00 -1.25877380e+00  3.53945494e-01 -2.32059956e-02
 -7.05229521e-01 -4.86864448e-01  8.25528383e-01  7.02305555e-01
 -6.71099365e-01 -1.85474467e+00 -1.09692383e+00  2.84415483e-01
  6.29719734e-01 -1.57172382e+00 -1.22496724e-01  1.53117561e+00
 -2.84017563e-01  5.38471818e-01  3.22029233e-01  1.75714016e-01
 -4.66011345e-01 -2.07143545e-01 -3.31185341e-01 -5.09544730e-01
  8.31651211e-01  3.42685223e-01  2.19285727e-01 -1.41528130e-01
 -1.03463292e+00 -1.74368143e-01  3.29001665e-01  2.84732580e-01
 -1.62556887e-01  5.88817596e-02  2.13595986e-01  6.62808418e-02
 -3.12407017e-02 -6.36584997e-01 -1.45268321e-01  1.49820805e-01
 -1.11934900e-01  1.39349580e-01 -3.53408277e-01  2.93759823e-01
  2.08928347e-01 -4.76072550e-01  6.14930749e-01  1.23441434e+00
 -1.15147245e+00 -8.87609363e-01  1.04322243e+00  9.44216013e-01
  8.17118883e-01 -5.39280176e-01 -1.73867941e-01 -4.73595381e-01
 -8.13627481e-01 -3.60218287e-01  2.92261124e-01 -1.68573380e-01
 -6.06215477e-01 -4.48513031e-02  2.68087626e-01  3.42309475e-03
 -2.51670003e-01 -5.25612056e-01 -1.52701378e-01 -4.85501051e-01
 -5.57320595e-01 -6.14404678e-04 -7.80321240e-01  4.25845385e-01
 -3.11101198e-01 -7.35018134e-01 -1.03228223e+00 -1.80806041e-01
 -8.44417393e-01 -9.61877167e-01 -1.38949478e+00 -8.01491499e-01
  4.58541393e-01 -5.50182819e-01 -2.79217243e-01 -2.84492254e-01
 -2.29786754e-01]
Pearson r: 0.745
MSE: 0.495
Fold 2, k_feat 16384
X_train.shape:  (265, 16384)
y_pred:  [ 0.9549254   1.7785689   1.3543321   1.0439101   1.4847199   1.7231647
 -1.0867498   0.8436333   0.48787796  0.31298077  0.8683771   0.5949582
 -1.402902    0.15312707 -1.1239208  -0.5141337  -1.4666256  -0.22972727
 -0.9291273   0.71808493 -0.30168796  0.3627149   1.0762163   1.2500991
  0.6868892  -0.6801145  -0.22590685 -0.11293197 -0.39941013  0.44048703
 -0.46838105 -0.9977941   0.04293311 -0.01160944 -2.1017017  -0.25402904
 -0.62617064 -1.1591465   3.116468    1.6052552   0.99476945  0.6240443
  0.4199568   0.3148626   0.7211691   0.6041732  -1.3986564  -1.5102925
  0.26258337  0.09817803 -0.4511479  -1.7423902  -0.7387258   0.30843604
  0.6003734   1.1466061   0.96609724  0.0590533   1.2573744  -0.77970064
 -0.11368549  0.8591291   1.4643954   0.9260582  -0.1948725   1.8485137
  0.9276725   0.7973888   0.9673513   1.4135638   1.8735062   0.29440796
  0.4580034   1.3786277  -0.0090822  -0.28020144  0.77570474  1.1927305
  0.9022852  -0.10697198 -0.194134    0.21854043 -0.459929   -0.5865133
  0.5205668  -0.02942133 -0.28666556 -0.50778955 -0.6701961   0.61179495
 -0.04003572 -0.6486597   0.2132138  -0.28242302 -0.337054    0.68247867
 -0.02908802  0.6477481   1.1464993   0.39275837  1.924038    0.7113583
 -0.6655756  -1.3597046  -0.63448024 -0.7772865  -0.49219942 -0.9190883
  1.265179   -0.53743577  1.2602562  -1.6322842  -0.29518872  0.22750556
 -0.82134515 -1.8478324  -1.0959798  -0.40015715 -0.8845825  -0.10360307
  0.05469728 -1.3632455  -0.9234542  -0.5864444  -0.8817987  -0.14028287
 -1.7564781  -0.48100388  0.8073331  -0.43663394 -0.09843349  0.9643136 ]
Pearson r: 0.775
MSE: 0.466
Fold 3, k_feat 16384
X_train.shape:  (265, 16384)
y_pred:  [ 1.0769525   1.963349    1.4289654   1.8090593   2.1459694   1.3804318
  2.0786276   1.0380632  -0.9995948   0.48280978  0.93099153  0.9883038
 -0.80687594  0.00965047  0.10663348 -0.0542357   0.06045836 -0.8427102
  0.5897685   0.24899375 -1.7527683  -0.7771689  -0.9193352   0.24061167
  0.26258647 -0.8685063  -1.2418606  -0.11925751 -0.3899699  -0.07981348
  0.49194372  0.832399    0.2514174  -0.04841828 -0.42229718 -0.4777084
 -0.20852518 -0.42656225 -1.1186242   0.45903146 -0.18154037  0.80727434
  0.86756885  0.70997417  0.36118138 -0.46710122  0.6623492   0.6316577
  0.92399085  1.5588332  -0.26364982 -0.12610936  0.5244007  -0.15718699
  0.4100381   0.28951812 -0.19785947  0.6918783   0.7684194  -0.629336
  1.4968227  -0.17367882  3.4041977   1.266647    0.19393104  0.24615467
 -0.4723184  -0.11393309 -0.54428995 -0.47344285  1.0367478   0.01195705
  0.890452   -0.5333319  -0.84401596  0.24564707  0.15494978 -0.5504665
 -0.10651684 -0.11410147 -0.03413355  0.25249517  0.14354408 -0.44132084
  0.21058214 -0.09797001  0.70772433  0.15998912  0.21295369 -0.6198918
 -0.57640237  0.18191874 -0.58797914 -0.17364526 -0.75938565 -0.9000624
 -0.8011807  -1.0724944  -0.1717766  -0.2043584   0.01416266  0.9090828
  0.65159726  0.5741799   1.3974637  -0.5735264   1.1652904  -0.02778262
  0.06765461 -0.518991   -0.46932644 -1.7293439  -0.58583534 -0.83980876
 -1.3262333  -1.1823069  -0.3941978   0.5466442  -0.30533427 -0.721182
 -0.37239456  0.71131384  1.483471    0.33744097 -0.9240335  -0.78579545
 -0.69007087  0.05298203 -0.27284026 -0.5197558  -0.08978426 -0.27014637]
Pearson r: 0.745
MSE: 0.382
Average pearson_r accross all folds = 0.7548721194992608
Average mse accross all folds = 0.44764432311058044
