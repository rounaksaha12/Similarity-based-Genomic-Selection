After clean(removal of rows with high missing values + redundancy removal) X.shape:  (402, 10792)
Fold 1, k_feat 8
X_train.shape:  (268, 8)
y_pred:  [-0.67582145 -0.31068206 -0.67582145 -0.67582145 -0.67582145 -0.31068206
 -0.31068206 -0.31068206 -0.67582145 -0.67582145 -0.31068206 -0.68470335
 -0.51755299  0.13032685 -0.74181568 -0.78264444 -0.78264444 -0.78264444
 -0.31068206 -0.40601675 -0.40490371 -0.40490371 -0.78264444 -0.78264444
 -0.52907223  0.49156514 -0.52907223 -0.31068206 -0.74181568 -0.45335094
 -0.31068206 -0.31068206 -0.52907223 -0.40490371 -0.74181568 -0.40490371
 -0.76227316  0.00769344 -0.27809365  0.30327497  0.49156514  0.50631175
 -0.01958149  0.35632356  0.13032685  0.50631175  0.50631175  0.35632356
 -0.01958149  0.00769344  0.10212494  0.50631175 -0.01958149  0.13032685
  0.00769344 -0.19418242  0.33409722  0.00769344 -0.78264444  0.17725427
 -0.19316467  0.00769344  0.00769344 -0.78264444  0.00769344  0.10212494
  0.50631175 -0.56642479  0.50631175  0.50631175  0.49156514  0.49156514
 -0.29083813  0.33409722  0.13032685 -0.01958149 -0.31068206 -0.31068206
  0.50631175 -0.48512896  0.50631175  0.00769344  0.13032685 -0.26457742
 -0.01958149 -0.01958149 -0.31068206 -0.48512896 -0.19316467 -0.19316467
  0.33409722 -0.66924638 -0.66924638  0.00769344  0.50631175  0.35632356
  0.07125758 -0.52907223  0.00769344  0.00769344  0.13032685  0.35632356
  0.50631175  0.35632356  0.00769344  0.00769344 -0.05597071  0.50631175
 -0.19316467  0.07125758  0.17725427 -0.27809365  0.50631175  0.50631175
 -0.27809365  0.00769344  0.00769344  0.00769344  0.50631175 -0.31068206
  0.35632356 -0.31068206  0.35632356  0.50631175  0.26046629 -0.31068206
  0.35632356 -0.07691066 -0.14855025 -0.22721891 -0.05767102 -0.07691066
 -0.14855025 -0.12037175]
Pearson r: 0.439
MSE: 0.873
Fold 2, k_feat 8
X_train.shape:  (268, 8)
y_pred:  [-9.16176899e-01 -7.99155916e-01 -7.99155916e-01 -9.16176899e-01
 -8.36390665e-01 -7.39601136e-01 -7.99155916e-01 -7.99155916e-01
 -7.99155916e-01 -7.99155916e-01 -4.06037448e-01 -4.06037448e-01
 -4.06037448e-01 -7.39601136e-01 -9.16176899e-01 -7.39601136e-01
 -8.36390665e-01 -2.13282225e-01 -4.06037448e-01 -4.06037448e-01
 -9.35988469e-01 -9.16176899e-01 -4.38639441e-02 -4.06037448e-01
 -2.13282225e-01 -2.13282225e-01  3.47250512e-01  3.47250512e-01
  7.70719489e-04  7.87648555e-02  2.31672202e-01  3.43514009e-01
 -7.99155916e-01 -2.12077222e-01 -9.79774333e-02  2.19420625e-01
  2.19420625e-01 -7.39601136e-01  3.43514009e-01  9.60568223e-02
  3.43514009e-01  2.31672202e-01  2.31672202e-01  7.70719489e-04
 -4.25167803e-01  2.19420625e-01  3.43514009e-01  3.43514009e-01
  3.43514009e-01  2.31672202e-01  9.60568223e-02  2.19420625e-01
  9.60568223e-02  9.60568223e-02  2.06593587e-01 -9.79774333e-02
  2.41049733e-01  2.06593587e-01 -4.06037448e-01  2.19420625e-01
  2.19420625e-01  7.87648555e-02  7.87648555e-02  7.87648555e-02
  2.19420625e-01  3.43514009e-01  2.41049733e-01  2.19420625e-01
  2.19420625e-01  2.19420625e-01  7.87648555e-02  2.19420625e-01
  2.19420625e-01  2.31672202e-01  7.87648555e-02  2.19420625e-01
  7.87648555e-02 -7.39601136e-01  3.43514009e-01 -7.39601136e-01
 -7.39601136e-01  7.87648555e-02 -5.01374571e-01  1.99728612e-01
 -5.24904454e-01 -5.64276708e-01  3.43514009e-01  3.47250512e-01
 -5.01374571e-01  2.31672202e-01  3.43514009e-01 -4.07303564e-01
 -9.79774333e-02  2.06593587e-01  3.43514009e-01 -9.79774333e-02
  3.43514009e-01  3.47250512e-01  2.06593587e-01  3.20872432e-01
  3.43514009e-01  2.19420625e-01  7.87648555e-02  3.43514009e-01
 -9.79774333e-02  2.19420625e-01  2.19420625e-01 -9.79774333e-02
  2.06593587e-01  3.43514009e-01 -5.24904454e-01 -3.52275047e-01
  3.43514009e-01  3.47250512e-01  3.43514009e-01 -7.99155916e-01
 -1.49755797e-01  2.31672202e-01  3.22336614e-01 -5.07231630e-01
  2.31672202e-01  2.31672202e-01  3.43514009e-01 -7.39601136e-01
  3.43514009e-01  2.19420625e-01  7.87648555e-02  7.87648555e-02
  2.19420625e-01  3.43514009e-01  3.43514009e-01  2.19420625e-01
  3.43514009e-01  2.19420625e-01]
Pearson r: 0.477
MSE: 0.649
Fold 3, k_feat 8
X_train.shape:  (268, 8)
y_pred:  [-0.61912125 -0.61912125 -0.91385566 -0.61912125 -0.50992534 -0.85188946
 -0.95581883 -0.7955683  -0.7955683  -0.91385566 -1.01212437 -1.01212437
 -0.50992534 -1.02071994 -0.7955683  -0.95581883 -0.95581883 -0.91377954
 -0.91385566 -0.7955683  -0.27744653 -0.50992534 -0.72619177 -0.58098087
 -0.81201011 -0.23200501 -0.95581883 -0.23200501 -0.61912125  0.34903489
  0.342291    0.342291    0.342291    0.15639856 -0.58098087  0.342291
 -0.24614733  0.41372411  0.31634701  0.27234763  0.31634701 -0.09075537
 -0.78922797 -0.05157555  0.07871794  0.28255171 -0.14748747  0.28255171
 -0.14663405  0.41372411  0.17666592  0.10588776  0.4199551   0.28255171
  0.342291    0.342291    0.09666886 -0.38799994 -0.25415355 -0.40354611
  0.34903489  0.34903489 -0.48155562  0.17666592  0.4199551   0.34903489
  0.26591891  0.10588776  0.18250502  0.18250502  0.05465312  0.342291
  0.29584129  0.342291    0.10588776 -0.91385566  0.07871794 -0.36313876
 -0.36313876  0.07871794 -0.07795756  0.17666592 -0.36313876  0.342291
  0.34903489  0.34903489  0.34903489  0.31634701 -0.16562901 -0.16562901
  0.41372411 -0.16562901 -0.16562901 -0.91385566  0.22244351  0.18250502
  0.34903489  0.34903489  0.34903489 -0.07128804  0.29584129  0.26591891
  0.34903489  0.4199551  -0.36313876  0.4199551   0.4199551   0.07871794
  0.17666592  0.27234763 -0.30365408  0.342291   -0.16562901  0.342291
  0.01934004 -0.16562901 -0.7955683  -0.16562901  0.342291   -0.16562901
  0.27234763  0.31634701 -0.07795756  0.34903489  0.34903489  0.34903489
 -0.36313876 -0.24614733  0.34903489  0.34903489 -0.36313876  0.34903489
 -0.36313876  0.34903489]
Pearson r: 0.476
MSE: 0.941
Average pearson_r accross all folds = 0.4641763081333516
Average mse accross all folds = 0.8209887255731436
Fold 1, k_feat 16
X_train.shape:  (268, 16)
y_pred:  [-0.81672908 -0.72021006 -0.81672908 -0.77907022 -0.72944351 -0.681725
 -0.74528511 -0.74528511 -0.87931819 -0.79136725 -0.74528511 -0.90713487
 -0.75820184 -0.03214057 -0.97137894 -0.97756472 -0.93087805 -0.86248474
 -0.74528511 -0.74041507 -0.82739084 -0.82739084 -1.03601373 -0.82723665
 -0.58145811  0.16610006 -0.78109837 -0.52798515 -0.6623998  -0.70753718
 -0.75255466 -0.67666696 -0.62766138 -0.63502555 -0.74177677 -0.81784094
 -0.8213221  -0.07155022  0.036422    0.24247592  0.33104493  0.34119332
 -0.2519334   0.26603193  0.16176072  0.06806082  0.34119332  0.12829873
  0.30176498 -0.09383818  0.099924    0.41359874  0.44177786  0.0726842
  0.0700189   0.09995603 -0.17754575  0.08804361 -0.14972948  0.27776179
  0.36347183  0.1876081   0.26946115  0.00812816 -0.15793914  0.10683015
  0.49239233 -0.48079772  0.46732875  0.46732875  0.18453163  0.39187344
 -0.37935238  0.24584308  0.15001045 -0.20136651  0.34967052  0.34967052
  0.44897348 -0.38839696  0.13381745  0.2050262   0.10986216 -0.42996771
 -0.15865123 -0.42109645 -0.34325496 -0.38839696  0.30389124  0.26249015
  0.42196657 -0.18916383 -0.35745249  0.0700189   0.53602084  0.36685283
  0.11382639 -0.19988725  0.1876081   0.1876081   0.16176072  0.37051879
  0.53239135  0.25427389 -0.18949397  0.08804361 -0.05475449  0.50705575
  0.39834416  0.214547    0.19879288  0.036422    0.49239233  0.41927065
  0.036422    0.09305264  0.08804361  0.02707489  0.44897348  0.34967052
  0.38584485 -0.40709906  0.26987509  0.32717439  0.12991008 -0.40709906
  0.19830378 -0.02178271  0.0091676  -0.19192347 -0.07412062 -0.02178271
  0.0091676   0.15159951]
Pearson r: 0.597
MSE: 0.718
Fold 2, k_feat 16
X_train.shape:  (268, 16)
y_pred:  [-0.88237622 -0.7973256  -0.7973256  -0.88237622 -0.82639848 -0.65366244
 -0.7973256  -0.7973256  -0.7973256  -0.7973256  -0.40191739 -0.40191739
 -0.40191739 -0.65366244 -0.88237622 -0.65366244 -0.82639848 -0.26987157
 -0.40191739 -0.40191739 -0.90505986 -0.88237622 -0.03832766 -0.40191739
 -0.26987157 -0.26987157  0.32074889  0.32074889  0.02270972  0.00103306
  0.19339931  0.36929869 -0.7973256  -0.2733575  -0.23079108  0.17376208
  0.17376208 -0.65366244  0.36929869 -0.04635211  0.36929869  0.19339931
  0.19339931  0.02270972 -0.42250443  0.17376208  0.36929869  0.36929869
  0.36929869  0.19339931 -0.04635211  0.17376208 -0.04635211 -0.04635211
  0.09908759 -0.23079108  0.2554688   0.09908759 -0.40191739  0.17376208
  0.17376208  0.00103306  0.00103306  0.00103306  0.17376208  0.36929869
  0.2554688   0.17376208  0.17376208  0.17376208  0.00103306  0.17376208
  0.17376208  0.19339931  0.00103306  0.17376208  0.00103306 -0.65366244
  0.36929869 -0.65366244 -0.65366244  0.00103306 -0.62796457  0.21079633
 -0.57852091 -0.61010849  0.36929869  0.32074889 -0.62796457  0.19339931
  0.36929869 -0.40268167 -0.23079108  0.09908759  0.36929869 -0.23079108
  0.36929869  0.32074889  0.09908759  0.28286714  0.36929869  0.17376208
  0.00103306  0.36929869 -0.23079108  0.17376208  0.17376208 -0.23079108
  0.09908759  0.36929869 -0.57852091 -0.45834397  0.36929869  0.32074889
  0.36929869 -0.7973256  -0.30210253  0.19339931  0.30587687 -0.41945727
  0.19339931  0.19339931  0.36929869 -0.65366244  0.36929869  0.17376208
  0.00103306  0.00103306  0.17376208  0.36929869  0.36929869  0.17376208
  0.36929869  0.17376208]
Pearson r: 0.443
MSE: 0.687
Fold 3, k_feat 16
X_train.shape:  (268, 16)
y_pred:  [-0.83166916 -0.83166916 -0.94189619 -0.89773731 -0.72303023 -0.81146536
 -0.92439733 -0.83867291 -0.78713164 -0.89274064 -1.0269988  -1.0269988
 -0.73781903 -0.98803072 -0.88068349 -0.88513138 -0.88513138 -0.88041345
 -0.89274064 -0.83867291 -0.38976949 -0.73781903 -0.71534372 -0.35239514
 -0.84281539 -0.59693592 -0.95689015 -0.67514688 -0.47537005  0.34718407
  0.2321884   0.3249287   0.1548316   0.17130321 -0.28698648  0.33999031
 -0.20183791  0.23618861  0.26512051  0.28486671  0.26512051  0.29037953
 -0.56931471  0.3368194   0.03636396  0.2864045  -0.1811678   0.2864045
  0.26520636  0.39838097 -0.17015884  0.19651286  0.39735407  0.2864045
  0.33785265  0.33785265  0.1945232  -0.34350556 -0.13960791 -0.35104014
  0.3380454   0.3380454  -0.39810092  0.31603793  0.14860464  0.25536946
 -0.02385193  0.06931562 -0.30898389 -0.11668049  0.25727718  0.42825297
  0.39780931  0.42825297  0.18540001 -0.63930631 -0.05199127 -0.63084592
  0.19409848  0.22798543 -0.06257303  0.31603793  0.19409848  0.47406224
  0.47818142  0.3380454   0.3380454   0.18582412  0.25640056  0.25640056
  0.23618861  0.25640056 -0.08650217 -0.22182888  0.32355157 -0.30898389
  0.3380454   0.3380454   0.3380454  -0.05952721  0.39780931  0.37816504
  0.25536946  0.402449    0.19409848  0.402449    0.39735407 -0.07448686
  0.17823387  0.3604444  -0.56698891  0.33785265 -0.08650217  0.47406224
  0.09459712 -0.03371497 -0.15493195 -0.03371497  0.47406224 -0.08650217
  0.3604444   0.2267647  -0.06780742  0.47818142  0.3380454   0.47818142
  0.19409848 -0.23421111  0.25722006  0.06396126 -0.20259015  0.25722006
 -0.20259015  0.25722006]
Pearson r: 0.508
MSE: 0.903
Average pearson_r accross all folds = 0.5160258282273272
Average mse accross all folds = 0.7691423762032444
Fold 1, k_feat 32
X_train.shape:  (268, 32)
y_pred:  [-0.5343547  -0.25151226 -0.5343547  -0.62061202 -0.48609884 -0.61876237
 -0.63278848 -0.63278848 -0.3344525  -0.56960612 -0.68751869 -0.58869268
 -0.77476162  0.0275979  -0.62773266 -0.49681307 -0.51774709 -0.60480856
 -0.63278848 -0.64086671 -0.82623134 -0.82623134 -0.9044888  -0.58908739
 -0.2257576   0.01487092 -0.29812944 -0.24114827 -0.41973132 -0.82020367
 -0.75772971 -0.79921116 -0.24891872 -0.13110054 -0.66360157 -0.34197638
 -0.41988587 -0.13781697 -0.03229294  0.1742864   0.55152038  0.15582734
 -0.33487422  0.14869656  0.12104463 -0.02804254  0.3015992   0.02807188
  0.06481997 -0.04164939  0.36485566  0.41368356  0.39673522  0.0574382
  0.24764251  0.12039787 -0.23928229  0.22415473  0.06712052  0.24589619
  0.1797198   0.25838274  0.31496475  0.1696007  -0.32054903  0.28325771
  0.58278491 -0.37244532  0.56420368  0.54267427  0.07949235  0.2971164
 -0.32882105  0.04269482  0.23596596 -0.31086253  0.16290938  0.16290938
  0.48391177 -0.40907926  0.19841971  0.22772718  0.11011457 -0.55916822
 -0.23242725 -0.47495935 -0.37862811 -0.3827441   0.14297913  0.12183542
  0.43436496  0.06490482 -0.24562341  0.22532076  0.50514459  0.45807303
  0.13019526 -0.10792806  0.22205132  0.09622519  0.31722476  0.21540202
  0.42400365  0.35801129 -0.18211048  0.14544242 -0.03826595  0.601805
  0.28809946  0.22902735  0.33290755  0.13847704  0.64958978  0.53387683
  0.1569335   0.07953333  0.04857953 -0.04361209  0.49711674  0.16290938
  0.3480294  -0.46273419  0.26445268  0.35520187  0.31394787 -0.46273419
  0.06097298  0.26281244  0.07540751 -0.10840843  0.01335864  0.26281244
  0.07540751  0.08140797]
Pearson r: 0.575
MSE: 0.780
Fold 2, k_feat 32
X_train.shape:  (268, 32)
y_pred:  [-0.79048427 -0.76510391 -0.52401441 -0.54663971 -0.53538677 -0.80906523
 -0.79487821 -0.8151611  -0.8151611  -0.8151611  -0.74050366 -0.74050366
 -0.74050366 -0.56088021 -0.98962935 -0.31846694 -0.60070894 -0.61831832
 -0.52454875 -0.52454875 -0.78655432 -0.81874347 -0.05959419 -0.6163797
 -0.29594483 -0.10127311  0.0908826   0.08852335  0.19773834 -0.23526053
  0.02154568  0.13786578 -0.42175507 -0.25626095 -0.01010924  0.27752619
  0.35811863 -0.31846694  0.33240368  0.23618425  0.43669478  0.35120486
  0.10919881 -0.01318769 -0.33182897  0.33747575  0.32842891  0.43669478
  0.39916094  0.18899863 -0.05592703  0.21551723 -0.05592703 -0.05592703
  0.21967912  0.06570281  0.16954922  0.34003644 -0.14695486  0.29824669
  0.29824669  0.18913065  0.14583312  0.14583312  0.085724    0.33240368
  0.35952968  0.21551723  0.21551723  0.29824669  0.14583312  0.21551723
  0.36039416 -0.08226622 -0.00748318  0.21551723  0.14583312 -0.4219928
  0.45084103 -0.63406421 -0.4219928  -0.15010882 -0.672593    0.24183501
 -0.66381797 -0.58556543  0.43521031  0.42992253 -0.5245395   0.03489512
  0.12651942 -0.42465518 -0.01412024 -0.0317973   0.48672206 -0.2665618
  0.08024744  0.41572792 -0.03033991  0.43654078  0.39596703  0.29415678
  0.02445583  0.33240368  0.11668276  0.00241213  0.15626383 -0.34781879
 -0.20032239  0.37395177 -0.57164239 -0.52308863  0.49918911  0.2202109
  0.41790578 -0.46099662 -0.2308036   0.20854868  0.30926061 -0.45429767
  0.18899863  0.18899863  0.49961224 -0.31846694  0.50356213 -0.02674682
 -0.02830606  0.14583312  0.1653347   0.23596365  0.23596365  0.01470084
  0.23596365  0.06929798]
Pearson r: 0.555
MSE: 0.597
Fold 3, k_feat 32
X_train.shape:  (268, 32)
y_pred:  [-0.93635467 -0.93879846 -0.95891069 -0.97846657 -0.8545523  -0.82013114
 -0.98989666 -0.84296242 -0.71500498 -0.7334254  -0.71567323 -0.71469792
 -0.78970076 -0.92452403 -0.94045535 -0.87982488 -0.87982488 -0.71369801
 -0.85553235 -0.67368171 -0.63833737 -0.71171391 -0.61169242 -0.36366191
 -0.66572923 -0.43361193 -0.91722972 -0.64489624 -0.26733413  0.09514691
  0.49176092  0.47970783  0.50941465  0.24685011  0.17500186  0.41162016
 -0.28779671  0.49375202  0.42164397  0.49800845  0.4363769   0.25017017
 -0.4543479   0.32703249  0.33780244  0.27783661 -0.35604952  0.17524911
 -0.04528029  0.32933345 -0.24432334  0.16793973  0.48415143  0.02928921
  0.23977529  0.23977529  0.46254025 -0.25872685  0.08324279 -0.07796765
  0.35990716  0.59569397 -0.17355327  0.37696645 -0.03434066 -0.1719977
 -0.15635892  0.13789172 -0.27503343 -0.18553372  0.20916606  0.36340972
  0.49821584  0.45137168  0.00229641 -0.44463846 -0.41969798 -0.87413612
  0.16689342  0.367248    0.20837532  0.37696645  0.10670362  0.37762557
  0.56904912  0.09620869  0.12075569  0.21280356 -0.00686239  0.093466
  0.00728844  0.06915004 -0.09088871 -0.19791524 -0.15020306  0.17985982
  0.50811398  0.12075569  0.44629456  0.03853601  0.06168269  0.08856183
 -0.08616583  0.06316059  0.10416688  0.31635558  0.24838606  0.01309501
  0.33439862  0.54029979 -0.31584551  0.54782459  0.33260346  0.53580544
  0.32031645  0.1066077   0.06420572  0.27853278  0.5410766   0.31792298
  0.4788246   0.18040259  0.14845324  0.37324276  0.32529158  0.62929232
  0.20239985 -0.1353416  -0.03768439  0.34580618 -0.3267971   0.33156161
 -0.34749855  0.3385651 ]
Pearson r: 0.620
MSE: 0.785
Average pearson_r accross all folds = 0.5834092036903518
Average mse accross all folds = 0.7206752499228083
Fold 1, k_feat 64
X_train.shape:  (268, 64)
y_pred:  [-0.55700863 -0.19556595 -0.55700863 -0.49229046 -0.61772278 -0.43829188
 -0.46972382 -0.56730982 -0.3512313  -0.13755796 -0.6763826  -0.28826801
 -0.90555024  0.00961766 -0.67093599 -0.57826986 -0.32841539 -0.28496367
 -0.45310046 -0.43672906 -0.67556648 -0.76957153 -0.72015142 -0.23279194
 -0.20596243 -0.16972816 -0.25017404 -0.19672322 -0.54691694 -0.68946998
 -0.7991221  -0.70971348 -0.20660449 -0.11544733 -0.53569479 -0.25158809
 -0.19971048 -0.045688   -0.00448677  0.31240862  0.64672779  0.13320454
 -0.26082962  0.09273752  0.04069365  0.0023557   0.31102458  0.05159832
  0.04054138  0.26391658  0.12956754  0.34654971  0.26235745 -0.12490556
  0.14471693  0.01623087 -0.29015292  0.35829535  0.01698955  0.12047602
  0.04026019  0.32287771  0.38269978  0.04992349  0.09057297  0.42112202
  0.38590286 -0.41383308  0.57803766  0.53513135  0.07593422  0.27753062
 -0.24195181 -0.04634156  0.14319376 -0.05182319 -0.10444231  0.11324608
  0.2514915  -0.36125924  0.14171769  0.27273667  0.13885752 -0.44764947
 -0.24516607 -0.4440917  -0.27728795 -0.24919766  0.18695159  0.28513991
  0.35440885 -0.31549143 -0.49353743  0.12646989  0.373052    0.39046213
  0.02954892 -0.08820109  0.3609431   0.10980637  0.36549602  0.16660625
  0.28886997  0.51691506 -0.22394756  0.11165435 -0.11295623  0.55184417
  0.1348773   0.34740971  0.33179426  0.041347   -0.04872266  0.46407537
  0.05680469 -0.07605132 -0.03719393 -0.02540183  0.45802512 -0.04998669
  0.3417916  -0.36752298  0.18599049  0.3741126   0.48183152 -0.32068035
  0.0951107   0.45514018  0.05906935 -0.02750689  0.15920008  0.45514018
  0.05906935  0.07642759]
Pearson r: 0.556
MSE: 0.815
Fold 2, k_feat 64
X_train.shape:  (268, 64)
y_pred:  [-0.86109476 -0.83957562 -0.55902749 -0.60439907 -0.6151043  -0.95444793
 -0.70847518 -0.74336394 -0.82915209 -0.81525919 -0.68673951 -0.68673951
 -0.7472171  -0.86056707 -1.14582562 -0.75447825 -0.73323481 -0.46819209
 -0.45811853 -0.72368085 -0.87636389 -0.80957261 -0.49965249 -0.45113454
 -0.11281804  0.20115241  0.22242696  0.20553852  0.2511379  -0.15923478
 -0.03939058 -0.09722059 -0.41913232 -0.04752596  0.1716871   0.14760328
  0.18287583 -0.35717331  0.328182    0.27207745  0.2630447   0.3472201
  0.14338344  0.22632879 -0.14223953  0.24929676  0.21634614  0.34951276
  0.20605625  0.11087601  0.0373342   0.15259272  0.10618309  0.12241466
  0.37189955  0.19346488  0.13519248  0.46288549 -0.12651203  0.21396365
  0.28907227  0.10496892  0.087691    0.17792923  0.14828524  0.06568053
  0.23006626  0.0562746   0.0562746   0.28835853  0.13642209  0.11820473
  0.16642158 -0.12306957 -0.05804704  0.01863857  0.11864204 -0.48040688
  0.20677469 -0.53643539 -0.74356202  0.0276141  -0.43326685  0.01616421
 -0.57203328 -0.49451899  0.23559627  0.21457621 -0.44373474 -0.15010228
  0.16448452 -0.38557645  0.15432107  0.16732533  0.39317725  0.1549291
  0.1305926   0.40678757  0.19086393  0.33684609  0.38701316  0.28755935
 -0.02809876  0.07085341  0.09120985  0.25512174  0.23390077 -0.31832393
 -0.0389785   0.26880921 -0.60679119 -0.5473093   0.4032285   0.17193943
  0.31507451 -0.43882585 -0.02662601  0.19898377  0.36131467 -0.42238503
  0.16336996  0.11763124  0.46800527 -0.75447825  0.1726837   0.27025123
  0.04665807 -0.0706442   0.3479594   0.32750654  0.32750654 -0.02436959
  0.11925581  0.08471964]
Pearson r: 0.571
MSE: 0.594
Fold 3, k_feat 64
X_train.shape:  (268, 64)
y_pred:  [-0.76486759 -0.871499   -0.95157278 -0.90967475 -0.79449837 -0.81083219
 -0.90668181 -0.89948665 -0.74744461 -0.72839703 -0.47126066 -0.4587272
 -0.80841262 -0.91075889 -0.85179083 -0.8138365  -0.79758927 -0.41284292
 -0.45720639 -0.73146428 -0.65395338 -0.7966134  -0.52521895 -0.29077361
 -0.68368225 -0.26138205 -0.86141634 -0.49613354 -0.54189356  0.1445478
  0.50002244  0.4781438   0.50681864  0.2952518   0.24883857  0.42750666
 -0.50194559  0.42516913  0.37601819  0.52111577  0.4418966   0.17766562
 -0.49407285  0.18618853  0.26916731  0.26196513 -0.43130522  0.13659068
 -0.06214789  0.1792122  -0.13876346 -0.12146667  0.39665522  0.16846241
  0.2275238   0.2275238   0.47292737 -0.29058933 -0.11786605 -0.00455744
  0.38762425  0.60141774 -0.15044443  0.2134104   0.02182556 -0.15503817
 -0.11069388 -0.09821619 -0.14527033 -0.16256321  0.21445613  0.31632074
  0.48355951  0.40062646 -0.26347866 -0.56078209 -0.50471251 -0.92493216
 -0.12401372  0.31700878  0.15509505  0.32919534 -0.15468157 -0.00841499
  0.1818323   0.04745303  0.09145765  0.29153976 -0.23590124 -0.08616239
 -0.04072902  0.05341535  0.00694379 -0.31928249 -0.13354774  0.27829927
  0.47949712  0.09145765  0.39783013 -0.04438541  0.06030267  0.08987239
 -0.04766434  0.02263228 -0.19663661  0.3338491   0.24988636  0.02626495
  0.28180928  0.57338084 -0.14316162  0.5505746   0.31135109  0.62525134
  0.28927086  0.13284588  0.09641372  0.28067175  0.20163019  0.29046915
  0.50003563  0.28298392  0.19737727  0.43780636  0.35091789  0.66406376
 -0.15866968 -0.30092146 -0.04036938  0.35016659 -0.46077668  0.37783648
 -0.50500816  0.40927414]
Pearson r: 0.626
MSE: 0.794
Average pearson_r accross all folds = 0.5842843023022916
Average mse accross all folds = 0.734507040115636
Fold 1, k_feat 128
X_train.shape:  (268, 128)
y_pred:  [-5.88791050e-01 -4.47148625e-01 -5.88791050e-01 -5.55786248e-01
 -7.25418716e-01 -2.53996387e-01 -2.19868295e-01 -5.50672992e-01
 -4.82456755e-01 -1.81813977e-01 -3.99148001e-01 -4.18114777e-01
 -9.04509520e-01 -3.14232221e-02 -6.34096880e-01 -6.82039465e-01
 -2.76640034e-01 -3.66007712e-01 -2.77515077e-01 -3.01435291e-01
 -6.61767870e-01 -6.59419852e-01 -6.27736532e-01 -2.37435710e-01
 -1.92820767e-01 -1.74837263e-01 -3.72071814e-01 -2.01999637e-01
 -6.22124467e-01 -6.53142418e-01 -6.36472540e-01 -6.63981235e-01
 -2.26365396e-01 -1.13337683e-01 -5.57120949e-01 -4.23545511e-01
 -1.98168857e-01  3.47714185e-02  1.10592595e-02  3.40662743e-01
  1.10355923e-01  1.97676252e-01 -1.00879158e-01  4.50616445e-02
  3.52006133e-02  2.95310233e-02  3.18351139e-01  3.25697900e-02
  5.20588126e-02  1.77869883e-01  2.67258781e-01  3.70291832e-01
  2.05158904e-01 -1.94004086e-01  1.57282871e-01  1.94918443e-01
 -2.29385254e-01  4.56755398e-01  1.74814082e-01  1.80585288e-01
  7.87262186e-02  4.97340258e-01  4.06886286e-01  1.60312389e-01
  1.68120030e-01  4.03144098e-01  3.70614724e-01 -3.06685710e-01
  5.73131027e-01  5.41310143e-01  4.66927570e-02  2.60394069e-01
 -1.22394952e-01  5.52384725e-02  2.37711788e-01  1.46934844e-02
 -8.32756973e-02 -2.26412642e-04  3.72702856e-01 -6.12823758e-02
  7.16410380e-02  1.49676278e-01 -9.63941495e-02 -4.44024601e-01
 -1.92888304e-01 -4.49695648e-01 -1.11755584e-01 -6.50339107e-02
  4.65951563e-02  2.45400558e-01  3.44775634e-01 -2.10890190e-01
 -3.81697275e-01  1.56680401e-01  2.45954097e-01  2.94891121e-01
  1.19895220e-01 -1.39794339e-02  5.18855363e-01  1.88357506e-01
  1.35119642e-01  8.55851640e-02  2.36243565e-01  3.14395184e-01
  2.45067455e-03  8.62626872e-02 -1.33920297e-01  5.96558878e-01
  1.36718121e-01  3.80819136e-01  2.65765646e-01  1.17262718e-01
  4.02779361e-02  5.06470535e-01  1.16394857e-01 -6.68691120e-02
  4.47540537e-02  1.39764938e-02  3.42712430e-01 -5.14368768e-03
  2.51028507e-01 -1.59517624e-01  1.73919694e-01  1.92311724e-01
  2.52669968e-01 -1.55743636e-01  1.59536275e-02  2.41997016e-01
  1.79505368e-02  3.39721028e-02  9.17396310e-02  2.37492647e-01
  1.79505368e-02  5.00023028e-02]
Pearson r: 0.562
MSE: 0.826
Fold 2, k_feat 128
X_train.shape:  (268, 128)
y_pred:  [-0.91184731 -0.65429381 -0.56233516 -0.74211809 -0.62335328 -0.95125162
 -0.72102491 -0.75172993 -0.77180604 -0.75592267 -0.51617183 -0.51617183
 -0.48766516 -0.90191096 -1.1103298  -0.81439473 -0.74427394 -0.41864081
 -0.31692507 -0.40642541 -0.92143294 -0.85201106 -0.31564236 -0.50851583
 -0.13804777  0.25654077  0.28448694  0.2797631   0.29338202 -0.04448351
 -0.07740426 -0.11640141 -0.38936162  0.0731235   0.13912137  0.29198547
  0.27917985 -0.55035223  0.33005949  0.15067262  0.36597174  0.4357727
  0.2061773   0.36678224 -0.07699805  0.24096723  0.26734666  0.33283096
  0.26534567  0.08488818  0.16586335  0.2275558   0.18872293  0.22735167
  0.40667601  0.32170735  0.15472095  0.36944249 -0.00694452  0.3311222
  0.24090357  0.27195824  0.07024653  0.30446496  0.29593892  0.15471095
  0.15330824  0.19214333  0.20169209  0.28741271  0.12534906  0.18903701
  0.24781812 -0.14317991  0.07911798  0.05991378  0.11450087 -0.09616136
  0.21510278 -0.53350726 -0.69250369  0.14701652 -0.41957537  0.03344227
 -0.45249305 -0.33489941  0.30846095  0.07531678 -0.33158436 -0.05442835
  0.12276763 -0.36566415  0.30123925  0.04007977  0.38807885  0.13997839
  0.2070791   0.40010316  0.22889976  0.30974896  0.35172502  0.18487401
 -0.02549842 -0.03919287  0.05802102  0.06534418  0.2574445  -0.39444538
 -0.18907398  0.2425685  -0.43876513 -0.30392772  0.35708738  0.17514573
  0.40576461 -0.39261499  0.04250347  0.31881379  0.43715202 -0.39012106
  0.23818867  0.24273665  0.33118224 -0.83198278  0.20779325  0.3539268
  0.13709759 -0.03280122  0.409301    0.25494246  0.28078529  0.13827352
  0.19798708  0.23597851]
Pearson r: 0.572
MSE: 0.573
Fold 3, k_feat 128
X_train.shape:  (268, 128)
y_pred:  [-0.6789393  -0.85593686 -0.84966363 -0.87402047 -0.72024608 -0.71971274
 -0.78711612 -0.91511857 -0.71955836 -0.74673861 -0.37526227 -0.43334416
 -0.78258332 -0.79319597 -0.81082361 -0.77598892 -0.77073075 -0.43118472
 -0.48180092 -0.79910527 -0.66965999 -0.81167411 -0.41159768 -0.29314858
 -0.57855953 -0.16175174 -0.7865913  -0.43933066 -0.62590906  0.11533582
  0.42811704  0.33889188  0.45760678  0.25180424  0.27332378  0.31003474
 -0.43669668  0.42429429  0.35731619  0.51234507  0.46430121  0.27693595
 -0.54350733  0.2791349   0.33032663  0.31194727 -0.46467736  0.18313118
  0.06693712  0.12353512 -0.01094574 -0.16100322  0.30635165  0.20095188
  0.28701117  0.28701117  0.37633879 -0.35336286 -0.24391841  0.02367326
  0.35284221  0.52371278 -0.21582572  0.2185043   0.06621924 -0.16040574
 -0.02941708 -0.06838801 -0.03098384 -0.12673512  0.11969122  0.17442774
  0.41761838  0.2947319  -0.28945447 -0.47199617 -0.45832937 -0.93800493
 -0.09178113  0.25034814  0.10875607  0.26121754 -0.11275063 -0.11284841
  0.11118428  0.10132915  0.15151507  0.30075959 -0.17237933  0.01635662
 -0.00884499  0.1679451   0.14836763 -0.22686374  0.00377071  0.28512897
  0.46692843  0.16913192  0.41747017 -0.11803386  0.14014571  0.11024613
 -0.11523417  0.06462733 -0.21212706  0.33231037  0.23710127  0.05025818
  0.14670884  0.54250665  0.0409906   0.5357996   0.32360769  0.32206636
  0.36633216  0.10130323  0.01529708  0.3070725   0.13938117  0.35229233
  0.54252769  0.29930177  0.1731429   0.35981041  0.32063181  0.54339411
 -0.10904017 -0.32119331  0.02490689  0.28740194 -0.30074633  0.32501845
 -0.3426119   0.31585327]
Pearson r: 0.620
MSE: 0.811
Average pearson_r accross all folds = 0.5847084055111039
Average mse accross all folds = 0.7368717111824791
Fold 1, k_feat 256
X_train.shape:  (268, 256)
y_pred:  [-0.69785796 -0.56844915 -0.69785796 -0.64463854 -0.68277377 -0.24967586
 -0.19240326 -0.55623595 -0.43393712 -0.20488009 -0.42467688 -0.42973863
 -0.7587096  -0.00863454 -0.55504504 -0.72359557 -0.23332295 -0.44639444
 -0.36801025 -0.38566534 -0.68157942 -0.66330741 -0.66678343 -0.23168773
 -0.13218956 -0.11188988 -0.33439992 -0.11339325 -0.58261526 -0.71247398
 -0.48478847 -0.66569591 -0.15518033 -0.09784696 -0.45237109 -0.26679828
 -0.19803658  0.02332215  0.18210187  0.49594858  0.05653449  0.22453704
 -0.08722536 -0.02982696 -0.050338    0.00257897  0.24073538  0.05772053
  0.03209141  0.18598012  0.21489005  0.27226397  0.17418933 -0.19653226
  0.22368378  0.19695265 -0.22390095  0.41875321  0.18313139  0.19804243
  0.04426236  0.46396343  0.30816008  0.13148766  0.20342581  0.29026943
  0.34072556 -0.1957556   0.53051311  0.54272288 -0.12018322  0.31804162
 -0.13135101 -0.06110464  0.3594243   0.00309373  0.00397033 -0.01499675
  0.33161667 -0.08477054 -0.23474653  0.28429004 -0.00579283 -0.39875387
 -0.07211248 -0.36781666 -0.05217456 -0.02620123  0.14274666  0.1926403
  0.35976552 -0.26686253 -0.34183679  0.19744795  0.15265403  0.18724555
  0.20698456  0.13030364  0.61129419  0.22600148  0.11662009  0.01916186
  0.20174428  0.18904739  0.11172859  0.12039883 -0.02999675  0.47269447
  0.21135921  0.33243421  0.16365583  0.17017694  0.02537226  0.45891092
  0.162098   -0.06818499  0.04947735  0.01306152  0.24752092  0.03165691
  0.11362733 -0.19762669 -0.01441732  0.13176873  0.25706992 -0.20683136
 -0.05660525  0.28285441 -0.01459906 -0.05297234  0.08103834  0.26899877
 -0.01892379  0.01752654]
Pearson r: 0.591
MSE: 0.809
Fold 2, k_feat 256
X_train.shape:  (268, 256)
y_pred:  [-0.72453446 -0.58243898 -0.5479461  -0.62206425 -0.53853505 -0.9923623
 -0.67283001 -0.73153732 -0.76792539 -0.76392939 -0.5260701  -0.53270989
 -0.50350624 -0.87693862 -1.1256371  -0.7891193  -0.73039841 -0.44070433
 -0.33451981 -0.35355249 -0.81489692 -0.8134064  -0.53705408 -0.51148003
 -0.25912827  0.19857469  0.39949358  0.26107345  0.41744372  0.16038754
  0.0117048  -0.02606702 -0.33603553 -0.02493823  0.11069048  0.4067846
  0.22239046 -0.51722222  0.18356483  0.05899551  0.33232249  0.31446669
  0.16220372  0.32403618 -0.06143476  0.0852456   0.46679861  0.36012491
  0.26232696  0.11623403  0.19472119  0.27025597  0.19325444  0.15333267
  0.32073829  0.46572172  0.13342945  0.42893971  0.1057283   0.3247383
  0.1724069   0.27133642  0.1258536   0.31548761  0.13462341 -0.01466852
  0.02022509  0.23764104  0.23173391  0.27937638  0.17575447  0.2421174
  0.0745628  -0.0317501   0.06794647  0.10542606  0.17407319 -0.07043528
  0.11380518 -0.39951925 -0.56493064  0.0319951  -0.28301357  0.08129829
 -0.34428555 -0.11074926  0.4911221   0.06075431 -0.21836501 -0.01269611
  0.09302325 -0.24941412  0.49934615  0.09117017  0.28223283  0.14343348
 -0.03739788  0.17855314  0.18281162  0.1636764   0.22543948  0.18563238
  0.05787614 -0.0125925   0.04964767  0.21919754  0.04495529 -0.26450697
 -0.20461026  0.22778243 -0.35909893 -0.01118067  0.38609929 -0.03378015
  0.55818244 -0.45836857  0.0425699   0.22475747  0.56644036 -0.35520903
  0.12845489  0.20153605  0.08083183 -0.69606979  0.22976928  0.43762495
  0.09044114  0.00591083  0.3172053  -0.09019696 -0.06681462 -0.02960435
  0.01281903  0.02347216]
Pearson r: 0.615
MSE: 0.552
Fold 3, k_feat 256
X_train.shape:  (268, 256)
y_pred:  [-0.68914323 -0.68275319 -0.70665819 -0.68771708 -0.670039   -0.67349838
 -0.72628341 -0.87045955 -0.69735229 -0.67350543 -0.35722385 -0.39813825
 -0.623515   -0.73345976 -0.71063651 -0.81768974 -0.81383834 -0.54702806
 -0.5622828  -0.71573398 -0.67613884 -0.67645465 -0.36992788 -0.3309377
 -0.65810158 -0.19383711 -0.65337508 -0.491286   -0.55213138 -0.11839581
  0.40023313  0.25714282  0.43092071  0.20842208  0.29787429  0.10237979
 -0.34210577  0.28976622  0.28602793  0.48600312  0.32559212  0.16670233
 -0.44371504  0.20400347  0.28753406  0.30294709 -0.36057235  0.06867246
  0.03730833  0.04547627  0.16028923 -0.15784173  0.01698783  0.28471836
  0.16452084  0.20744499  0.26348318 -0.18744475 -0.23973394 -0.02892353
  0.26585391  0.49164895 -0.1783561   0.19523318  0.13730579 -0.06160486
  0.0809317   0.01580068  0.01809133  0.07975253  0.0729376   0.06116255
  0.32554266  0.16867933 -0.30431165 -0.44106503 -0.43134562 -0.68335336
 -0.08400108  0.19805359  0.0854729   0.23300937 -0.08304233  0.0413515
  0.13230307  0.19964985  0.05201634  0.31063766 -0.10601681  0.0043175
  0.1333213   0.1258836   0.10299485 -0.10556691 -0.05866796  0.23317618
  0.52211738  0.18228545  0.35708113 -0.15574064  0.02597218  0.06234938
 -0.02033776  0.23339661 -0.18604679  0.17912358  0.22113743 -0.01238999
  0.12117587  0.38126548  0.11402794  0.46355313  0.26881231  0.34639351
  0.16755622  0.03083186 -0.10018784  0.17216757  0.10809135  0.20457699
  0.43676899  0.33916864  0.05936152  0.29150743  0.31198385  0.44914003
 -0.09012109 -0.20658427  0.00990886  0.3356235  -0.30106539  0.24188506
 -0.33304757  0.24518133]
Pearson r: 0.626
MSE: 0.835
Average pearson_r accross all folds = 0.6105881846757918
Average mse accross all folds = 0.731948647543183
Fold 1, k_feat 512
X_train.shape:  (268, 512)
y_pred:  [-6.93634521e-01 -6.00238440e-01 -7.01862862e-01 -5.65568222e-01
 -6.76027249e-01 -2.74074065e-01 -2.17363735e-01 -3.95165219e-01
 -4.37686721e-01 -1.02028047e-01 -3.67121012e-01 -4.54906462e-01
 -6.43397883e-01 -6.89496590e-02 -5.54105901e-01 -6.41115520e-01
 -2.70928007e-01 -3.84329000e-01 -3.75503481e-01 -3.89391943e-01
 -5.36700694e-01 -7.03242011e-01 -6.63293168e-01 -2.64369729e-01
 -1.56415740e-01 -1.12909706e-01 -3.20052994e-01 -1.78559710e-01
 -5.26286750e-01 -5.82819039e-01 -5.13834892e-01 -5.92355968e-01
 -1.87381263e-01 -1.45479791e-01 -3.96540933e-01 -3.78341517e-01
 -1.97448487e-01  1.09123218e-01  1.76924645e-01  5.36591955e-01
  5.54045561e-02  1.92546447e-01 -5.87002878e-02 -3.82242272e-02
  8.03227760e-03 -2.86060263e-02  2.31038592e-01  8.16739239e-03
  1.02282238e-01  1.67586229e-01  1.76752589e-01  2.13258009e-01
  2.28672086e-01 -2.48240324e-01  2.08571637e-01  1.94574556e-01
 -1.70534401e-01  4.37651102e-01  2.27023336e-01  1.90949117e-01
  1.78849845e-01  4.75968161e-01  2.75836120e-01  1.10823278e-01
  2.14198555e-01  1.94066708e-01  2.74012781e-01 -1.64058552e-01
  5.20348496e-01  4.50912463e-01 -1.08020456e-01  2.72388169e-01
 -1.20671780e-01 -5.58762196e-02  4.00792162e-01  7.88082387e-02
 -1.29996740e-02  5.86735876e-02  2.50310959e-01 -1.62157606e-01
 -2.40369154e-01  2.53589547e-01  4.20716126e-02 -2.68412400e-01
  3.47631803e-02 -2.16600679e-01 -3.52119944e-02  6.41470671e-03
  1.26707149e-01  8.38039566e-02  3.50941877e-01 -2.09420893e-01
 -2.52897687e-01  7.82612990e-02  1.54937608e-01  1.81171748e-01
  2.42139773e-01  1.78309858e-01  5.42398880e-01  2.41377953e-01
 -9.79983508e-03  1.47817968e-02  2.88303390e-01  1.76622725e-01
  1.41432410e-01  1.63921175e-01 -4.82554390e-02  3.79041148e-01
  3.09027258e-01  3.49602345e-01  2.00234010e-01  2.23820397e-01
  3.19782845e-02  4.58857485e-01  1.45774567e-01  7.27613971e-02
  4.80748724e-02  4.45953380e-02  2.88681384e-01  1.05661859e-01
  1.28126491e-01 -1.62481925e-01  2.30148693e-02  1.94006070e-01
  3.25034407e-01 -1.73297008e-01 -1.13593120e-02  3.47294688e-01
  5.23971612e-02 -2.94012063e-04  1.56629616e-01  3.31716893e-01
  5.04612772e-02  1.17181215e-01]
Pearson r: 0.587
MSE: 0.826
Fold 2, k_feat 512
X_train.shape:  (268, 512)
y_pred:  [-0.57303812 -0.51509836 -0.45874509 -0.56511227 -0.53333004 -0.95896527
 -0.60103514 -0.70754835 -0.71916675 -0.62577147 -0.55994172 -0.56588469
 -0.54567006 -0.84379282 -1.06496899 -0.72286246 -0.62020323 -0.39658054
 -0.32378585 -0.22820534 -0.68199974 -0.86530538 -0.64295501 -0.58188362
 -0.29269069  0.15558277  0.26106654  0.23786682  0.21465896  0.14841221
  0.04847206  0.04985622 -0.23567851 -0.01359389  0.13190012  0.30635563
  0.22412855 -0.50776879  0.25972656  0.08213849  0.31762398  0.3449533
  0.05908276  0.24360512  0.04909671  0.04254186  0.49260856  0.37190261
  0.23008027  0.24324584  0.30016157  0.29844691  0.25930986  0.12080024
  0.42923158  0.51851052  0.23962487  0.43607388  0.17803053  0.29758906
  0.22546304  0.30683969  0.21723247  0.38716801  0.14611147  0.02321373
  0.13662211  0.23996446  0.20146619  0.30890389  0.16540415  0.3118937
  0.14004161  0.14480116  0.04707746  0.14034878  0.30539204 -0.05811791
  0.04363032 -0.35360284 -0.50006853 -0.11400195 -0.23018297  0.08638812
 -0.29778084  0.03428603  0.51654768  0.08385296 -0.15289209  0.05759628
  0.15199493 -0.13529319  0.61589274  0.24900376  0.20488377  0.29197807
 -0.03803786  0.19512136  0.25644775  0.21468049  0.12751002  0.31414606
  0.19039178 -0.01553704  0.2050745   0.37963564 -0.05786208 -0.15774711
  0.02680263  0.28864021 -0.24334784  0.19068262  0.4419147   0.09184413
  0.6102749  -0.35099338  0.17692892  0.29951563  0.52143731 -0.24518494
  0.05542445  0.18033009  0.05932608 -0.55653427  0.29100209  0.42339506
  0.18072944  0.14127332  0.28928301 -0.03643766 -0.01503995 -0.05124891
  0.13307571  0.10287549]
Pearson r: 0.642
MSE: 0.520
Fold 3, k_feat 512
X_train.shape:  (268, 512)
y_pred:  [-0.64793183 -0.53798815 -0.60146086 -0.66987526 -0.64445467 -0.61291803
 -0.66451482 -0.80065514 -0.67817086 -0.76338985 -0.45317879 -0.45835225
 -0.56742303 -0.66719694 -0.79688546 -0.78913196 -0.79208577 -0.60278095
 -0.68297706 -0.66086474 -0.62625949 -0.64506297 -0.29241274 -0.40778654
 -0.57195058 -0.19175343 -0.58501763 -0.63283946 -0.51151618 -0.01446081
  0.32166503  0.21015621  0.30346857  0.15770662  0.27832724  0.01667092
 -0.22297283  0.29447059  0.24956105  0.43970291  0.34668259  0.1856138
 -0.35699657  0.26922134  0.21980529  0.16346971 -0.28822102  0.0074818
 -0.06523118  0.1466625   0.05952079 -0.03744581  0.12267521  0.12301909
  0.10087462  0.12002228  0.23751009 -0.02072169 -0.12312477 -0.04805257
  0.16225177  0.33727887 -0.17838286  0.08349152  0.06137795  0.02708517
  0.04113922  0.09337447  0.04181233  0.08525941  0.13326458  0.08297714
  0.25152785  0.07831736 -0.33600719 -0.34559596 -0.45350718 -0.49575819
 -0.07402284  0.17981444  0.13049946  0.28816138 -0.0551984   0.13511543
  0.19388055 -0.00421792 -0.05443729  0.34496523  0.03133906  0.09236834
  0.1285482   0.1619633   0.06560033 -0.0696118  -0.05437288  0.12341364
  0.41188233  0.22139037  0.257944   -0.11902222  0.03953601  0.05664891
 -0.09946631  0.279212   -0.03742984  0.2027817   0.20975856  0.11907437
  0.0680938   0.25981861  0.15216418  0.42304291  0.16126289  0.34192795
  0.20086305  0.04813174 -0.07902835  0.2380638   0.17259156  0.20272204
  0.32680709  0.21540735  0.06449444  0.25223601  0.34342007  0.34583161
 -0.00304336 -0.06373997  0.02802637  0.300245   -0.21778509  0.20897659
 -0.26302485  0.16858209]
Pearson r: 0.657
MSE: 0.829
Average pearson_r accross all folds = 0.6287636578129165
Average mse accross all folds = 0.7249792423990827
Fold 1, k_feat 1024
X_train.shape:  (268, 1024)
y_pred:  [-0.52726843 -0.49817396 -0.5322664  -0.54642456 -0.54213924 -0.29721088
 -0.27033087 -0.41349004 -0.4058566  -0.13683048 -0.41620955 -0.39152743
 -0.56085077 -0.02486782 -0.48351048 -0.59593041 -0.28983422 -0.37320038
 -0.38391039 -0.38125106 -0.63206259 -0.68297819 -0.64812549 -0.23736449
 -0.22568832 -0.16948054 -0.36599768 -0.23100417 -0.44692241 -0.61875775
 -0.57388721 -0.60196134 -0.25098495 -0.18030394 -0.43128609 -0.47201489
 -0.19106147  0.12312816  0.15230062  0.45158229  0.10053581  0.23248449
 -0.04150699  0.00102747  0.03895948 -0.01479957  0.18971685  0.01980899
  0.12506551  0.13173563  0.24534249  0.33381073  0.29654006 -0.12939988
  0.24146719  0.16514758 -0.21413682  0.40434259  0.21411973  0.06445153
  0.26367892  0.38292033  0.26993538 -0.00964094  0.29708722  0.07770856
  0.32603905 -0.20379495  0.57138467  0.40663486  0.02803088  0.18943531
 -0.07345496 -0.05308513  0.32820328  0.10413785  0.01036602  0.11765315
  0.1173066  -0.09538798 -0.07010392  0.21716969  0.07327677 -0.21379971
  0.03351894 -0.20044492  0.04049512  0.09917605  0.17660832  0.02342667
  0.34275623 -0.1046224  -0.13219422  0.09886027  0.19967775  0.20277359
  0.24927026  0.10425621  0.47076375  0.2427465   0.00191409  0.07576171
  0.23828473  0.24480546  0.15468154  0.17127628 -0.00336661  0.30722086
  0.42830873  0.27350472  0.25130186  0.18819694  0.05905666  0.41962505
  0.10920172  0.11776933  0.07131427 -0.00657896  0.32302887  0.19175693
  0.14990459 -0.04444063  0.06105119  0.25896821  0.37149625 -0.06263197
 -0.03269992  0.4050665   0.10824475  0.01883326  0.18947147  0.37465765
  0.08023548  0.19656264]
Pearson r: 0.596
MSE: 0.832
Fold 2, k_feat 1024
X_train.shape:  (268, 1024)
y_pred:  [-0.49854976 -0.47519196 -0.44717416 -0.54963319 -0.47427434 -0.78880095
 -0.45572439 -0.69499092 -0.64156513 -0.55416543 -0.54291777 -0.55391702
 -0.53939361 -0.66137191 -0.97479382 -0.54966349 -0.55939585 -0.36853768
 -0.2701538  -0.19755113 -0.56022876 -0.72591881 -0.7149467  -0.58411039
 -0.23484226  0.21748061  0.23000588  0.30258432  0.21103137  0.1631399
  0.01990597  0.01127217 -0.14668534  0.12712686  0.10546101  0.18133139
  0.20343563 -0.28453462  0.19219951  0.12484162  0.12451742  0.24081935
 -0.00813298  0.14628712  0.0296821  -0.01680703  0.33340124  0.20743479
  0.01723322  0.14548099  0.29977713  0.27016894  0.23417966  0.15569046
  0.37611943  0.40569466  0.28926902  0.43568476  0.10531234  0.26712651
  0.1728375   0.25044811  0.20802068  0.3241004   0.10012735  0.07059306
  0.1353373   0.17969485  0.14661152  0.21581293  0.12694085  0.23911165
  0.18705849  0.1044932   0.05810582  0.13155208  0.25430862 -0.06768619
  0.05018458 -0.24995799 -0.32169032 -0.17722732 -0.16712201 -0.05422935
 -0.26753849  0.0211652   0.41890603  0.12272135 -0.16038443 -0.13129573
  0.06680028 -0.08933606  0.49939567  0.22564042  0.03952189  0.34238396
 -0.10102324  0.11755552  0.19658541  0.17362795  0.08341964  0.24047252
  0.19090865  0.02320623  0.26988735  0.39164377 -0.05159442 -0.04727536
  0.1322646   0.25520353 -0.15473712  0.1875966   0.3395241   0.1751313
  0.42116616 -0.2670401   0.17653193  0.18608644  0.35424011 -0.17772256
  0.05787554  0.03706022  0.11144235 -0.33760067  0.29698133  0.29980344
  0.13758614  0.17754697  0.2502733   0.08720759  0.0926809   0.02113048
  0.17810607  0.11271486]
Pearson r: 0.679
MSE: 0.524
Fold 3, k_feat 1024
X_train.shape:  (268, 1024)
y_pred:  [-0.61032121 -0.47857888 -0.50242765 -0.57603784 -0.54875707 -0.53001826
 -0.58896638 -0.81559052 -0.62733911 -0.68185119 -0.34650395 -0.35471531
 -0.42544168 -0.64130358 -0.67681762 -0.70614294 -0.70702605 -0.59683057
 -0.72519488 -0.6472639  -0.56709205 -0.54238286 -0.17992383 -0.42577474
 -0.51357213 -0.22264775 -0.5094319  -0.58957034 -0.51392156  0.18508135
  0.2340795   0.24316586  0.18579821  0.18387211  0.21588602  0.13750195
 -0.0174485   0.32297273  0.29537373  0.46685247  0.42058616  0.20415045
 -0.22062281  0.24838074  0.14932933  0.08555804 -0.23425051  0.03599475
 -0.06004769  0.17456086  0.148395    0.06387262  0.23196607  0.13462482
  0.1745117   0.20271422  0.19444734  0.17620932 -0.03415754 -0.02873269
  0.19490135  0.2662135  -0.09495359  0.08634913  0.08578289  0.06430461
  0.10562789  0.13644782  0.11096648  0.109866    0.24335735  0.10777199
  0.13367577 -0.04069591 -0.34713176 -0.33656862 -0.36446376 -0.39066771
 -0.09833167  0.15838705  0.17702964  0.23093785 -0.02160899  0.12739537
  0.16843062 -0.00881424 -0.05991297  0.28408127  0.06955629  0.10262617
  0.05192117  0.11602053  0.03111877 -0.11917605 -0.06884851  0.10992942
  0.34115871  0.22582084  0.21248231 -0.17565615  0.08833241  0.09812756
 -0.11188799  0.21321102  0.12686545  0.27040158  0.27762067  0.25473259
  0.04097031  0.24940388  0.18692282  0.38112121  0.22663409  0.30633418
  0.23692923  0.06950691 -0.11377477  0.28902445  0.16082948  0.16563893
  0.18591547  0.21056379  0.19026027  0.23135863  0.31714263  0.33426791
 -0.03454997  0.08739378  0.08862565  0.2411473  -0.22039469  0.13887591
 -0.24582442  0.08737602]
Pearson r: 0.698
MSE: 0.816
Average pearson_r accross all folds = 0.6574894934338394
Average mse accross all folds = 0.7240202710204175
Fold 1, k_feat 2048
X_train.shape:  (268, 2048)
y_pred:  [-5.37670650e-01 -5.24942045e-01 -5.36861250e-01 -4.92366257e-01
 -5.35097941e-01 -3.04109401e-01 -2.32563288e-01 -3.47437341e-01
 -3.23509922e-01 -8.09752349e-02 -4.20887431e-01 -3.70362679e-01
 -5.17153481e-01 -2.19958552e-04 -4.48012677e-01 -5.37997080e-01
 -1.92823133e-01 -2.44581242e-01 -3.78351709e-01 -3.35144800e-01
 -7.63022740e-01 -7.90486389e-01 -7.68542917e-01 -1.44734421e-01
 -2.14730249e-01 -4.20725810e-02 -3.50922869e-01 -2.66889983e-01
 -3.67139387e-01 -8.15401985e-01 -6.72184830e-01 -7.03680145e-01
 -2.53482289e-01 -1.87750492e-01 -4.45633770e-01 -6.45908497e-01
 -7.59818114e-02  1.83132223e-01  1.80176441e-01  4.59249579e-01
  1.99749853e-01  3.25725225e-01 -7.82476546e-02  8.73693098e-02
  1.28789403e-01 -3.23879638e-02  2.77251963e-01 -4.87257432e-02
  1.45330756e-01  1.90958338e-01  3.54598949e-01  3.33597529e-01
  3.18538231e-01 -4.82656633e-02  2.02004375e-01  1.54994443e-01
 -2.68290661e-01  3.89657097e-01  2.37621375e-01 -1.92196495e-01
  2.57701428e-01  3.09577899e-01  3.74190508e-01 -2.31509334e-02
  3.65895203e-01  2.79501279e-02  3.00608345e-01 -3.30757716e-01
  5.68327613e-01  4.63386435e-01  1.51698847e-01  1.71500456e-01
  7.78697519e-02 -1.46927222e-01  2.67340667e-01  4.64880525e-02
 -5.30198942e-02 -1.11873077e-02 -2.59132386e-02 -1.53755988e-01
 -9.44772902e-02  2.36933769e-01  7.02594542e-02 -4.14501414e-01
 -9.75134732e-02 -2.34168568e-01  3.32452688e-02  9.18087585e-02
  2.42323108e-01 -1.24856842e-01  3.40164809e-01 -1.21987811e-01
 -7.47447926e-02  1.03539724e-01  2.27084457e-01  2.92602034e-01
  2.35703179e-01  1.89428168e-02  4.05818402e-01  2.61779743e-01
  3.82491505e-02  1.84623814e-01  1.16283691e-01  2.98518992e-01
  1.77360056e-01  1.92959743e-01  3.23645013e-02  1.74862846e-01
  4.30758619e-01  1.71935277e-01  3.45897481e-01  9.93658443e-02
  6.81982269e-02  3.11423531e-01  5.04643924e-02  1.55507617e-01
  1.27689975e-01 -7.62464173e-02  2.93301277e-01  1.64957671e-01
  2.38786529e-01 -1.69499893e-02  4.27813280e-02  3.34008739e-01
  3.50664136e-01  7.35189259e-02  9.95084034e-04  3.74956610e-01
  4.22796450e-02  9.86269203e-02  1.33952078e-01  3.52427860e-01
 -4.24911606e-04  1.89342440e-01]
Pearson r: 0.577
MSE: 0.835
Fold 2, k_feat 2048
X_train.shape:  (268, 2048)
y_pred:  [-4.79645259e-01 -4.32230326e-01 -4.55755145e-01 -5.47426602e-01
 -3.80802876e-01 -6.46375715e-01 -3.03369716e-01 -6.29654619e-01
 -5.38018721e-01 -3.84573962e-01 -5.09451236e-01 -5.17738725e-01
 -4.97081402e-01 -5.48625595e-01 -8.72037078e-01 -4.34739497e-01
 -4.38271076e-01 -3.09718105e-01 -2.46606740e-01 -2.01030206e-01
 -4.69340901e-01 -7.20203899e-01 -7.11138802e-01 -5.98977865e-01
 -1.35638113e-01  3.14593716e-01  2.70098453e-01  3.55763725e-01
  3.08162842e-01  2.63409599e-01  1.92443679e-02 -2.43449289e-02
 -8.45105328e-02  1.39310227e-01  3.25555198e-02  1.46391695e-01
  2.07173077e-01 -5.75515629e-02  2.05869634e-01  2.38497906e-01
  1.28247513e-01  2.14160465e-01  1.68681927e-02  1.37027478e-01
  6.68157738e-02  7.15816724e-03  2.00842166e-01  1.87848685e-01
 -7.14642852e-02  1.83715172e-01  2.57800991e-01  2.45905306e-01
  1.80607312e-01  1.47197995e-01  2.50872702e-01  2.82708333e-01
  2.92334464e-01  4.33207907e-01  1.65359687e-01  1.64557799e-01
  1.52808743e-01  1.57294776e-01  1.31842891e-01  2.29698020e-01
 -1.78341676e-02  8.19379626e-02  6.58252257e-02  1.08725978e-01
  8.35762947e-02  1.24576232e-01  1.22731322e-01  1.82957762e-01
  2.15924652e-01  9.09395616e-02  6.05308474e-03  6.13911336e-02
  2.45273257e-01 -1.47493569e-01  1.99801873e-02 -2.33932979e-01
 -3.11415706e-01 -1.43566443e-01 -1.49253193e-02 -1.27477341e-01
 -2.41380500e-01 -1.92107147e-03  3.12049893e-01  5.63046421e-02
 -1.16544032e-01 -1.31666671e-01  7.82085336e-02 -9.27285773e-05
  4.35894231e-01  1.96968404e-01 -1.57465273e-01  3.12329002e-01
 -1.02716340e-01  1.02657317e-02  1.83522347e-01  1.53179656e-01
  8.03200691e-02  1.52058516e-01  1.56640219e-01 -6.77851522e-03
  3.06770971e-01  2.98692347e-01 -1.22180014e-01 -8.79902286e-03
  1.70111759e-01  2.34600758e-01 -6.57302087e-02  2.10036531e-01
  2.99700868e-01  1.63642383e-01  4.20421734e-01 -6.12428216e-02
  1.92422500e-01  1.18155935e-01  2.34035473e-01 -1.37205876e-01
  1.06939882e-01  1.97822677e-02  9.55476441e-02 -2.89302864e-01
  2.66049399e-01  3.21285855e-01  1.01806313e-01  1.64535070e-01
  2.87751726e-01  8.56070360e-02  7.26161127e-02  4.40482107e-02
  1.33442107e-01  1.19148439e-01]
Pearson r: 0.689
MSE: 0.538
Fold 3, k_feat 2048
X_train.shape:  (268, 2048)
y_pred:  [-0.61047693 -0.42869603 -0.54558255 -0.55447431 -0.45263431 -0.46384249
 -0.56153637 -0.73506031 -0.59205574 -0.62559544 -0.35125299 -0.32924246
 -0.37418481 -0.6426777  -0.63183446 -0.67595179 -0.67704223 -0.61655989
 -0.70681576 -0.66022136 -0.61490456 -0.52258174 -0.18045164 -0.44515779
 -0.3946616  -0.32055112 -0.46266025 -0.49588146 -0.54793395  0.18526724
  0.1206085   0.17417877  0.07824688  0.0928933   0.12913564  0.17154841
  0.098837    0.28708479  0.25777758  0.39955566  0.37406099  0.23181264
 -0.17653145  0.28980168  0.11465323  0.03888962 -0.3002977   0.11126709
  0.01046545  0.16999771  0.11403231  0.12823435  0.23054521  0.09948523
  0.26504275  0.26418076  0.13271655  0.17474827  0.05681871  0.00955797
  0.17756917  0.24332038 -0.07322374  0.14690835  0.11378908  0.05401687
  0.20322208  0.16110712  0.22250694  0.03745794  0.28010392  0.09070938
  0.15199925 -0.12121555 -0.295167   -0.32966025 -0.3054856  -0.29177797
 -0.11794565  0.0781733   0.17440412  0.12299728 -0.01211768  0.15166346
  0.18742239  0.01565093  0.01411666  0.28695393  0.097357    0.13460484
  0.04578288  0.10049848  0.01565472 -0.25696329 -0.00429432  0.18859419
  0.24488659  0.16565235  0.21236123 -0.17866781  0.1035331   0.11062737
 -0.04565274  0.15727675  0.22400156  0.28930897  0.27694124  0.29138924
  0.06581694  0.27327765  0.21927727  0.32439879  0.15892821  0.28086217
  0.26443888  0.00709787 -0.10863723  0.28212487  0.12324319  0.16068291
  0.1497275   0.16344258  0.18371469  0.17824214  0.26119403  0.23567048
 -0.0469164   0.13404068  0.0447805   0.12305075 -0.19497795  0.05201258
 -0.22178387  0.01740856]
Pearson r: 0.701
MSE: 0.827
Average pearson_r accross all folds = 0.6555340969159843
Average mse accross all folds = 0.7333102851071548
Fold 1, k_feat 4096
X_train.shape:  (268, 4096)
y_pred:  [-0.39087602 -0.37997134 -0.39084187 -0.31183086 -0.34129678 -0.21436633
 -0.13298637 -0.26017331 -0.16653917  0.05146793 -0.30491081 -0.21389442
 -0.33454219 -0.00809862 -0.25269887 -0.33874114 -0.14887709 -0.16250223
 -0.27006728 -0.27513209 -0.48174373 -0.63690341 -0.52677488 -0.06491339
 -0.15820323 -0.02808213 -0.2849218  -0.14298744 -0.24316156 -0.70946051
 -0.5750837  -0.65687976 -0.16175139 -0.11220287 -0.32364928 -0.50346191
  0.00523475  0.21375169  0.19514356  0.46269476  0.2486796   0.29801148
  0.01009274  0.09118651  0.06047794 -0.05497684  0.23421629  0.03299392
  0.19893916  0.2568825   0.28234697  0.2979916   0.33000666  0.05223639
  0.16466924  0.14711282 -0.30334128  0.37888885  0.23504938 -0.10809468
  0.19693036  0.28796336  0.37925313  0.02233743  0.28184965  0.04794951
  0.25713505 -0.18945775  0.52667243  0.42350547  0.15995949  0.16013684
  0.07760142 -0.07055157  0.28330326  0.01672641 -0.06372028 -0.0782399
  0.01830186 -0.21978829 -0.15973899  0.24101616  0.07042576 -0.2239079
 -0.13779195 -0.23179116 -0.05530332  0.04432653  0.15179093 -0.08031192
  0.22837533 -0.05900629 -0.05088785  0.0995424   0.19622129  0.25933417
  0.20883799  0.05207769  0.32287497  0.25539337  0.05699776  0.1981507
  0.11435691  0.21748227  0.12712052  0.21157329  0.14312912  0.19297261
  0.36464258  0.18455528  0.32253753  0.18914649  0.13054665  0.31000114
  0.1005537   0.15766688  0.16442642 -0.01741044  0.28554997  0.09311589
  0.20804081 -0.08989568  0.09246849  0.29129308  0.36364965 -0.04345915
  0.03113709  0.3878572   0.00213962  0.16782045  0.14682363  0.36099432
 -0.04329517  0.14712124]
Pearson r: 0.598
MSE: 0.874
Fold 2, k_feat 4096
X_train.shape:  (268, 4096)
y_pred:  [-0.35223808 -0.42563618 -0.47242345 -0.39262886 -0.37721647 -0.56466101
 -0.17651168 -0.5625354  -0.43534892 -0.24530808 -0.47141088 -0.4765074
 -0.45398894 -0.46781873 -0.78318766 -0.37164314 -0.32120114 -0.27885665
 -0.20835156 -0.20064427 -0.31105957 -0.6839872  -0.66960147 -0.60678255
 -0.1140695   0.29821676  0.20962516  0.32545664  0.29951433  0.20990437
 -0.02927356 -0.08581657 -0.07218897  0.11999284  0.05503796  0.08567945
  0.10824343  0.01679915  0.26077198  0.25723957  0.10618038  0.21083325
  0.02846861  0.17614739  0.10753036  0.02599096  0.23446438  0.15275793
  0.03641167  0.2290754   0.23838449  0.19353819  0.15596306  0.1191416
  0.19094998  0.23800203  0.24923977  0.39365999  0.14233957  0.1643185
  0.16196395  0.15532363  0.1473109   0.23448516  0.00517711  0.08096971
  0.1012207   0.12873528  0.08901518  0.05272086  0.11211036  0.18456084
  0.17497251  0.02185531  0.0800861   0.07918097  0.32939288 -0.14661958
  0.03096561 -0.27596108 -0.3386581  -0.17863087 -0.02593399 -0.25773666
 -0.11685344 -0.00441199  0.24024768 -0.00413785 -0.05000821 -0.08415444
  0.05250566  0.05263584  0.37977299  0.19297067 -0.22759077  0.32128243
  0.02572918  0.03328743  0.15124604  0.20587742  0.00804761  0.04420151
  0.13648301 -0.06082134  0.29120571  0.27374619 -0.17887112 -0.02574385
  0.22298013  0.19183511  0.01903079  0.2149452   0.26115422  0.17317786
  0.37147717  0.06068768  0.17950093  0.1673348   0.17047985 -0.04000087
  0.11459417  0.00121127  0.0327212  -0.23622247  0.1682367   0.30615238
  0.06860453  0.09673286  0.27603547  0.02606999 -0.00518039 -0.02790706
  0.0531345   0.07572932]
Pearson r: 0.691
MSE: 0.553
Fold 3, k_feat 4096
X_train.shape:  (268, 4096)
y_pred:  [-0.53719628 -0.36903274 -0.49884623 -0.48645662 -0.36196793 -0.47600488
 -0.50556292 -0.56878851 -0.48880463 -0.49660687 -0.3243576  -0.24640257
 -0.31453599 -0.58534549 -0.56720257 -0.51698295 -0.51669351 -0.59896352
 -0.62524739 -0.5746666  -0.54846149 -0.4820414  -0.17999138 -0.38458513
 -0.37031746 -0.23666217 -0.40292305 -0.47295609 -0.46552173  0.15695091
  0.06086004  0.13841745  0.0255659   0.06372169  0.07825803  0.12916028
  0.12296013  0.18647083  0.22939709  0.38259431  0.39215533  0.10717288
 -0.05983817  0.27934235  0.08770654  0.00596307 -0.22121827  0.12101663
 -0.02978014  0.2277905   0.0505541   0.17586615  0.16558948  0.06535752
  0.20880092  0.20896553  0.12471331  0.23576491  0.07833149 -0.00445315
  0.1281411   0.19730094 -0.02208396  0.07773938  0.12885151  0.03255343
  0.28847611  0.16712403  0.3200775   0.01868148  0.31216342 -0.04587868
  0.06594501 -0.15202221 -0.28790591 -0.25476986 -0.25689768 -0.27287549
 -0.14243272 -0.00318303  0.14010427  0.06939829 -0.04214143  0.0197153
  0.06326019 -0.06058855 -0.02655083  0.29926893  0.11881152  0.14483799
  0.09042299  0.1284626   0.04536721 -0.21138788  0.05183722  0.19532627
  0.14926887  0.10637444  0.12363192 -0.15739108  0.06158639  0.12866847
 -0.0150842   0.09839715  0.20458863  0.26684157  0.24586019  0.22075387
 -0.01032911  0.23767176  0.14125078  0.22125976  0.14590703  0.07818577
  0.15388838 -0.10868357 -0.12365302  0.15833327  0.00579783  0.15882936
  0.12875591  0.13514183  0.11631747  0.13608855  0.18395861  0.14780545
 -0.14475543  0.0573421   0.06162372  0.04223865 -0.24848069  0.00588401
 -0.2717342  -0.0129985 ]
Pearson r: 0.692
MSE: 0.874
Average pearson_r accross all folds = 0.6604473637259888
Average mse accross all folds = 0.7669846370396171
Fold 1, k_feat 8192
X_train.shape:  (268, 8192)
y_pred:  [-0.30651086 -0.31642099 -0.31174955 -0.20442799 -0.20704966 -0.11194256
 -0.0079021  -0.27496362 -0.1416758   0.03833766 -0.24308881 -0.09176964
 -0.27065553  0.02764236 -0.12964386 -0.22295181 -0.1284148  -0.07997094
 -0.18926378 -0.20275846 -0.42938823 -0.54453858 -0.51423116  0.01321817
 -0.10849034 -0.05355734 -0.22647993 -0.10441749 -0.22088201 -0.62704759
 -0.46350119 -0.59478881 -0.12951036 -0.07828317 -0.22356368 -0.49464057
  0.08249189  0.22681749  0.1859002   0.43033887  0.26241223  0.27829867
  0.06595555  0.09216562  0.08362061  0.00964888  0.21561389  0.08473148
  0.21070929  0.27665656  0.20741016  0.20759967  0.28066793  0.03184197
  0.10430861  0.13055604 -0.31846408  0.31831534  0.19363088 -0.05479729
  0.1439404   0.24445474  0.32743362  0.05702733  0.24458182  0.10032022
  0.19061702 -0.09874781  0.40616154  0.30678707  0.1476253   0.10527683
  0.04128398 -0.10059026  0.20418935 -0.10446239 -0.13019234 -0.11870982
  0.00382947 -0.27475816 -0.18413899  0.22764687  0.06695865 -0.1803771
 -0.0864437  -0.19356438 -0.05265247  0.019573    0.0476078  -0.11604708
  0.16465764 -0.04985391 -0.0681927   0.03374482  0.14318047  0.20115975
  0.1100075   0.02989719  0.25631709  0.19185782  0.09167461  0.21933306
  0.03539122  0.12875371  0.11968073  0.17005028  0.15231193  0.18324332
  0.25097417  0.13363887  0.25751558  0.22455735  0.11323843  0.24590661
  0.09253546  0.13750129  0.16015808 -0.00489678  0.23386268  0.04419022
  0.17781968 -0.13328609  0.10755718  0.24391427  0.37621941 -0.13299055
  0.03241129  0.37632483 -0.04395562  0.15548913  0.11536999  0.34961741
 -0.07130371  0.09950712]
Pearson r: 0.601
MSE: 0.900
Fold 2, k_feat 8192
X_train.shape:  (268, 8192)
y_pred:  [-3.66792291e-01 -4.19673990e-01 -4.38452018e-01 -3.98368422e-01
 -2.81041547e-01 -4.78026296e-01 -7.11137158e-02 -4.29068334e-01
 -3.32121766e-01 -1.10078482e-01 -3.43323266e-01 -3.45564956e-01
 -3.16227816e-01 -3.95747474e-01 -5.88396567e-01 -3.41039694e-01
 -2.07343427e-01 -1.91289121e-01 -1.10822178e-01 -1.54924304e-01
 -2.95200683e-01 -6.19725882e-01 -5.77315509e-01 -5.57401893e-01
 -1.09523807e-01  1.81788263e-01  1.36561169e-01  1.76436598e-01
  1.92778664e-01  1.45924638e-01 -5.85518102e-02 -1.07828083e-01
 -7.49983257e-02  6.62354919e-02 -6.36984187e-02  5.41345016e-02
  7.12816745e-02  7.37474708e-03  1.95620460e-01  1.68428433e-01
  1.28624031e-01  2.03797301e-01  6.15619137e-02  2.02974595e-01
  1.08511106e-01 -6.87026082e-02  1.71592497e-01  1.04257868e-01
  2.69758811e-02  2.47070710e-01  2.03491100e-01  1.39901950e-01
  1.70033593e-01  8.90926176e-02  1.32866255e-01  1.20466595e-01
  1.72105426e-01  3.53317042e-01  1.20324698e-01  2.12252763e-01
  1.34051405e-01  1.86143768e-01  1.93946016e-01  2.53574354e-01
  5.77297491e-02  6.40814411e-02  1.04502709e-01  1.40340876e-01
  1.07832754e-01  5.90863166e-03  9.06380661e-02  1.82288721e-01
  1.41086592e-01  4.42736043e-02  9.93691618e-02  1.04528415e-01
  2.70606559e-01 -2.33250253e-01 -7.39256425e-02 -3.47209332e-01
 -4.27681188e-01 -3.06162479e-01  3.01587151e-02 -3.03312959e-01
 -1.55401973e-01 -5.16807242e-02  1.77373959e-01 -9.02516043e-02
 -5.25017113e-02 -7.83799972e-02 -7.78809239e-03  4.67574948e-02
  2.44017241e-01  1.43498023e-01 -3.50484251e-01  2.49524281e-01
  3.77327479e-02 -2.34597712e-02  1.76297512e-01  1.28095454e-01
 -3.92952715e-02  1.32510973e-02  1.02981167e-01 -6.41160975e-02
  1.63828554e-01  1.83965557e-01 -1.48710701e-01 -6.27637136e-03
  1.53523410e-01  1.09318830e-01  1.07578571e-02  1.42011451e-01
  1.73204081e-01  8.79563246e-02  3.32618115e-01  1.39334425e-01
  1.80053851e-01  1.54626519e-01  1.40594005e-01 -2.42200601e-02
  1.09010319e-01  2.27640290e-02 -7.53823323e-02 -3.08117404e-01
  8.69767331e-02  1.52609927e-01  1.91527118e-02  4.09024047e-02
  1.34175332e-01 -1.06212347e-01 -1.57553294e-01 -5.69966609e-02
 -3.94581348e-04  2.34618807e-02]
Pearson r: 0.657
MSE: 0.600
Fold 3, k_feat 8192
X_train.shape:  (268, 8192)
y_pred:  [-0.42188531 -0.27690536 -0.39070831 -0.3531562  -0.20829357 -0.36512878
 -0.38482419 -0.3738694  -0.35491483 -0.33508043 -0.19143251 -0.0969836
 -0.13926996 -0.41669391 -0.40527691 -0.32713175 -0.32715649 -0.5185971
 -0.48403605 -0.48961544 -0.42574253 -0.35789824 -0.1092098  -0.28636548
 -0.30164794 -0.14144943 -0.26850123 -0.42906045 -0.28918961  0.19403633
  0.08257738  0.12304399  0.01506168  0.05759532  0.09546709  0.18691167
  0.17916536  0.16529371  0.17192744  0.32215261  0.30166811  0.04185589
  0.00630116  0.20908779  0.04651189 -0.02036108 -0.11400767  0.06810554
 -0.05431124  0.18816465  0.06339211  0.19320355  0.18395753  0.02850908
  0.12039474  0.10659632  0.13622433  0.18068256  0.04755025  0.04862341
  0.10993075  0.12631876 -0.0114802  -0.02312866  0.08527412 -0.03584191
  0.24156997  0.18561259  0.26114126  0.05123019  0.35697614 -0.05633659
  0.02774683 -0.21911863 -0.37821927 -0.30311715 -0.37653755 -0.32391015
 -0.16273909 -0.00819573  0.22226813  0.07610576 -0.06347766  0.04687419
  0.07932886 -0.02795584 -0.02265671  0.26235051  0.13301254  0.11166266
  0.08097805  0.0879875   0.038936   -0.17809096  0.04870452  0.16108382
  0.14273971  0.09443181  0.10804106 -0.13017596  0.00388968  0.08707494
 -0.02255742  0.08139275  0.2221621   0.1993862   0.18402615  0.22028247
 -0.01076947  0.1436643   0.10258791  0.10693312  0.09408722  0.05662751
  0.11257902 -0.05997076 -0.08258001  0.13188638 -0.00318803  0.10002727
  0.04491762  0.08037321  0.14822819  0.16590124  0.14866589  0.15912959
 -0.2756746   0.14464083  0.09186601  0.06339229 -0.36403784 -0.0088111
 -0.38626932 -0.02193504]
Pearson r: 0.693
MSE: 0.921
Average pearson_r accross all folds = 0.6504222055677767
Average mse accross all folds = 0.8070551499497395
