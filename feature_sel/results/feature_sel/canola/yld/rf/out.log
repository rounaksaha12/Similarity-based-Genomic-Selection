After clean(removal of rows with high missing values + redundancy removal) X.shape:  (402, 10792)
Fold 1, k_feat 8
X_train.shape:  (268, 8)
y_pred:  [-0.62837528 -0.52285794 -0.62837528 -0.62837528 -0.62837528 -0.52285794
 -0.52285794 -0.52285794 -0.62837528 -0.62837528 -0.52285794 -1.0594531
 -1.9888651   0.45883898 -0.90876649 -1.33094577 -1.33094577 -1.33094577
 -0.52285794 -1.05394439 -1.16979059 -1.16979059 -1.33094577 -1.33094577
 -0.22616229  0.8234072  -0.22616229 -0.52285794 -0.90876649 -0.50752707
 -0.52285794 -0.52285794 -0.22616229 -1.16979059 -0.90876649 -1.16979059
 -0.04433421  0.14081846  0.03174949  1.27811519  0.8234072   0.5635532
  0.17329111  0.1483527   0.45883898  0.5635532   0.5635532   0.1483527
  0.17329111  0.14081846  0.05744685  0.5635532   0.17329111  0.45883898
  0.14081846 -0.57222618  0.26648663  0.14081846 -1.33094577  0.36303954
  1.09345633  0.14081846  0.14081846 -1.33094577  0.14081846  0.05744685
  0.5635532   0.89606943  0.5635532   0.5635532   0.8234072   0.8234072
 -0.05298678  0.26648663  0.45883898  0.17329111 -0.52285794 -0.52285794
  0.5635532  -0.95990963  0.5635532   0.14081846  0.45883898 -0.66469002
  0.17329111  0.17329111 -0.52285794 -0.95990963  1.09345633  1.09345633
  0.26648663  0.03132769  0.03132769  0.14081846  0.5635532   0.1483527
  0.2934821  -0.22616229  0.14081846  0.14081846  0.45883898  0.1483527
  0.5635532   0.1483527   0.14081846  0.14081846  0.20399277  0.5635532
  1.09345633  0.2934821   0.36303954  0.03174949  0.5635532   0.5635532
  0.03174949  0.14081846  0.14081846  0.14081846  0.5635532  -0.52285794
  0.1483527  -0.52285794  0.1483527   0.5635532   1.02787073 -0.52285794
  0.1483527   1.09554171 -1.08847157 -1.14429143 -0.15323905  1.09554171
 -1.08847157 -0.77192843]
Pearson r: 0.448
MSE: 0.917
Fold 2, k_feat 8
X_train.shape:  (268, 8)
y_pred:  [-1.45911631 -0.59021581 -0.59021581 -1.45911631 -0.76618463 -1.03940812
 -0.59021581 -0.59021581 -0.59021581 -0.59021581  0.03062715  0.03062715
  0.03062715 -1.03940812 -1.45911631 -1.03940812 -0.76618463 -0.19853695
  0.03062715  0.03062715 -0.65871726 -1.45911631  0.26372114  0.03062715
 -0.19853695 -0.19853695  0.67524333  0.67524333  0.26940421  0.34395043
  0.513917    0.54217271 -0.59021581  0.01363071  0.13499227  0.16866257
  0.16866257 -1.03940812  0.54217271  0.28831302  0.54217271  0.513917
  0.513917    0.26940421 -0.32201642  0.16866257  0.54217271  0.54217271
  0.54217271  0.513917    0.28831302  0.16866257  0.28831302  0.28831302
  0.42243538  0.13499227  2.02437294  0.42243538  0.03062715  0.16866257
  0.16866257  0.34395043  0.34395043  0.34395043  0.16866257  0.54217271
  2.02437294  0.16866257  0.16866257  0.16866257  0.34395043  0.16866257
  0.16866257  0.513917    0.34395043  0.16866257  0.34395043 -1.03940812
  0.54217271 -1.03940812 -1.03940812  0.34395043  0.09829866  0.07051866
 -0.40684864 -0.52005744  0.54217271  0.67524333  0.09829866  0.513917
  0.54217271 -0.49573565  0.13499227  0.42243538  0.54217271  0.13499227
  0.54217271  0.67524333  0.42243538  0.35752833  0.54217271  0.16866257
  0.34395043  0.54217271  0.13499227  0.16866257  0.16866257  0.13499227
  0.42243538  0.54217271 -0.40684864 -0.03157318  0.54217271  0.67524333
  0.54217271 -0.59021581 -0.23334822  0.513917    0.7855799  -0.10242154
  0.513917    0.513917    0.54217271 -1.03940812  0.54217271  0.16866257
  0.34395043  0.34395043  0.16866257  0.54217271  0.54217271  0.16866257
  0.54217271  0.16866257]
Pearson r: 0.440
MSE: 0.656
Fold 3, k_feat 8
X_train.shape:  (268, 8)
y_pred:  [-1.23201509 -1.23201509 -1.42777603 -1.23201509 -1.00669962 -1.17242322
 -0.88216056 -0.94630973 -0.94630973 -1.42777603 -1.51404369 -1.51404369
 -1.00669962 -1.13516895 -0.94630973 -0.88216056 -0.88216056 -1.13346959
 -1.42777603 -0.94630973 -0.48108573 -1.00669962 -0.25120245 -0.32877285
 -0.69741097 -0.42592292 -0.88216056 -0.42592292 -1.23201509  0.60563797
  0.39101607  0.39101607  0.39101607  0.50390714 -0.32877285  0.39101607
 -0.71694781  0.98078784  0.31783046  0.33064949  0.31783046  0.40051877
 -1.30645403  0.12034753 -0.05808216  0.08574926  0.40496203  0.08574926
  0.04662754  0.98078784  0.34214327  0.75358694  0.63532145  0.08574926
  0.39101607  0.39101607  1.3291932   0.29922351  0.26053988  0.25817842
  0.60563797  0.60563797  0.23233613  0.34214327  0.63532145  0.60563797
  0.33038651  0.75358694  0.2653257   0.2653257   0.10672525  0.39101607
  0.41500747  0.39101607  0.75358694 -1.42777603 -0.05808216 -0.12868335
 -0.12868335 -0.05808216 -0.07391192  0.34214327 -0.12868335  0.39101607
  0.60563797  0.60563797  0.60563797  0.31783046  0.15215157  0.15215157
  0.98078784  0.15215157  0.15215157 -1.42777603  0.361999    0.2653257
  0.60563797  0.60563797  0.60563797  0.15253093  0.41500747  0.33038651
  0.60563797  0.63532145 -0.12868335  0.63532145  0.63532145 -0.05808216
  0.34214327  0.33064949  0.43133204  0.39101607  0.15215157  0.39101607
  0.12034753  0.15215157 -0.94630973  0.15215157  0.39101607  0.15215157
  0.33064949  0.31783046 -0.07391192  0.60563797  0.60563797  0.60563797
 -0.12868335 -0.71694781  0.60563797  0.60563797 -0.12868335  0.60563797
 -0.12868335  0.60563797]
Pearson r: 0.459
MSE: 0.971
Average pearson_r accross all folds = 0.4488731943509199
Average mse accross all folds = 0.8480461425292213
Fold 1, k_feat 16
X_train.shape:  (268, 16)
y_pred:  [-1.049311   -1.67126155 -1.049311   -1.22687368 -0.40812532 -1.37949391
 -1.49910473 -1.49910473 -0.92087256 -1.21816324 -1.49910473 -1.73657626
 -2.26939514  0.14037305 -1.20512145 -1.02917832 -1.70505872 -1.31598654
 -1.49910473 -1.21226631 -1.96158733 -1.96158733 -1.7937545  -1.02754451
 -0.21462164  0.29086319 -0.59342487 -0.52429783 -1.01307183 -0.90483428
 -1.16339416 -0.98772849 -0.22295043 -0.73803188 -0.74593038 -0.59172338
 -0.61265162 -0.11366268 -0.15130024  1.41528149  1.45211916  0.43737876
  0.2104839  -0.05779297  0.55195768  0.43045477  0.43737876  0.13636344
  0.67524666  0.00600641  0.02221272  0.40894757  0.71348287  0.84425684
  0.22470971  0.01565871 -1.82308476  0.32842706 -0.08628215  0.73921111
  1.32788156  0.44119606  0.37463773  0.12971411 -0.27682873  0.9263274
  0.51595633  0.00353785  0.63890713  0.63890713  0.29558655  0.74443815
 -0.25205861 -0.08945905  0.51170744 -0.48892851  0.62979853  0.62979853
  0.48411825 -0.99235916 -0.08130743  0.49303097  0.47676891 -1.06801123
 -0.76710907 -1.07815858 -0.7460882  -0.99235916  0.95644947  0.72046359
  0.24354545 -0.17030858 -0.26302905  0.22470971  0.33542332  0.43717585
  0.36005903  0.39578876  0.44119606  0.44119606  0.55195768  0.17426234
  0.40449323 -0.09858246 -0.19637066  0.32842706  0.07527878  0.85206223
  1.67413371  0.36867784  0.41055003 -0.15130024  0.51595633  0.54757292
 -0.15130024  0.37804984  0.32842706 -0.19215812  0.48411825  0.62979853
  0.43602911 -0.95974215 -0.12341895 -0.02401449  0.05633128 -0.95974215
 -0.22561061  0.31916898 -0.07076813 -0.45938098 -0.35305353  0.31916898
 -0.07076813 -0.35274935]
Pearson r: 0.661
MSE: 0.614
Fold 2, k_feat 16
X_train.shape:  (268, 16)
y_pred:  [-1.45911631 -0.59021581 -0.59021581 -1.45911631 -0.77341722 -1.03940812
 -0.59021581 -0.59021581 -0.59021581 -0.59021581  0.03062715  0.03062715
  0.03062715 -1.03940812 -1.45911631 -1.03940812 -0.77341722 -0.19853695
  0.03062715  0.03062715 -0.65871726 -1.45911631  0.32522005  0.03062715
 -0.19853695 -0.19853695  0.67524333  0.67524333  0.26940421  0.34395043
  0.513917    0.54217271 -0.59021581 -0.14362186  0.13499227  0.16866257
  0.16866257 -1.03940812  0.54217271  0.28031295  0.54217271  0.513917
  0.513917    0.26940421 -0.55599551  0.16866257  0.54217271  0.54217271
  0.54217271  0.513917    0.28031295  0.16866257  0.28031295  0.28031295
  0.42243538  0.13499227  2.03158956  0.42243538  0.03062715  0.16866257
  0.16866257  0.34395043  0.34395043  0.34395043  0.16866257  0.54217271
  2.03158956  0.16866257  0.16866257  0.16866257  0.34395043  0.16866257
  0.16866257  0.513917    0.34395043  0.16866257  0.34395043 -1.03940812
  0.54217271 -1.03940812 -1.03940812  0.34395043  0.11191655  0.07051866
 -0.37848427 -0.45505128  0.54217271  0.67524333  0.11191655  0.513917
  0.54217271 -0.50262151  0.13499227  0.42243538  0.54217271  0.13499227
  0.54217271  0.67524333  0.42243538  0.28597908  0.54217271  0.16866257
  0.34395043  0.54217271  0.13499227  0.16866257  0.16866257  0.13499227
  0.42243538  0.54217271 -0.37848427 -0.00484911  0.54217271  0.67524333
  0.54217271 -0.59021581 -0.25972861  0.513917    0.90899573  0.2738244
  0.513917    0.513917    0.54217271 -1.03940812  0.54217271  0.16866257
  0.34395043  0.34395043  0.16866257  0.54217271  0.54217271  0.16866257
  0.54217271  0.16866257]
Pearson r: 0.434
MSE: 0.664
Fold 3, k_feat 16
X_train.shape:  (268, 16)
y_pred:  [-1.11454911 -1.11454911 -1.56737831 -1.74399549 -0.35943575 -1.29959259
 -1.34559987 -0.79694929 -0.99796991 -1.36786398 -1.47683729 -1.47683729
 -1.23201815 -1.31435872 -0.63565363 -1.54282011 -1.54282011 -1.21878907
 -1.36786398 -0.79694929 -0.8492434  -1.23201815 -0.28293127 -0.37175819
 -0.63287582 -0.25392124 -1.22123798 -0.57809999 -0.44364444  1.04366508
  0.92739295  1.20196831  0.88950532  1.22168704 -0.42586063  0.91801184
  1.28807026  1.00287771  0.29808018  0.16647665  0.29808018  0.46348661
 -0.54317325  0.66703395  1.37325184  0.08746524  0.57003919  0.08746524
  0.39634473  0.41773565 -0.32742054  1.57624243  0.73768469  0.08746524
  0.40193543  0.40193543  2.02762053  0.36174254  0.31065466  0.44038941
  0.61758758  0.61758758 -0.11127419  0.41855182  0.04308442 -0.01558088
 -0.04228812 -0.30886975 -0.26834097 -0.21340235  0.55954193  0.29949031
  0.50055943  0.29949031  0.24507677 -0.36966117 -0.06889609 -1.47373078
  1.24862855  0.13876572 -0.29244826  0.41855182  1.24862855  0.26958398
  1.60335575  0.61758758  0.61758758  0.41482018  0.55228383  0.55228383
  1.00287771  0.55228383 -0.09854213 -0.03544434  0.40667274 -0.26834097
  0.61758758  0.61758758  0.61758758  0.18719803  0.50055943  0.19189979
 -0.01558088  0.41451898  1.24862855  0.41451898  0.73768469 -0.08230649
  1.88872799  0.45434381 -0.13771926  0.40193543 -0.09854213  0.26958398
 -0.39189611 -0.06027185 -0.0329911  -0.06027185  0.26958398 -0.09854213
  0.45434381  0.02348805  0.80682015  1.60335575  0.61758758  1.60335575
  1.24862855  0.19801478 -0.07929066 -0.14192327 -0.73586714 -0.07929066
 -0.73586714 -0.07929066]
Pearson r: 0.599
MSE: 0.791
Average pearson_r accross all folds = 0.5645162494376067
Average mse accross all folds = 0.6895122447371232
Fold 1, k_feat 32
X_train.shape:  (268, 32)
y_pred:  [-0.91406791 -0.68499025 -0.91406791 -1.01304612 -0.29498395 -1.38611047
 -1.5102861  -1.5102861  -0.8953978  -1.20042881 -1.46490993 -1.45014024
 -1.90407155  0.49470983 -1.15325588 -1.02156412 -1.42094184 -1.38349072
 -1.5102861  -1.19746192 -1.96158733 -1.96158733 -2.23992663 -1.26769652
 -0.41188906  0.22867135 -0.63291023 -0.27050883 -1.00704618 -1.597135
 -1.58363979 -1.62003914 -0.44041808 -0.58001637 -0.77527114 -0.60800636
 -0.70038077 -1.05824341 -0.1814343   0.89903253  1.96184164  0.38801711
 -0.12804316  0.21654081  0.30990694  0.31005093  0.43296099  0.02835671
  0.4892084   0.38378621  0.05822057  0.52271067  0.89975687  0.21205484
  0.1325051  -0.05758152 -1.91715816 -0.05843712  0.08295587  0.18468337
  0.28876438  0.45688923  0.17223714  0.32527038 -0.25819436  1.12322574
  0.56175266 -0.08349925  0.76670883  0.66376895  0.26660166  0.45198761
 -0.37465512 -0.39947949  0.27279853 -0.57409341  0.78361272  0.78361272
  0.5882697  -1.01575888 -0.05059301  0.26852826  0.16810935 -0.78501886
 -0.54708766 -0.64480982 -0.69951284 -0.99951023  0.19616284  0.46149889
  0.43167314  0.24101125  0.01452     0.23104071  0.30065133  0.52291376
  0.16007425  0.30664216  0.19050887  0.87473071  0.49280661  0.38998295
  0.26055969 -0.05018223  0.3358166   0.12590631 -0.05526513  0.77279199
  0.86656209  0.35929161  0.39237698  0.14665809  0.52670365  0.65213922
 -0.00310188 -0.19051928 -0.34241509 -0.56468114  0.50496007  0.78361272
  0.37334165 -1.10253349 -0.02501429  0.0673745   0.38997603 -1.10253349
 -0.38392976  0.4192012  -0.28466156 -0.28539302 -0.24809411  0.4192012
 -0.28466156 -0.26972783]
Pearson r: 0.644
MSE: 0.631
Fold 2, k_feat 32
X_train.shape:  (268, 32)
y_pred:  [-1.14574841e+00 -9.20981549e-01 -7.86890921e-01 -7.30700791e-01
 -6.63702012e-01 -1.70584176e+00 -1.95240146e+00 -6.99827639e-01
 -6.99827639e-01 -6.99827639e-01 -7.01251959e-01 -7.01251959e-01
 -7.01251959e-01 -1.20522379e+00 -2.28450240e+00 -2.73735699e-01
 -6.16274050e-01 -4.46218016e-01  2.09972005e-01  2.09972005e-01
 -7.87130998e-01 -1.91213142e+00  5.36888094e-01 -4.92161645e-01
 -2.43172426e-01 -2.43172426e-01  1.24195878e+00  1.00032604e+00
  1.15206816e+00  1.70530072e-01  1.71816678e-01  3.83202506e-01
  8.73775203e-01  3.78668225e-01  2.85849410e-01  3.48984026e-01
  5.57008617e-01 -2.73735699e-01  1.07376842e+00  2.86920453e-01
  5.75412937e-01  1.09690907e+00  7.23196804e-01  7.56278629e-01
  3.74454169e-01  3.19219108e-01  6.63580127e-01  5.75412937e-01
  9.77598309e-01  3.36919837e-01  9.60545190e-02  5.45924921e-02
  1.12732887e-01  1.12732887e-01 -8.76304835e-02  5.44267985e-01
  1.28360089e+00  5.19987267e-01  2.30294566e-01  1.19700695e-01
  1.19700695e-01  5.17936832e-01  1.92978769e-01  3.46575127e-01
  2.38092728e-01  1.07376842e+00  1.24310050e+00  5.45924921e-02
  5.45924921e-02  1.19700695e-01  3.46575127e-01  5.45924921e-02
  4.34923860e-01  4.05404464e-01  1.25779255e-03  5.45924921e-02
  3.46575127e-01 -3.30652150e-01  3.42829690e-01 -7.98435716e-01
 -3.30652150e-01  1.25779255e-03  1.34507275e-03  2.02729701e-01
  3.57695841e-02 -4.06415137e-02  8.84644389e-01  2.58687956e-01
  3.61614062e-01  3.81851200e-01  5.52571279e-02  5.65826489e-01
  5.43354879e-01  2.82847749e-01  2.06356811e+00  3.24561686e-01
  2.35647140e-01  7.95675398e-01  7.14593797e-01  3.36781818e-01
  6.19138991e-01  3.79906823e-01  2.36678191e-01  1.07376842e+00
  5.66868938e-01  2.78718982e-01  1.31805767e+00  2.23651907e-01
  1.17426193e-01  7.99241317e-01 -6.45475623e-02  3.82124787e-01
  7.56405928e-01  3.61723532e-01 -1.17383619e-01 -2.70712647e-02
 -8.90865972e-03  2.57470869e-01  5.96637612e-01  6.32649044e-01
  3.36919837e-01  3.36919837e-01  1.00221259e+00 -2.73735699e-01
  3.97352530e-01  2.04995606e+00  1.99322661e-01  3.46575127e-01
 -4.75957936e-01 -2.66020632e-01 -2.66020632e-01 -1.40787168e-01
 -2.66020632e-01  9.27558623e-02]
Pearson r: 0.550
MSE: 0.567
Fold 3, k_feat 32
X_train.shape:  (268, 32)
y_pred:  [-1.48895567 -1.63156304 -1.03392891 -1.87074441 -0.74816591 -1.17863026
 -1.35771674 -1.17534358 -0.69535189 -1.42806477 -1.74287397 -1.57343807
 -1.16963632 -1.09698415 -0.90514757 -1.01546634 -1.01546634 -0.62398556
 -1.50390706 -0.75365672 -0.90622195 -0.82936925 -0.22431424 -0.06667427
 -0.69645635 -0.26009183 -0.94474124 -0.29272033  0.41970279  0.23785108
  0.70772733  1.03006364  0.6916713   1.03887142  0.7164877   1.28821273
  0.77344916  0.60165663  0.50754377  0.69111666  0.38278101  0.31428122
  0.0258071   0.40941708  0.66809623  0.01516202 -0.70347323 -0.46442768
 -0.26282361  0.99021943 -0.75194578  0.42467636  1.0851377   0.1531639
 -0.06599372 -0.06599372  1.8299795  -0.28380599  0.29306814  0.45722218
  1.01017486  1.15272532  0.31186277  0.48060147  0.04926482 -0.22516438
 -0.15564583  1.47116436 -0.22539313  0.2112296   1.61969732  0.31876046
  0.3876096   0.37793229  0.33162445 -0.51487969 -0.91944973 -1.87053796
  0.38795566  0.45669099 -0.00973591  0.48060147  0.31614484 -0.01158588
  0.22749124  0.28311772  0.33424861  0.45673536  0.44227598  0.06305973
  0.25018476  0.24401154 -0.29873757 -0.16425016  0.18630471  0.38291513
  0.55022221  0.33424861  0.50525102 -0.0863323   0.19234012  0.46172379
 -0.03318311  0.12607077  1.65864005  1.67642972  0.56472778  0.39750297
  0.68578083  0.5619291  -0.06256955  0.45015846  0.16107503  0.85469815
  0.11868329 -0.45689165  0.13637409 -0.00540473  0.67619788 -0.14101061
  0.73522084 -0.09453913  0.91062148  1.18155876  0.33980497  1.78761357
  0.54049315  1.25450517  0.08560913  0.56102901 -1.16852137  0.91857504
 -1.02776413  0.38054242]
Pearson r: 0.630
MSE: 0.733
Average pearson_r accross all folds = 0.6079884634018821
Average mse accross all folds = 0.6433909776961281
Fold 1, k_feat 64
X_train.shape:  (268, 64)
y_pred:  [-1.26507624 -1.1417185  -1.26507624 -1.47732953 -1.16167448 -1.27169915
 -1.29475149 -1.07137723 -0.95298119 -1.45306065 -1.24629741 -1.34195489
 -1.56619445  0.69285334 -1.272385   -0.98338617 -1.39970454 -1.42570618
 -1.30414901 -1.18587789 -2.49029394 -2.22560956 -1.54880117 -0.75939923
 -0.22185427 -0.44153628 -0.71248338 -0.45575863 -0.66752019 -2.16096316
 -1.97349575 -2.04107379 -0.38277262  0.00950485 -0.46823623 -1.03926741
 -0.64879058 -0.54874324 -0.21994284  1.19648134  2.09326289  0.51915148
  0.0274237   0.13346282  0.33065391  0.51954106  0.51731391  0.44762973
  0.75022586  0.36669032  0.5124071   0.5112321   0.99945414 -0.05000269
  0.25262711 -0.0581247  -1.99820809  0.33056772  0.34259767  0.03924193
  0.23591659  0.41119449  0.28017441  0.2939587  -0.10044752  0.43213416
  0.5880964  -0.1662042   0.77666528  0.74996419  0.08301852  0.10481627
 -0.26550415 -0.42981605  0.1264394  -0.37925039  0.32018828  0.20472848
  0.10271756 -0.7396863  -0.33468177  0.35398268  0.02558448 -1.42622059
 -0.95696872 -1.50365442 -0.53736649 -0.70953293 -0.09314701  0.11384783
  0.63532984  0.19622239 -0.40588041  0.26285075  0.31243957  0.62713397
  0.48315294  0.53246413  0.36291768  0.71776481  0.60349209  0.45998603
  0.29648457  0.45486734  0.11545337  0.21192354  0.00875005  0.50620452
  0.74415892  0.42433026  0.3964497   0.31699708  0.03513565  0.60618134
  0.2182675  -0.36707775 -0.19159748 -0.60650459  0.80561218  0.53091852
  0.51743995 -0.84322407  0.22793506  0.4113519   0.95791169 -0.72490798
 -0.29378874  0.46809175 -0.16663238 -0.28916005  0.26512037  0.46809175
 -0.16663238  0.41458559]
Pearson r: 0.655
MSE: 0.625
Fold 2, k_feat 64
X_train.shape:  (268, 64)
y_pred:  [-9.27244738e-01 -7.88851360e-01 -7.76946640e-01 -6.81540932e-01
 -6.27897005e-01 -1.79000202e+00 -6.89707355e-01 -8.85164283e-01
 -8.05433463e-01 -2.29658123e-01 -1.08699208e+00 -1.08699208e+00
 -9.79500446e-01 -9.07098148e-01 -2.21753988e+00 -5.07715338e-01
 -4.96275807e-01 -3.85991705e-01 -1.00671815e-01 -8.06717739e-01
 -7.35444253e-01 -1.19924434e+00 -4.53100823e-01 -5.22917453e-01
 -4.40996031e-01  1.94248846e-01  1.18908055e+00  9.58091941e-01
  1.26031243e+00  1.20737469e-02  2.45132512e-01  2.55054855e-01
  3.19999589e-01  2.36404373e-01  3.33846052e-01  5.56023612e-01
  4.90023888e-01 -2.98904643e-01  1.05215151e+00  2.44473010e-01
  1.02474256e+00  9.04638308e-01  2.21408896e-01  1.11274665e-01
  2.64367903e-01 -6.44024370e-02  3.32270241e-01  9.88316990e-01
  3.73359187e-01  5.35862891e-01  1.44736165e-01  1.90588697e-01
  1.11786053e-01  5.78970161e-03  2.10217946e-01  8.30059130e-01
  1.48643656e+00  4.46208558e-01  2.75963007e-01  3.36991050e-01
  3.61723251e-01  3.77541195e-01  4.71150344e-01  5.55998511e-01
  2.77948684e-01  5.65967003e-01  1.23589585e+00  3.63956944e-01
  3.63956944e-01  1.82273911e-01  3.17268189e-01  4.92466092e-01
  4.24374175e-01  6.85071015e-01  3.17378143e-01  2.89192752e-01
  4.01354523e-01 -4.20016969e-01  3.73275661e-01 -5.49979969e-01
  5.51599277e-02 -3.98506540e-02  4.82405407e-02  1.02107942e-01
  2.40785807e-01  7.16887046e-02  1.14736508e+00  2.10029994e-01
  2.47268390e-01  1.65505525e-01  7.15871370e-01  3.49009753e-01
  6.65045314e-01  5.33743872e-01  1.27945503e+00  9.61890168e-01
  3.93898691e-01  4.05098065e-01  7.53313693e-01  4.70330871e-01
  3.90218195e-01  4.59788478e-01  4.22600342e-01  3.17580836e-01
  6.77034522e-01  3.95458247e-01  7.61668259e-01  2.59575504e-01
  1.00711448e-01  9.75438819e-01  7.02168373e-05 -1.52998615e-01
  8.78716418e-01  3.70390615e-01  4.31501605e-01  3.38484502e-01
  2.57053990e-01  2.94578269e-01  2.75546651e-01  5.88090632e-01
  4.66523348e-01  1.06180288e+00  4.89400167e-01 -5.07715338e-01
  7.01543074e-01  1.90019894e+00  3.41556038e-01  7.95117077e-02
 -4.05822584e-01 -3.82163224e-01 -3.82163224e-01 -2.54342288e-02
  1.52400332e-01  2.45309367e-01]
Pearson r: 0.590
MSE: 0.506
Fold 3, k_feat 64
X_train.shape:  (268, 64)
y_pred:  [-1.24161558 -1.42107425 -1.08244845 -1.45278542 -0.76198524 -1.36916167
 -1.3812125  -1.0876415  -0.73493034 -1.76652076 -1.31081528 -1.29606418
 -1.21140005 -1.10095125 -1.11177773 -1.29912861 -1.31368535 -1.20425504
 -1.41490419 -1.06743522 -0.95917919 -0.82045386 -0.21196604 -0.18414781
 -0.61039226 -0.12481808 -0.91157551 -0.40424178  0.50041986  0.29477872
  0.68744969  0.91419879  0.65162035  1.08763226  0.63485538  1.49382043
  0.7082294   0.5399428   0.35740307  0.50480371  0.48766092  0.28643052
 -0.10674502  0.39702011  0.46634888  0.04239153 -0.70046216 -0.36220318
 -0.13918381  0.58851319 -0.08719285  0.93502386  0.94763166  0.24927304
  0.2372913   0.2372913   1.17081206  1.05035566  0.35908029  0.56185659
  1.04212459  0.97859184  0.48781295  1.29852289  0.11449034 -0.13528636
 -0.09639758  1.20709401 -0.07938201  0.08913901  1.11680383  0.56441013
  0.6080863   0.51234854  0.01405319 -0.61798751 -0.93759977 -1.74559178
  0.31871826  0.43964203  0.33347274  0.24817537  0.17409676 -0.12705881
  0.10065469  0.12862651  0.2016943   0.42638044  0.37512477  0.23028953
  0.36220784  0.22139187 -0.09196683 -0.11456885  0.17224634  0.25628552
  0.46080895  0.2016943   0.36173095  0.89942516  0.18475123  0.43190468
 -0.19335838  0.46418111  1.67314758  0.85773     0.31320945  0.43963449
  0.58092392  0.58403518 -0.04563615  0.11161952  0.11979614  1.10695966
  0.03367399 -0.29737508  0.18905473 -0.12303283  0.80107281 -0.14587879
  0.99415054 -0.13937133  0.79856513  1.23359606  0.29522329  1.73005218
  0.18730944  1.38010941  0.08247297  0.83262049 -1.26172013  0.77765254
 -1.19389205  0.34796276]
Pearson r: 0.673
MSE: 0.656
Average pearson_r accross all folds = 0.6392091480050363
Average mse accross all folds = 0.5954360522276869
Fold 1, k_feat 128
X_train.shape:  (268, 128)
y_pred:  [-1.17732358e+00 -1.45518929e+00 -1.17732358e+00 -1.58146358e+00
 -1.22999953e+00 -1.45850890e+00 -1.38729112e+00 -1.30495026e+00
 -1.25908690e+00 -1.34519821e+00 -1.25170778e+00 -1.25250554e+00
 -1.15711668e+00  3.99481168e-01 -1.58960014e+00 -1.21161949e+00
 -1.36186836e+00 -1.37561055e+00 -1.35499511e+00 -1.15804132e+00
 -1.34905961e+00 -1.35288413e+00 -1.26718992e+00 -1.00314398e+00
 -3.21227737e-01 -4.87763102e-01 -6.02435266e-01 -3.68730576e-01
 -7.59859717e-01 -1.76700096e+00 -1.59329864e+00 -1.68178119e+00
 -3.34716240e-01 -7.78377357e-02 -6.76425740e-01 -8.69258639e-01
 -5.77902485e-01 -2.09712271e-01 -1.93434767e-01  1.19675462e+00
  2.12407131e+00  4.74337482e-01 -1.06703901e-03  1.07484439e-01
  2.66689040e-01  3.05647286e-01  3.34887123e-01  4.58926152e-01
  5.89075556e-01  3.40360077e-01  3.06647555e-01  4.94532079e-01
  7.67752905e-01 -3.09314648e-01  1.81600634e-01 -2.89680043e-02
 -1.73760144e+00  3.47467248e-01  5.88527175e-02  1.26844291e-01
  2.73300770e-01  5.07559314e-01  3.68663348e-01  3.72303423e-01
  3.66662327e-02  5.48320731e-01  6.82183273e-01 -1.19439319e-01
  8.14929483e-01  6.91309564e-01  1.51127982e-01  2.66345505e-01
 -4.04920043e-01 -4.04784632e-01  2.39222152e-01 -3.83751552e-01
  9.64641249e-02  6.83434501e-03  2.68607518e-01 -5.18056354e-01
 -4.24493150e-01  2.42693948e-01 -1.46201429e-02 -1.35624224e+00
 -7.33933149e-01 -1.34048542e+00 -5.87942390e-01 -5.29319198e-01
 -3.62141738e-01 -5.47336817e-02  6.58630140e-01 -9.52720704e-02
 -4.67002505e-01  8.25565449e-02  2.47980326e-01  5.90966647e-01
  4.01485488e-01  4.40381074e-01  4.80624578e-01  2.54940695e-01
  3.31617338e-01  4.62138706e-01  2.83853161e-01  3.92095690e-01
  4.19212834e-01  2.82760460e-01 -9.88677163e-02  2.94923583e-01
  1.05491816e+00  5.29846666e-01  3.09514677e-01  4.22508129e-01
  1.39936586e-01  7.13245326e-01  3.71480447e-01  1.28784903e-01
 -2.56163675e-02 -4.80261948e-01  7.05901862e-01  3.71475690e-01
  5.37694631e-01 -8.48765171e-01  2.66482354e-01  1.86292422e-01
  7.11436894e-01 -8.27453792e-01 -3.77528051e-01  2.72933757e-01
 -2.23700778e-01 -5.77337855e-02  2.01947061e-02  4.10512829e-01
 -2.23700778e-01  1.21119005e-01]
Pearson r: 0.705
MSE: 0.533
Fold 2, k_feat 128
X_train.shape:  (268, 128)
y_pred:  [-1.06149433 -0.55766884 -0.51419993 -0.79975308 -0.64852117 -1.39711183
 -0.93601869 -1.02752566 -0.91715335 -0.22026191 -1.14908413 -1.14908413
 -1.09342345 -0.89720789 -1.63408211 -0.54725967 -0.56178917 -0.31521403
  0.03050599 -0.33055406 -0.86497889 -1.16345002 -0.49044038 -0.62337958
 -0.46939101  0.61687386  1.31076731  1.11478295  1.30299268  0.48323205
  0.51293143  0.60267618  0.3449521  -0.01883751  0.46197413  0.48973263
  0.34837452 -0.12542689  1.26038276  0.08017835  0.91785565  0.86553979
  0.28796703  0.32474868  0.08389225 -0.12939172  0.47515423  0.9044515
  0.63515097  0.60956169  0.13677924  0.18577901  0.1226121   0.15333143
  0.44015128  0.60093613  0.96967621  0.49453858  0.19552449  0.39030013
  0.1780127   0.47671682  0.32641934  0.49540774  0.17405752  0.44171827
  0.76127432  0.24364589  0.25244072  0.30604697  0.25760425  0.47957488
  0.26748971  1.18777806  0.05892515  0.31702591  0.38684718 -0.18771985
  0.60351569 -0.44312735 -0.36818472 -0.13398373  0.16902817  0.01179128
 -0.12724895  0.41632888  1.02497076  0.35498619  0.37500502  0.32666465
  0.29696221  0.3603015   0.57412869  0.47480226  0.81500749  0.54434663
  0.4324349   0.50545146  0.01003604  0.93326041  0.92177986  0.24948165
  0.32080633  0.08871793  0.61361817  0.66995528  0.6753471   0.02907815
 -0.0802274   0.55175662  0.08261705  0.48932951  0.60048916  0.35589252
  0.57108479  0.1734513   0.41769496  0.35299249  0.58742295  0.58825648
  0.47771881  1.13518566  0.19338391 -0.48301486  0.59667438  1.81797341
  0.2785739   0.16151228  0.11548053 -0.36342233  0.66480673  0.49139591
  0.04902586  0.02527374]
Pearson r: 0.608
MSE: 0.480
Fold 3, k_feat 128
X_train.shape:  (268, 128)
y_pred:  [-1.26009659 -1.35573179 -1.11623734 -1.4240344  -0.87142969 -1.13629778
 -1.38540788 -1.06332523 -0.88579004 -1.76600493 -1.03421839 -1.24222194
 -1.23638824 -1.05764137 -1.01956989 -1.2052024  -1.20659265 -0.98749796
 -1.42415667 -0.82960345 -1.02387358 -0.8366607  -0.2290393  -0.39971219
 -0.40265342 -0.43419558 -0.96358508 -0.47417235  0.13191535  0.62914714
  0.72988578  0.96280469  0.70975423  0.98543546  0.74575332  1.40887857
  0.87623154  0.66436659  0.47375278  0.46448278  0.48123872  0.24448104
  0.00403888  0.31528747  0.56527255  0.17244025 -0.61259224 -0.14488071
 -0.49752221  0.89755356  0.26163342  0.73609892  1.47190186  0.10729738
  0.33813186  0.33813186  0.95230864  0.78967793  0.2315585   0.7058524
  0.91963607  1.21827426  0.92829392  1.41662466  0.04079817 -0.33502017
  0.09285886  0.92404836  0.02457335  0.08375667  1.15057077  0.50230194
  0.52380392  0.46401043 -0.19755237 -0.37131432 -0.82914759 -1.67501129
  0.34866261  0.35936388  0.28551415  0.23354553  0.20952583 -0.10772015
  0.20015596  0.09207132  0.21636433  0.23108713  0.15425702 -0.01402092
  0.5672083   0.05631731 -0.15982709 -0.02216899  0.31019192  0.41984281
  0.61403963  0.13863983  0.22334982  0.54800319  0.0402402   0.17506049
 -0.18384032  0.69725836  2.09979186  0.68297039  0.30680717  0.3712506
  0.51924004  0.56068255 -0.16149726  0.3064415   0.33602599  0.84888142
  0.12886585 -0.02493351  0.07403818  0.25031424  0.73040731 -0.02125869
  0.95802497 -0.02392685  0.79303367  1.03611334  0.31544703  1.73422057
  0.22779246  1.57583308 -0.12286565  0.53226187 -1.31197084  0.29269234
 -1.19910544  0.4114624 ]
Pearson r: 0.685
MSE: 0.636
Average pearson_r accross all folds = 0.6658918166814768
Average mse accross all folds = 0.5495746498915483
Fold 1, k_feat 256
X_train.shape:  (268, 256)
y_pred:  [-1.16340877 -1.50997758 -1.16340877 -1.49408346 -1.13483014 -0.7944662
 -1.36022557 -1.37691796 -1.36296934 -1.07821971 -1.44229812 -1.07295679
 -1.13376745  0.42042801 -1.45557071 -1.35602747 -1.29033936 -1.33312727
 -1.10277342 -1.11961171 -1.41023556 -1.33355996 -1.40515342 -0.61241027
 -0.31010416 -0.37765819 -0.55438395 -0.39776726 -0.64889224 -1.78664413
 -1.40227737 -1.64935118 -0.31683644 -0.29189863 -0.82041947 -0.69137592
 -0.60094886  0.24996887 -0.10861467  1.15669312  1.86799438  0.46400093
  0.15982796  0.08174872  0.3209658   0.19286115  0.37673258  0.66110903
  0.16740942  0.39759096  0.30692448  0.64114027  0.58886106 -0.05531638
  0.31668192  0.11286109 -1.57939322  0.45369048  0.10257513  0.19147359
  0.41962206  0.2712911   0.36433557  0.27689393  0.30259973  0.25108013
  0.43552643 -0.08606921  0.76665144  0.65026766 -0.20145862  0.56111799
 -0.13729132 -0.44429276  0.37750538 -0.43679083  0.00425305 -0.06766099
  0.14716859 -0.69527207 -0.84431289  0.30149765  0.23404553 -1.12772545
 -0.52851621 -1.07138126 -0.34397818 -0.39456496  0.21839179  0.10301957
  0.69054295 -0.24301672 -0.16948887  0.17827636  0.11666361  0.59196809
  0.58495229  0.41818803  0.53626617  0.49490261  0.07716684  0.36998797
  0.34493922  0.34050339  0.03140266  0.14977685 -0.03095353  0.41951992
  1.03254759  0.59410291  0.11367301  0.50285075  0.24995271  0.31025041
  0.4848629   0.20279695  0.20677029 -0.18217518  0.64442941  0.38053622
  0.25195135 -0.95038969  0.45823693  0.21861139  0.4368063  -0.92483727
 -0.36679551  0.36984664 -0.28752579  0.30281514  0.137365    0.55253298
 -0.37701087  0.482665  ]
Pearson r: 0.706
MSE: 0.534
Fold 2, k_feat 256
X_train.shape:  (268, 256)
y_pred:  [-0.66987934 -0.77193113 -0.74799129 -0.74173046 -0.73635294 -1.25892958
 -0.98824628 -1.03929682 -0.99292496 -0.2576167  -0.82622348 -0.8325805
 -0.86363054 -0.88893513 -1.51250028 -0.28561316 -0.67161694 -0.25267998
 -0.25162848 -0.32054436 -0.82146451 -1.10146599 -0.59813724 -0.54075745
 -0.33355014  0.75125767  1.67215204  1.38448706  1.38172251  1.09701248
  0.64085521  0.71144534  0.54697813  0.14444259  1.0603916   0.84362494
  0.47560685  0.28041343  0.72995634  0.1301697   0.7928559   0.60644516
  0.17626343  0.10801193  0.29096156 -0.14030633  0.92199551  0.84941178
  1.12759195  0.63241368  0.35510577  0.23031804  0.25433795  0.20020234
  0.69279049  0.99675941  0.2926015   0.53707829  0.26087646  0.64967251
  0.40853781  0.43660987  0.34488643  0.68955256  0.09195801  0.44102441
  0.07700495  0.31221643  0.32441424  0.32474741  0.3785837   0.54496591
  0.00475112  0.57790953  0.03213812  0.29212821  0.26830171 -0.15252636
  0.49157846 -0.18861857 -0.28778965 -0.28127321  0.39763178 -0.0748024
 -0.36769626  0.42154112  1.05122531  0.19913097  0.38683942  0.35809577
  0.03242133  0.14405274  1.05306433  0.58303293  0.72169431  0.39178092
  0.18512047  0.36216387  0.25883001  0.4553538   0.63411331  0.22491667
  0.21552163 -0.03111782  0.92137519  0.5771015   0.09288776  0.16365544
 -0.05170685  0.35245663  0.34227018  0.41628513  0.93209574  0.25646904
  0.9668798   0.19886357  0.14791225  0.6222378   0.62082506  0.2050048
  0.27495282  0.5075433  -0.25058828 -0.1159451   0.59630284  1.74256358
  0.55771946  0.29523082 -0.23080599 -0.51765693 -0.15186596  0.00880934
 -0.16560324 -0.09059021]
Pearson r: 0.663
MSE: 0.423
Fold 3, k_feat 256
X_train.shape:  (268, 256)
y_pred:  [-1.28703991 -1.05944611 -0.99951975 -1.30349235 -0.81903803 -1.76854967
 -1.43448467 -1.16214699 -1.11891654 -1.53591904 -1.64652803 -1.49701198
 -0.84517747 -1.2328035  -0.83605538 -1.41197812 -1.41603891 -1.08056184
 -1.14896277 -1.25878538 -1.35444071 -1.21723126 -0.27069288 -0.32722733
 -0.27017871 -0.09242945 -0.80806819 -0.63907859 -0.00467159  0.33132792
  0.94643133  1.13988121  0.9639836   0.95585558  0.81317371  0.6756735
  0.9551081   0.66463663  0.59754406  0.60966539  0.46039913  0.28715639
  0.08256343  0.28245384  0.69843473  0.32369734 -0.47200289 -0.22398926
 -0.36790024  0.69329932  0.39103689  0.46378173  1.13701652  0.12847004
  0.46306781  0.45157714  0.75677323  0.45087791  0.21375766  0.51666081
  0.50890324  0.61713754  0.53676365  1.32208877  0.13194187 -0.08066834
 -0.02455911  0.93832403 -0.06603905  0.10418271  0.58542676  0.21524273
  0.30225173  0.09259023 -0.38453712 -0.40406103 -0.81982947 -1.32869812
  0.27831526  0.51705371  0.32666952  0.38596014 -0.04807069  0.05720539
  0.10463447  0.02113462  0.11996245  0.18560816  0.17386347  0.02905525
  0.35579546  0.13198873 -0.0985955   0.04620999  0.19825754  0.29664611
  0.7300027   0.17639197  0.36528191  0.24574653  0.0924434   0.2257705
  0.17675163  0.54568796  1.79753777  0.4587121   0.44816804  0.44965335
 -0.19612012  0.35608158  0.19271919  0.34761911  0.56426321  0.80446995
  0.34134416  0.08792121  0.1979059   0.53706859  0.32720512  0.32819805
  0.86888742 -0.10160599  0.56322246  0.89856265  0.71818499  1.17458438
  0.37391905  1.39425887  0.004097    0.80866041 -1.22804088  0.60215287
 -1.28676628  0.58122253]
Pearson r: 0.738
MSE: 0.548
Average pearson_r accross all folds = 0.7022987708691092
Average mse accross all folds = 0.5015202682460699
Fold 1, k_feat 512
X_train.shape:  (268, 512)
y_pred:  [-1.14883078 -1.45938917 -1.14982869 -1.33032829 -1.12252026 -0.93053779
 -1.42808973 -1.48092836 -1.04669924 -0.94668136 -1.49936832 -1.21605327
 -1.13584342  0.19466461 -1.22819199 -1.12751396 -1.22297448 -1.32588263
 -1.06290931 -1.17472168 -1.62191245 -1.48577821 -1.61162455 -0.77972224
 -0.30719354 -0.18640686 -0.49021346 -0.28748847 -0.85885283 -1.89952677
 -1.55783378 -1.62372484 -0.2118862  -0.31848645 -0.68085802 -1.03307688
 -0.40457931  0.30769734  0.02903923  1.25612764  1.50784092  0.42783113
  0.21949671  0.08519796  0.26574908 -0.05722068  0.2259926   0.48105054
  0.19598553  0.3921314   0.01568116  0.51566766  0.48337429 -0.17643928
  0.10006141  0.18704384 -1.39471911  0.36890217  0.10193158  0.11989614
  0.34391362  0.29904429  0.26462769  0.13678768  0.21737576  0.24047333
  0.45139862 -0.24860375  0.69072832  0.54648152 -0.17356999  0.47452671
 -0.12379349 -0.45569911  0.19351193 -0.38521048 -0.13787903 -0.09613088
  0.12371561 -0.73822532 -0.52023654  0.35788261  0.10346931 -0.90590873
 -0.46160652 -0.83679917 -0.23200037 -0.48495862  0.15642195 -0.35424044
  0.60896543 -0.2224088  -0.28686877 -0.05268582  0.37841108  0.61915098
  0.555914    0.34779229  0.49204244  0.51674137  0.00600908  0.31261984
  0.37807172  0.27801467  0.06480301  0.43000069 -0.07446932  0.38760004
  0.64602316  0.80643931  0.21061114  0.3691698   0.16545216  0.69365675
  0.29694011  0.45512816  0.25976216 -0.00590148  0.71985032  0.45825336
  0.77460025 -0.93919392  0.24222831  0.0493633   0.4315067  -0.72392904
 -0.26052391  0.10475214 -0.28890376 -0.07428058 -0.08093359  0.20113958
 -0.31867674  0.25417229]
Pearson r: 0.717
MSE: 0.516
Fold 2, k_feat 512
X_train.shape:  (268, 512)
y_pred:  [-0.798121   -0.7747027  -0.80211149 -0.76047008 -0.59603113 -1.31044831
 -1.03486337 -1.10438913 -1.04128235 -0.24214507 -0.98397116 -0.99725861
 -0.79189959 -0.89266139 -1.32322065 -0.38702562 -0.60623739 -0.26253747
 -0.2770663  -0.35402339 -0.84727689 -1.07180636 -0.65957601 -0.63909492
 -0.38716192  0.84474581  1.06872713  1.39513287  1.56597127  0.90718671
  0.37846298  0.52197241  0.50374437  0.02769714  1.24659091  0.71612827
  0.61220183  0.48483649  0.83292251  0.31024442  0.66555857  0.57385747
  0.26689672  0.26929902  0.23609674 -0.16048458  0.63500907  0.58639006
  0.36760246  0.68238141  0.49941477  0.15753217  0.24496583  0.19050127
  0.73677457  1.13841395  0.31879197  0.66970765  0.31438422  0.78684017
  0.37878703  0.59879736  0.51643392  0.59972038  0.29703395  0.64468286
  0.23480203  0.35634207  0.51064067  0.3433577   0.34810356  0.67379631
  0.12651435  0.45098755  0.15980364  0.35552806  0.411088    0.00385901
  0.35099627 -0.11703187 -0.16263417 -0.02269799  0.24193883  0.14353525
 -0.26151722  0.36441583  0.90529059  0.03471039  0.43101756  0.37026669
  0.08633056  0.36538297  1.16264671  0.74490311  0.57807652  0.5226218
  0.28576857  0.24979766  0.36260429  0.2827796   0.14412014  0.41250265
  0.38536677  0.06696879  1.02678782  0.90979939 -0.14275486  0.19109091
  0.10575561  0.60214785  0.41759166  0.68742457  1.0656015   0.28643401
  0.96785065  0.47818344  0.42242062  0.86613358  0.6463267   0.28339466
  0.27645491  0.29904134 -0.24229531 -0.02729316  0.55436041  1.55640451
  0.48452283  0.34048015 -0.30830009 -0.4175077  -0.27189841 -0.08701645
 -0.14439222  0.11807236]
Pearson r: 0.683
MSE: 0.402
Fold 3, k_feat 512
X_train.shape:  (268, 512)
y_pred:  [-1.16828322e+00 -1.08503391e+00 -9.93771701e-01 -1.22505318e+00
 -6.37488995e-01 -1.28614458e+00 -1.27159408e+00 -1.25873211e+00
 -1.76802900e+00 -1.53689044e+00 -1.92941892e+00 -1.22292302e+00
 -9.57772153e-01 -1.10500417e+00 -1.17052086e+00 -1.35634691e+00
 -1.36229083e+00 -1.24611634e+00 -1.42787422e+00 -1.62901376e+00
 -1.19863683e+00 -1.19293397e+00 -2.62157259e-01 -4.63100930e-01
 -3.93863758e-01 -1.72059071e-01 -7.73297930e-01 -1.13614956e+00
  1.54996359e-02  6.47706538e-01  9.99956998e-01  1.01250609e+00
  7.01133820e-01  1.08625307e+00  9.79959660e-01  7.94715905e-01
  9.90409794e-01  7.40299178e-01  5.94735519e-01  4.80593563e-01
  6.23055495e-01  2.01708051e-01  5.51096287e-02  2.67758574e-01
  5.65976384e-01  1.89674031e-01 -1.75120407e-01 -1.96496150e-03
 -1.18823603e-01  9.35556168e-01  5.79302016e-01  4.95085108e-01
  8.24289077e-01 -6.35495395e-02  3.14382821e-01  2.97109934e-01
  9.97619629e-01  7.04300036e-01  2.56732805e-01  4.09176691e-02
  3.02999048e-01  4.32354239e-01  4.04424779e-01  6.98099514e-01
  7.00525328e-02 -1.27638117e-02  6.45583411e-02  9.74708664e-01
  6.17631574e-02 -1.57787757e-02  6.46201495e-01  2.03806136e-01
  6.47584634e-02  1.80274303e-01 -1.95592169e-01 -3.13509934e-01
 -5.65305809e-01 -1.20878068e+00 -2.01082723e-01  4.31119805e-01
  4.51405756e-01  3.75996540e-01  1.47272707e-01  4.08301575e-01
  5.29496668e-01  7.43124935e-02  2.00807323e-01  4.81503977e-01
  2.64847414e-01  2.90611592e-01  2.36920742e-01  1.39102200e-01
 -5.67740583e-02  2.67163704e-02  1.93459731e-01  5.44651191e-01
  5.19792728e-01  2.76766396e-01  1.79076653e-01 -8.56004483e-02
  3.23777855e-01  3.03030139e-01  1.44664777e-01  3.61285143e-01
  1.97138348e+00  5.12107575e-01  6.06040670e-01  6.62168637e-01
 -2.55047802e-02  4.99431254e-01  4.39276848e-01  4.61323292e-01
  7.61339795e-01  6.15647582e-01  3.37916122e-01  1.14716012e-01
  2.53903230e-01  4.46136733e-01  2.98750088e-01  2.54427338e-01
  7.61168097e-01  8.73302783e-02  7.63778694e-01  6.83564789e-01
  5.64818374e-01  6.72757744e-01  1.40493780e-01  1.28489995e+00
 -1.40213346e-01  6.95729761e-01 -1.22821764e+00  4.98419717e-01
 -1.27213406e+00  4.57350093e-01]
Pearson r: 0.734
MSE: 0.554
Average pearson_r accross all folds = 0.7114691817945124
Average mse accross all folds = 0.49059126977663325
Fold 1, k_feat 1024
X_train.shape:  (268, 1024)
y_pred:  [-1.19058694 -1.49493717 -1.14657515 -1.22359249 -1.16049848 -0.83651981
 -1.30459851 -1.47954456 -1.18049545 -1.12103674 -1.54954808 -1.17890177
 -1.11619511  0.07182769 -1.23177386 -1.09050194 -1.31169787 -1.33284959
 -1.07754227 -1.15288825 -1.85730483 -1.4445652  -1.39786593 -0.53847965
 -0.29472799 -0.34723985 -0.53356922 -0.4524815  -0.68305136 -1.71076812
 -1.12201966 -1.55935734 -0.35750032 -0.44726336 -0.6916474  -0.8065947
 -0.56256814  0.13340571  0.10664534  1.19331582  1.24661129  0.41783927
  0.14888255  0.0504215   0.27240631  0.26231251  0.25697619  0.51480677
  0.40132355  0.25055687  0.15468494  0.50060394  0.49280411 -0.02562258
  0.22874908  0.24274846 -1.36173115  0.32273979 -0.07508662  0.14946574
  0.37675794  0.32771357  0.30009274  0.08630578  0.21963561  0.22684021
  0.43135135 -0.18684385  0.76304603  0.7293908  -0.15290009  0.49934057
  0.02084209 -0.23004946  0.3777729  -0.37187149 -0.00503253 -0.17670467
  0.01729056 -0.69625466 -0.58316555  0.31111483  0.05981046 -0.86064458
 -0.33363732 -0.59921209 -0.24460549 -0.32722999  0.13117632 -0.03046452
  0.64959268 -0.01059133 -0.07119028  0.06775765  0.26402462  0.47841253
  0.31313346  0.25526444  0.3431664   0.43761291  0.01137358  0.24446585
  0.36978256  0.2933699   0.10172046  0.42557307  0.02293007  0.35300528
  0.82380273  0.77490562  0.21781894  0.28993613  0.13953489  0.50026372
  0.14666194  0.31421647  0.16795589 -0.06840328  0.70983252  0.46069436
  0.44996713 -0.71400715  0.24323698  0.04694042  0.64367291 -0.71349793
 -0.38101839  0.399256   -0.35309816 -0.05462199 -0.05465471  0.65875145
 -0.39295164  0.5365277 ]
Pearson r: 0.701
MSE: 0.543
Fold 2, k_feat 1024
X_train.shape:  (268, 1024)
y_pred:  [-0.68559885 -0.83904301 -0.78349816 -0.83836785 -0.67549437 -1.4293309
 -0.99259686 -1.1771175  -1.09737138 -0.31549464 -1.05408795 -1.10982595
 -0.90569981 -0.88759199 -1.37224337 -0.42897545 -0.73125309 -0.23064232
 -0.34543407 -0.2623154  -0.78104345 -1.16060275 -0.74234753 -0.65669085
 -0.46854989  0.80785324  0.97467017  1.40532005  1.39308149  0.7934628
  0.45647469  0.67602337  0.54479661  0.10233429  1.25366141  0.73005847
  0.86544631  0.3462551   0.76973056  0.43324257  0.46059007  0.48783567
  0.15349206  0.36437223  0.31510085 -0.06520251  0.52530547  0.56175697
  0.24582295  0.54265331  0.48231299  0.26831802  0.3140815   0.09490642
  0.77828823  1.10192812  0.53456209  0.62184685  0.38860132  0.70349452
  0.45529745  0.52389463  0.4653504   0.62678256  0.18691809  0.6212583
  0.20388644  0.26238925  0.31021011  0.20586367  0.51420196  0.31355546
 -0.04368261  0.47180123  0.21044184  0.68654378  0.48267741 -0.0317636
  0.43715632 -0.12506814 -0.07083298 -0.05664905  0.12593607  0.11136982
 -0.29836816  0.59124306  0.84202584  0.02915515  0.2759066   0.25331983
 -0.02633954  0.3410416   1.0139274   1.17652346  0.41686188  0.67534118
  0.16184373  0.43668382  0.41943793  0.22029788  0.15403574  0.29114285
  0.15099938  0.04932191  1.02901077  0.74217196 -0.14566668  0.18410504
  0.20082887  0.59846005  0.52486254  0.89696558  1.1021866   0.30863064
  1.06920996  0.5901635   0.41236445  0.74240306  0.73349766  0.28737324
  0.15954125  0.46734685 -0.14900456 -0.1001814   0.63039997  1.42471998
  0.48225402  0.39960651 -0.07082741 -0.28593681 -0.26701044 -0.05235162
 -0.14812284  0.04988682]
Pearson r: 0.684
MSE: 0.401
Fold 3, k_feat 1024
X_train.shape:  (268, 1024)
y_pred:  [-1.11723799 -0.97009739 -0.84731287 -1.30324261 -0.66594623 -1.40304665
 -1.43081529 -1.29009624 -1.5148505  -1.56285546 -1.83232463 -1.17693938
 -1.17148706 -1.09843311 -1.03029836 -1.34426519 -1.36290597 -1.26296791
 -1.22177258 -1.70939021 -1.19783641 -1.52448394 -0.23684362 -0.55741444
 -0.49446704 -0.15276484 -0.79461298 -0.9685516  -0.03651185  0.76645279
  1.02861251  1.13922906  0.74995152  0.95249917  0.95137066  0.82940469
  1.05646776  0.67880384  0.60094975  0.51588583  0.59471529  0.26258048
 -0.25646414  0.32493128  0.38251126  0.25859486 -0.27202683  0.03056279
 -0.23316565  0.74955037  0.57277975  0.59759454  1.03114343  0.01545179
  0.22148848  0.19844292  0.95607061  0.43643586  0.30149437  0.30060736
  0.19260843  0.34865055  0.38388155  0.51531242  0.12060813 -0.22485538
  0.16352438  0.80646819  0.17535751  0.09494739  0.69133747  0.28239
 -0.01978216  0.07176146 -0.32350911 -0.38359038 -0.54639852 -1.27936893
 -0.3922085   0.42253496  0.51758428  0.31019136  0.06861926  0.48827393
  0.48257922  0.0669497   0.18355541  0.29936258  0.16678364  0.09499755
  0.13684654  0.09042837  0.02109418  0.08379008  0.23444473  0.44332771
  0.54188634  0.29480967  0.21414408  0.04655413  0.24346594  0.21724519
  0.09045557  0.27872272  1.89590639  0.81607996  0.49668958  0.72191522
  0.09725083  0.48952254  0.38683577  0.39536997  0.66780891  0.82880053
  0.55829049  0.12950787  0.38017271  0.77799423  0.15915948  0.22663092
  0.58641439  0.0505841   0.62240422  0.67658731  0.61191665  0.54023705
  0.07510768  1.09064457 -0.00235457  0.74950754 -1.13903884  0.39827394
 -1.23668152  0.32020058]
Pearson r: 0.756
MSE: 0.518
Average pearson_r accross all folds = 0.7137493517978983
Average mse accross all folds = 0.4874381088292625
Fold 1, k_feat 2048
X_train.shape:  (268, 2048)
y_pred:  [-1.17486368e+00 -1.45789106e+00 -1.14204384e+00 -1.16198317e+00
 -1.08144937e+00 -6.77672812e-01 -1.11484179e+00 -1.41476709e+00
 -1.13996937e+00 -9.97580804e-01 -1.48251048e+00 -1.03994662e+00
 -1.06492480e+00  1.79015033e-01 -1.22980379e+00 -1.10775502e+00
 -1.16660622e+00 -1.36145312e+00 -9.41318140e-01 -1.11012819e+00
 -1.45967705e+00 -1.39787529e+00 -1.31729003e+00 -7.13089499e-01
 -1.97386451e-01 -2.08254389e-01 -5.23386488e-01 -4.05230919e-01
 -7.60652595e-01 -1.67317142e+00 -1.36083635e+00 -1.61396439e+00
 -2.61523161e-01 -3.78690161e-01 -7.35688467e-01 -8.46956059e-01
 -5.50309642e-01  1.35391127e-01  2.47386675e-01  1.24059432e+00
  1.21905681e+00  3.51902236e-01  2.37972469e-01  1.69040590e-01
  2.70563344e-01  3.15877534e-01  2.35863799e-01  4.95417729e-01
  4.13347245e-01  3.49242899e-01  2.31445787e-01  4.93665392e-01
  6.57679916e-01  3.11952226e-02  1.88191386e-01  7.56684591e-02
 -1.21325421e+00  2.95360107e-01  3.73976297e-01  3.45021377e-02
  4.67501266e-01  2.40225081e-01  3.09488615e-01 -7.02403913e-02
  2.54225124e-01  1.71783880e-01  3.99804411e-01 -1.43694794e-01
  8.48248341e-01  8.36009487e-01 -1.28700107e-01  3.68094061e-01
 -1.36010746e-01 -1.02644136e-01  3.92312233e-01 -4.12105650e-01
 -1.28262029e-01 -3.01429444e-01 -1.09851174e-05 -7.00559437e-01
 -4.81995061e-01  1.81238943e-01  1.87347904e-01 -6.46711669e-01
 -2.98108208e-01 -4.50577842e-01 -4.96935335e-02 -2.64623231e-01
  1.39131374e-01 -4.25425506e-02  2.90632580e-01 -4.52627677e-02
 -1.49989324e-01  8.12235042e-02  2.02903673e-01  3.67511671e-01
  3.15508367e-01  2.08747241e-01  4.83107968e-01  4.86490927e-01
  6.54311159e-02  2.36181262e-01  4.04639416e-01  2.25933851e-01
  4.77581769e-02  4.40806371e-01  2.75468929e-01  3.27183890e-01
  7.60883941e-01  7.66289618e-01  3.37477216e-01  2.78432670e-01
  2.36359130e-01  5.73068340e-01  2.77356025e-01  1.36267113e-01
  1.34332952e-01 -1.17385558e-01  6.50637135e-01  2.88971405e-01
  4.70134841e-01 -7.66274952e-01  1.23325627e-01  9.41363291e-02
  6.58344430e-01 -6.32204450e-01 -2.93034765e-01  4.33364929e-01
 -3.90473190e-01 -8.30602658e-02  4.36457461e-02  8.02734941e-01
 -3.76852882e-01  1.96270096e-01]
Pearson r: 0.704
MSE: 0.544
Fold 2, k_feat 2048
X_train.shape:  (268, 2048)
y_pred:  [-0.80806376 -0.87799118 -0.92189643 -0.9052724  -0.57290017 -1.47469961
 -1.13427087 -1.06209739 -0.98901105 -0.28965362 -1.1741421  -1.17439955
 -0.79776756 -0.93341792 -1.25630326 -0.31546769 -0.74321011 -0.28102493
 -0.35304613 -0.40664208 -0.83446807 -1.10729735 -0.7248825  -0.7882638
 -0.53651727  0.82444763  1.03686713  1.53413549  1.56110645  1.23100255
  0.37517229  0.42478626  0.56905134  0.16708313  1.25885499  0.81357614
  0.80865789  0.52607995  0.63256692  0.27746019  0.4555324   0.47262181
  0.14007084  0.31793003  0.30310775 -0.03446327  0.55816975  0.59586745
  0.1539936   0.69541312  0.43585254  0.29284091  0.25756843  0.08460438
  0.67453     1.02069148  0.75707932  0.71000594  0.41560249  0.68298268
  0.39324769  0.46706088  0.48094871  0.59082281  0.24835212  0.49007524
  0.17435666  0.26730814  0.36271922  0.09931737  0.42284898  0.45455922
  0.05334268  0.48830674  0.37847661  0.47937496  0.55595434 -0.1628467
  0.33120884 -0.20349978 -0.23961698 -0.20087541  0.15211203  0.033014
 -0.17976257  0.52841336  0.82379645 -0.03790049  0.22025083  0.16476316
  0.06478352  0.36127796  1.40941368  1.15723618  0.25588179  0.88775247
  0.27202586  0.3823658   0.41548327  0.41530252  0.53372543  0.13564893
  0.20944622  0.1490768   1.06731887  1.08005366 -0.12212157  0.06903754
  0.2194939   0.6907411   0.50287245  1.01237779  1.14168158  0.35329169
  0.94580043  0.39174498  0.41079512  0.50626254  0.53369287  0.16485461
  0.17030621  0.36783726 -0.16374122 -0.00844737  0.58959133  1.25037232
  0.4290079   0.61771809 -0.04262502 -0.20999709 -0.25319231 -0.15151863
 -0.1649699   0.05042562]
Pearson r: 0.709
MSE: 0.375
Fold 3, k_feat 2048
X_train.shape:  (268, 2048)
y_pred:  [-1.09748247e+00 -1.01724690e+00 -8.79293447e-01 -1.19975855e+00
 -7.65755861e-01 -1.45037837e+00 -1.37410446e+00 -1.28657629e+00
 -1.35224475e+00 -1.56357487e+00 -1.66218810e+00 -1.21017229e+00
 -1.21099229e+00 -1.04763640e+00 -1.10757687e+00 -1.45956203e+00
 -1.45895919e+00 -1.20894472e+00 -1.15135514e+00 -1.68882114e+00
 -1.38995339e+00 -1.50384107e+00 -3.16492930e-01 -6.51263450e-01
 -4.69258121e-01 -3.85101240e-01 -8.26338356e-01 -9.39921695e-01
 -4.52444009e-01  7.51835356e-01  9.31471508e-01  1.08673104e+00
  7.50768888e-01  9.41875738e-01  8.95884204e-01  7.25183034e-01
  1.02673698e+00  7.79752939e-01  6.60172243e-01  6.07549631e-01
  6.15577583e-01  2.92516948e-01  1.90016627e-01  4.05729630e-01
  4.79856533e-01  2.18360679e-01  4.21680276e-03  1.23970612e-01
 -1.15780697e-01  8.31540003e-01  2.88318320e-01  6.16413700e-01
  1.09150937e+00  4.44480367e-02  3.36990452e-01  3.36780179e-01
  7.62235213e-01  4.41694399e-01  3.21389780e-01  3.40895155e-01
  2.51103542e-01  5.70729299e-01  4.84330499e-01  6.61900903e-01
  3.13938470e-01 -1.86938393e-01  2.01727400e-01  5.72315739e-01
  3.12190788e-01  3.99436446e-03  5.83967368e-01  2.96763241e-01
  2.09222333e-01  1.08134461e-01 -3.97143871e-01 -3.75879511e-01
 -5.55540050e-01 -1.07515099e+00 -5.07107135e-01  4.09496588e-01
  4.56041762e-01  3.60620382e-01  1.85918905e-01  2.95801067e-01
  3.59616762e-01  1.12463480e-01  1.00939202e-01  4.49673109e-01
  2.49056063e-01  3.27941723e-01  3.12371766e-01  2.05068637e-01
 -2.04129522e-02  7.62377343e-02  2.54091928e-02  4.16680454e-01
  6.63238455e-01  3.12499259e-01  2.07177542e-01 -8.64272058e-02
  2.92088279e-01  2.14516346e-01  3.45096521e-01  3.62430480e-01
  1.91003785e+00  8.04006238e-01  5.23276841e-01  8.33489010e-01
  2.02330914e-01  3.74915018e-01  5.31699463e-01  4.28653653e-01
  7.62640657e-01  6.81109257e-01  5.18343232e-01  6.05015275e-02
  3.07519376e-01  6.30989658e-01  2.40122173e-01  3.62044912e-01
  6.86149778e-01 -1.58794604e-03  6.71186379e-01  7.61386151e-01
  6.91670827e-01  5.63994771e-01  1.10580578e-01  1.36748714e+00
  4.80471591e-03  7.41776144e-01 -1.02001818e+00  2.53241078e-01
 -1.18465951e+00  4.55728287e-01]
Pearson r: 0.752
MSE: 0.525
Average pearson_r accross all folds = 0.7217706975384468
Average mse accross all folds = 0.48122121140701674
Fold 1, k_feat 4096
X_train.shape:  (268, 4096)
y_pred:  [-1.20519557 -1.3592615  -1.21379088 -1.01917633 -1.02550538 -0.55061133
 -1.12875191 -1.36014088 -0.91656377 -0.8505855  -1.41064124 -0.95561797
 -1.02365473  0.01932825 -1.09687093 -0.97213214 -1.18317496 -1.23629174
 -0.76632319 -1.06526983 -1.46092063 -1.34526126 -1.24510393 -0.49922042
 -0.15410479 -0.25714119 -0.59872733 -0.39283694 -0.6733369  -1.61458706
 -1.35267722 -1.53595415 -0.21584857 -0.24189866 -0.67880116 -0.98792156
 -0.61069631  0.14762595  0.15148829  1.12880286  1.2722287   0.42215133
  0.25684105  0.26112187  0.34364859  0.21283419  0.35310399  0.52572185
  0.46408866  0.3599224   0.25613094  0.49148801  0.55274233  0.06586234
  0.09222641  0.10357281 -1.12537642  0.40845967  0.29962058  0.128456
  0.40182025  0.24451369  0.35917763  0.15195871  0.10506098  0.30675342
  0.43145324 -0.0716381   0.7759818   0.80651215 -0.09188693  0.25193986
 -0.10036071 -0.07082186  0.47188631 -0.42646456 -0.08322873 -0.19625084
  0.01241499 -0.56611431 -0.54061796  0.23071578  0.16295516 -0.65788853
 -0.33057728 -0.54566083 -0.1858587  -0.31940987  0.0371696  -0.08020142
  0.46703941 -0.07531419 -0.11868571  0.11634674  0.19915238  0.43261182
  0.43728787  0.21499155  0.24892596  0.30972816  0.01642191  0.27848201
  0.32043722  0.20180224  0.12010324  0.25565323  0.22023929  0.48503027
  0.73571277  0.51729296  0.51655485  0.36840352  0.28837831  0.44543955
  0.21817245  0.04027812  0.20292537 -0.06209331  0.6159208   0.2628727
  0.44282435 -0.72304948  0.10506902  0.14570055  0.49000235 -0.65556687
 -0.35581542  0.41237577 -0.33403981  0.06125123 -0.03808187  0.58037758
 -0.4463372   0.21511421]
Pearson r: 0.697
MSE: 0.561
Fold 2, k_feat 4096
X_train.shape:  (268, 4096)
y_pred:  [-0.74891379 -0.97931744 -0.88306667 -0.91731263 -0.63614928 -1.3479768
 -1.30121053 -1.09349416 -0.91028695 -0.28051756 -1.04388294 -1.0381925
 -0.80101101 -0.94680111 -1.27781662 -0.29065041 -0.73975316 -0.39926642
 -0.232917   -0.28566366 -0.80160469 -1.05292803 -0.79583111 -0.7523214
 -0.46480736  0.83118077  1.08054398  1.43162619  1.37170793  1.26918369
  0.35282742  0.34509569  0.46664966  0.11863187  1.27629291  0.69822079
  0.99377892  0.57158703  0.89629926  0.24674062  0.64293281  0.5021263
  0.14087139  0.36745928  0.4250324  -0.09673778  0.57863598  0.64424868
  0.19482461  0.63761782  0.41256436  0.37026541  0.30624082  0.14426317
  0.58303305  1.0035812   0.66716005  0.669476    0.28688586  0.58597453
  0.27620768  0.49719855  0.48363544  0.52817351  0.25193524  0.41915844
  0.14956393  0.24110843  0.30969219  0.14936515  0.51199559  0.3305675
  0.03812376  0.25105096  0.20784104  0.44383411  0.4906382  -0.12565528
  0.33938861 -0.20492677 -0.18146225 -0.16331245  0.17703548 -0.07098242
 -0.0781034   0.47575318  0.79995877 -0.06839819  0.4756012   0.10818621
  0.00238836  0.35148156  1.025125    0.90067725  0.12520788  0.70050202
  0.02331571  0.33068767  0.59708499  0.35908041  0.36366352  0.23094533
  0.28870303  0.1359354   0.88823795  0.95203098 -0.07092779  0.34307057
  0.34909372  0.66130408  0.34260778  0.8137759   1.31673066  0.46832711
  0.89709822  0.3848029   0.38307895  0.54844914  0.77199296  0.17046371
  0.23068292  0.22563206 -0.16873589 -0.28136106  0.68003706  1.10297954
  0.42492842  0.50527861  0.10918558 -0.22408961 -0.24178119 -0.18988279
 -0.20744236  0.1661427 ]
Pearson r: 0.701
MSE: 0.384
Fold 3, k_feat 4096
X_train.shape:  (268, 4096)
y_pred:  [-1.00881119 -0.98115795 -0.95101462 -1.25309709 -0.72638723 -1.31277921
 -1.24533417 -1.23467661 -1.39307396 -1.46472357 -1.59400004 -1.22753529
 -1.19052172 -1.05586052 -1.08391017 -1.59319468 -1.6016383  -1.228299
 -1.24803887 -1.79871488 -1.36804739 -1.507795   -0.29924928 -0.60740675
 -0.44145116 -0.25085486 -0.83085089 -0.8734786  -0.26897568  0.84823912
  0.93627174  1.11154288  0.81908556  0.92244555  0.90116192  0.94302323
  0.83604808  0.71589509  0.43426028  0.54628166  0.60031367  0.28564795
 -0.07510432  0.43319796  0.47333983  0.22865321 -0.1023573   0.12818953
 -0.17919363  0.64941188  0.52604095  0.70579406  0.95676206  0.36197756
  0.23292891  0.23775823  0.89450574  0.45975343  0.3255006   0.34013084
  0.27283207  0.42668389  0.42660418  0.74639858  0.18038469 -0.1241156
  0.37229166  0.6396018   0.2565843   0.07565609  0.5948139   0.12234072
  0.11277714  0.10022817 -0.3619848  -0.37340957 -0.4629852  -1.03183405
 -0.43726548  0.45964755  0.38122015  0.409872    0.10647829  0.9487614
  0.44880272  0.25047386  0.02130264  0.51943779  0.23999732  0.20003918
  0.30089102  0.2077249   0.03588795  0.1141716   0.02043849  0.38616116
  0.63193498  0.30206464  0.2958189  -0.10070961  0.21899345  0.22244476
  0.18093224  0.21407364  1.74309972  0.77394121  0.51530354  0.59739265
  0.14544503  0.44289978  0.46642481  0.49032117  0.67354902  0.94186484
  0.50579677  0.28937119  0.21675699  0.70293815  0.27919521  0.17996175
  0.65787428  0.08507544  0.78774401  0.61939039  0.57225837  0.52240069
 -0.04341013  1.33261397 -0.01082746  0.64531905 -1.04936949  0.2670562
 -1.1649598   0.27781774]
Pearson r: 0.762
MSE: 0.509
Average pearson_r accross all folds = 0.7200420223211559
Average mse accross all folds = 0.484647873237327
Fold 1, k_feat 8192
X_train.shape:  (268, 8192)
y_pred:  [-1.16805685 -1.325835   -1.16138546 -1.17982811 -1.20810876 -0.61494065
 -0.96786126 -1.30352583 -1.14647422 -0.64873851 -1.19538197 -0.99081166
 -1.00472505 -0.02338556 -1.07192144 -1.07585037 -1.26788106 -1.26210209
 -0.70354672 -1.00556134 -1.47486202 -1.37852517 -1.23891046 -0.49390328
 -0.24573197 -0.18071047 -0.56267326 -0.45347864 -0.80344236 -1.54570825
 -1.27839333 -1.42537919 -0.26517636 -0.21688942 -0.74123247 -0.9419281
 -0.6092887   0.21617485  0.08845462  1.18977946  1.25661367  0.38389856
  0.28386712  0.25564436  0.21858334  0.27047738  0.43042399  0.37327446
  0.28963069  0.50340417  0.2071528   0.55547853  0.60072646 -0.05050084
  0.05098987  0.01819116 -1.0971358   0.29937612  0.03625807  0.05513342
  0.43667954  0.29698649  0.47635483  0.27906501  0.23558899  0.49118216
  0.37885332 -0.22586794  0.72781751  0.81044942 -0.04113094  0.30823231
  0.02155037 -0.10981027  0.39119709 -0.40585252 -0.16417461 -0.19519058
 -0.0433771  -0.68945585 -0.51425125  0.31230314  0.19000444 -0.5706555
 -0.21506291 -0.40618701 -0.21898153 -0.24251431  0.03074721 -0.12761415
  0.18171738 -0.06783595 -0.07183049  0.03849921  0.00351372  0.35744567
  0.28385322  0.19955219  0.33516391  0.29798182 -0.00638279  0.44442826
  0.2754133   0.05701669  0.1789542   0.24787138  0.16513959  0.45938769
  0.68552743  0.61089188  0.40702747  0.23391531  0.3043975   0.41798936
  0.23641993 -0.08475955 -0.06180657 -0.1672732   0.54391276  0.19201541
  0.42046163 -0.67405957  0.01168113  0.11780593  0.48905621 -0.64432384
 -0.21866269  0.42931175 -0.4745167  -0.07037183  0.01710664  0.46223515
 -0.50306132  0.06186327]
Pearson r: 0.708
MSE: 0.546
Fold 2, k_feat 8192
X_train.shape:  (268, 8192)
y_pred:  [-0.80188911 -0.94519576 -0.96208747 -0.95180828 -0.64377705 -1.57914117
 -1.09043331 -1.08919928 -0.92041726 -0.21338006 -1.00541411 -1.00552039
 -0.75767113 -0.89318743 -1.20519397 -0.39982188 -0.77954735 -0.51234436
 -0.2148727  -0.32606073 -0.78520714 -1.09334064 -0.8502496  -0.7611173
 -0.45945955  0.82700381  1.06270328  1.47318317  1.40307322  1.35115934
  0.32094634  0.27872446  0.52124649  0.12124782  1.0762075   0.45783056
  0.71334976  0.55885308  0.9068933   0.1689095   0.53458659  0.45301126
  0.31064463  0.38108652  0.19070334 -0.16882901  0.72079255  0.39158738
  0.43264143  0.52907162  0.44038285  0.28425841  0.23965342  0.06385636
  0.45688592  1.0420178   0.56024663  0.61751821  0.33625604  0.54690309
  0.25725702  0.47433454  0.57032344  0.50679717  0.42552385  0.53366547
  0.15332637  0.1938311   0.18296032  0.09759979  0.46668498  0.35079499
  0.09573885  0.15271445  0.24198005  0.50282822  0.48871516 -0.13087824
  0.37055882 -0.30234184 -0.30744017 -0.25019405  0.15203616 -0.13457731
 -0.15174952  0.50828369  0.75686309 -0.12828749  0.37288136  0.21274252
 -0.09284062  0.32546343  1.0100997   0.91312829  0.09634223  0.68627953
  0.23054766  0.34132258  0.42444368  0.40964717  0.35202142  0.20596441
  0.29917033  0.1627163   0.85752768  0.90259143 -0.12944167  0.36902981
  0.41604526  0.48884645  0.38739446  0.8336456   1.13542169  0.4511871
  0.65249737  0.43970466  0.23593608  0.42448687  0.6326999   0.10946136
  0.33624986  0.2706323  -0.10730093 -0.30772536  0.54925972  1.2366444
  0.38594785  0.3904615   0.10772068 -0.15565342 -0.29189558 -0.10749934
 -0.15952225  0.10755268]
Pearson r: 0.703
MSE: 0.384
Fold 3, k_feat 8192
X_train.shape:  (268, 8192)
y_pred:  [-0.94663453 -0.86841458 -0.94924555 -1.31967187 -0.7642651  -1.26111221
 -1.41547364 -1.29833047 -1.55178391 -1.51178578 -1.63482661 -1.37783332
 -1.05896042 -1.04444213 -1.14484768 -1.45960742 -1.45960742 -1.21098047
 -1.12588525 -1.80646987 -1.27448847 -1.57281844 -0.28505207 -0.71156306
 -0.40028849 -0.42125216 -0.78804833 -0.81349058 -0.20320177  0.80580134
  0.9655002   1.07592138  0.84029402  1.01938013  1.01624386  0.93144051
  0.9134733   0.69032367  0.47169238  0.53955443  0.64281212  0.21687919
  0.10047619  0.28879408  0.44676023  0.22692457 -0.02044129  0.03415347
 -0.14624957  0.661728    0.55722616  0.50208863  0.73733299  0.36039479
  0.1663173   0.18472897  0.93192348  0.46884209  0.37921005  0.43903924
  0.3007778   0.27648919  0.49211002  0.64434538  0.18646094 -0.16961792
  0.33728311  0.5827772   0.23323237  0.03676267  0.62866643  0.16563449
  0.23837168  0.1019934  -0.31561045 -0.36338515 -0.53663618 -1.17220047
 -0.53778415  0.3656406   0.42363153  0.47580504  0.06683078  0.56464407
  0.30649349  0.10790801  0.05763378  0.52820505  0.08463146  0.2346554
  0.29387429  0.11969811 -0.0796103   0.22748134  0.09772795  0.56490823
  0.424631    0.34842314  0.17919916 -0.01183092  0.2277784   0.2326464
  0.15083341  0.18001775  1.79775226  0.71800599  0.50538581  0.74350161
  0.291489    0.466172    0.39708349  0.63711536  0.44793127  0.80185271
  0.51502559  0.35234047  0.4931929   0.57597116  0.3039173   0.17210574
  0.70744595  0.18665147  0.74443712  0.70401017  0.66675628  0.58272219
 -0.09657994  1.36457846 -0.04651228  0.72258088 -1.03456559  0.28116809
 -1.14843875  0.28617405]
Pearson r: 0.764
MSE: 0.506
Average pearson_r accross all folds = 0.7248884662020804
Average mse accross all folds = 0.47864289547573396
